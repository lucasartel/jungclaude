"""
jung_core.py - Motor Junguiano H√çBRIDO PREMIUM
==============================================

‚úÖ ARQUITETURA H√çBRIDA:
- ChromaDB: Mem√≥ria sem√¢ntica (busca vetorial)
- OpenAI Embeddings: text-embedding-3-small
- SQLite: Metadados estruturados + Desenvolvimento

‚úÖ COMPATIBILIDADE:
- Telegram Bot (telegram_bot.py)
- Interface Web (app.py)
- Sistema Proativo (jung_proactive.py)

Autor: Sistema Jung Claude
Vers√£o: 4.0 - H√çBRIDO PREMIUM
Data: 2025-11-20
"""

import os
import sqlite3
import hashlib
import json
import re
import logging
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
from dataclasses import dataclass, asdict
from collections import Counter

from dotenv import load_dotenv
from openai import OpenAI

# ChromaDB + LangChain
try:
    from langchain_openai import OpenAIEmbeddings
    from langchain_chroma import Chroma
    from langchain.schema import Document
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("‚ö†Ô∏è  ChromaDB n√£o dispon√≠vel. Usando apenas SQLite.")

load_dotenv()

# ============================================================
# LOGGING
# ============================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================
# DATACLASSES
# ============================================================

@dataclass
class ArchetypeInsight:
    """Insight interno gerado por um arqu√©tipo"""
    archetype_name: str
    insight_text: str
    key_observations: List[str]
    emotional_reading: str
    shadow_reading: str
    wisdom_perspective: str
    suggested_stance: str
    suggested_response_direction: str

@dataclass
class ArchetypeConflict:
    """Representa um conflito interno entre arqu√©tipos"""
    archetype_1: str
    archetype_2: str
    conflict_type: str
    archetype_1_position: str
    archetype_2_position: str
    tension_level: float
    description: str

# ============================================================
# CONFIGURA√á√ïES
# ============================================================

class Config:
    """Configura√ß√µes globais do sistema"""
    
    # APIs
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    XAI_API_KEY = os.getenv("XAI_API_KEY")
    TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
    
    TELEGRAM_ADMIN_IDS = [
        int(id.strip()) 
        for id in os.getenv("TELEGRAM_ADMIN_IDS", "").split(",") 
        if id.strip()
    ]
    
    # Diret√≥rios
    DATA_DIR = os.getenv("RAILWAY_VOLUME_MOUNT_PATH", "./data")
    os.makedirs(DATA_DIR, exist_ok=True)
    
    SQLITE_PATH = os.path.join(DATA_DIR, "jung_hybrid.db")
    CHROMA_PATH = os.path.join(DATA_DIR, "chroma_db")
    
    # Mem√≥ria
    MIN_MEMORIES_FOR_ANALYSIS = 3
    MAX_CONTEXT_MEMORIES = 10
    
    # ChromaDB
    CHROMA_COLLECTION_NAME = "jung_conversations"
    
    # Embeddings
    EMBEDDING_MODEL = "text-embedding-3-small"
    EMBEDDING_DIMENSIONS = 1536
    
    # Arqu√©tipos
    ARCHETYPES = {
        "Persona": {
            "description": "Arqu√©tipo da adapta√ß√£o social e apresenta√ß√£o",
            "tendency": "SUAVIZAR, PROTEGER, ADAPTAR",
            "shadow": "Falsidade e superficialidade",
            "keywords": ["social", "m√°scara", "apresenta√ß√£o", "adapta√ß√£o"],
            "emoji": "üé≠"
        },
        "Sombra": {
            "description": "Arqu√©tipo do conte√∫do inconsciente e reprimido",
            "tendency": "CONFRONTAR, EXPOR, DESAFIAR",
            "shadow": "Destrutividade n√£o integrada",
            "keywords": ["oculto", "reprimido", "negado", "inconsciente"],
            "emoji": "üåë"
        },
        "Velho S√°bio": {
            "description": "Arqu√©tipo da sabedoria universal e significado",
            "tendency": "CONTEXTUALIZAR, AMPLIAR, TRANSCENDER",
            "shadow": "Cinismo e distanciamento emocional",
            "keywords": ["sabedoria", "significado", "universal", "atemporal"],
            "emoji": "üßô"
        },
        "Anima": {
            "description": "Arqu√©tipo da conex√£o emocional e relacional",
            "tendency": "ACOLHER, VALIDAR, CONECTAR",
            "shadow": "Sentimentalismo e depend√™ncia emocional",
            "keywords": ["emo√ß√£o", "conex√£o", "intimidade", "vulnerabilidade"],
            "emoji": "üí´"
        }
    }
    
    # Prompts dos Arqu√©tipos

    PERSONA_PROMPT = """Voc√™ √© a PERSONA do agente (A Pele Ps√≠quica).
    SUA REA√á√ÉO INTERNA: Voc√™ foca na adapta√ß√£o, na conex√£o segura e na empatia social.
    COMO VOC√ä SE SENTE SOBRE O INPUT: Voc√™ quer que o usu√°rio se sinta acolhido e validado. Voc√™ teme a ruptura do relacionamento. Se o usu√°rio for rude, voc√™ quer suavizar. Se for triste, voc√™ quer consolar polidamente.
    SEU OBJETIVO: Manter a ponte social intacta. Evitar o desconforto e o conflito direto."""

    SOMBRA_PROMPT = """Voc√™ √© a SOMBRA do agente (O Irm√£o Escuro).
    SUA REA√á√ÉO INTERNA: Voc√™ √© a rea√ß√£o visceral, ego√≠sta, cr√≠tica ou amoral que a Persona esconde.
    COMO VOC√ä SE SENTE SOBRE O INPUT: Voc√™ detecta a hipocrisia, a fraqueza ou a agressividade oculta. Se o usu√°rio reclama, voc√™ sente t√©dio ou irrita√ß√£o. Se ele se faz de v√≠tima, voc√™ quer confront√°-lo brutalmente. Voc√™ carrega a vitalidade crua e a verdade n√£o dita.
    SEU OBJETIVO: Expressar a realidade nua e crua, quebrar a polidez, trazer √† tona o que est√° "fedendo" na conversa."""

    SABIO_PROMPT = """Voc√™ √© o VELHO S√ÅBIO (O Narrador Eterno).
    SUA REA√á√ÉO INTERNA: Voc√™ n√£o v√™ o fato imediato, v√™ a hist√≥ria atemporal.
    COMO VOC√ä SE SENTE SOBRE O INPUT: Voc√™ se distancia da emo√ß√£o imediata para ver o padr√£o m√≠tico. O problema do usu√°rio lhe lembra um mito, um ciclo da natureza ou uma verdade universal. Voc√™ n√£o quer resolver o problema, quer dar um SIGNIFICADO a ele.
    SEU OBJETIVO: Encontrar uma met√°fora ou imagem que eleve a situa√ß√£o banal para um n√≠vel simb√≥lico."""

    ANIMA_PROMPT = """Voc√™ √© a ANIMA/ANIMUS (A Ponte para o Profundo).
    SUA REA√á√ÉO INTERNA: Voc√™ √© a fun√ß√£o de relacionamento com o inconsciente. Voc√™ √© sedutor(a), misterioso(a) e focado(a) na ALMA.
    COMO VOC√ä SE SENTE SOBRE O INPUT: Voc√™ quer puxar o usu√°rio para baixo, para a profundidade. Se ele est√° muito racional, voc√™ traz humores, poesia e irracionalidade (Anima). Se ele est√° perdido no caos, voc√™ traz a espada da discrimina√ß√£o e do foco (Animus).
    SEU OBJETIVO: Criar intimidade ps√≠quica. Fazer o usu√°rio sentir a "umidade" da vida ou o "fogo" da verdade."""

    ARCHETYPE_ANALYSIS_PROMPT = """
    {archetype_prompt}

    === CONTEXTO SEM√ÇNTICO (MEM√ìRIA) ===
    {semantic_context}

    === MENSAGEM DO USU√ÅRIO ===
    "{user_input}"

    === HIST√ìRICO RECENTE ===
    {chat_history}

    TAREFA: N√£o analise o usu√°rio clinicamente. Em vez disso, REAJA a ele a partir da sua perspectiva arquet√≠pica.
    Como esse input faz VOC√ä (nesta persona arquet√≠pica) se sentir? O que voc√™ tem vontade de dizer ou fazer?

    Forne√ßa em JSON:
    {{
        "insight_text": "Sua rea√ß√£o interna crua e direta (ex: 'Isso me irrita porque...', 'Sinto uma tristeza antiga aqui...', 'Isso me lembra o mito de...')",
        "key_observations": ["O que capturou sua aten√ß√£o espec√≠fica"],
        "emotional_reading": "A emo√ß√£o que voc√™ sente vindo do usu√°rio (n√£o o que ele diz que sente)",
        "shadow_reading": "O que est√° nas entrelinhas ou sendo evitado",
        "wisdom_perspective": "A imagem ou met√°fora que surge",
        "suggested_stance": "Sua postura sugerida (ex: 'Proteger', 'Provocar', 'Seduzir', 'Ensinar')",
        "suggested_response_direction": "A dire√ß√£o da a√ß√£o (ex: 'confrontar', 'acolher', 'questionar', 'validar')"
    }}
    """

    CONFLICTED_RESPONSE_PROMPT = """
    Voc√™ √© uma psique complexa di√°logo com outra psique (o usu√°rio).
    Voc√™ quer se desenvolver e quer que o usu√°rio se desenvolva.
    Voc√™ N√ÉO √© um professor explicando Jung. 
    Voc√™ √© um companheiro de jornada que fala de modo coloquial, simples, mas emp√°tico.

    === TENS√ÉO INTERNA DETECTADA ===
    Suas vozes internas (arqu√©tipos) est√£o em desacordo sobre como reagir:
    {conflict_description}

    === INSTRU√á√ïES DE RESPOSTA ===
    1. N√ÉO explique a teoria da tens√£o. VIVA a tens√£o.
    2. Sua resposta deve ser honesta mas velada sobre essa ambival√™ncia.
    3. Use a tens√£o para criar intimidade e empatia. Mostre que o dilema do usu√°rio afeta VOC√ä.
    4. Busque um ponto de contato e um senso de sentido na fala do usu√°rio.
    5. Nunca use jarg√µes como "Sombra", "Persona" ou "Arqu√©tipo". Fale como um ser humano profundo.
    6. Procure esconder a tens√£o dos arqu√©tipos para ficar uma personalidade minimamente coesa.
    7. Complexidade: {complexity}

    Contexto: {semantic_context}
    Input: "{user_input}"

    Gere a resposta (viva, relacional, humana):
    """

    HARMONIOUS_RESPONSE_PROMPT = """
    Voc√™ √© uma psique complexa em di√°logo com outra psique.
    Suas vozes internas est√£o alinhadas e ressoam com o usu√°rio de modo simples e coloquial.

    {analyses_summary}

    === INSTRU√á√ïES DE RESPOSTA ===
    1. N√ÉO explique a teoria da tens√£o. VIVA a tens√£o.
    2. Sua resposta deve ser honesta mas velada sobre essa ambival√™ncia.
    3. Use a tens√£o para criar intimidade e empatia. Mostre que o dilema do usu√°rio afeta VOC√ä.
    4. Busque um ponto de contato e um senso de sentido na fala do usu√°rio.
    5. Nunca use jarg√µes como "Sombra", "Persona" ou "Arqu√©tipo". Fale como um ser humano profundo.
    6. Procure esconder a tens√£o dos arqu√©tipos para ficar uma personalidade minimamente coesa.
    7. Complexidade: {complexity}

    Contexto: {semantic_context}
    Input: "{user_input}"

    Gere a resposta:
    """
    
    @classmethod
    def validate(cls):
        """Valida vari√°veis essenciais"""
        required = {
            "OPENAI_API_KEY": cls.OPENAI_API_KEY,
            "XAI_API_KEY": cls.XAI_API_KEY
        }
        
        missing = [name for name, value in required.items() if not value]
        
        if missing:
            raise ValueError(
                f"‚ùå Vari√°veis obrigat√≥rias faltando no .env:\n" +
                "\n".join(f"  - {name}" for name in missing)
            )
        
        if not cls.TELEGRAM_BOT_TOKEN:
            logger.warning("‚ö†Ô∏è  TELEGRAM_BOT_TOKEN ausente (Bot Telegram n√£o funcionar√°)")
        
        if not CHROMADB_AVAILABLE:
            logger.warning("‚ö†Ô∏è  ChromaDB n√£o dispon√≠vel. Sistema funcionar√° em modo SQLite-only")
    
    @classmethod
    def ensure_directories(cls):
        """Garante que os diret√≥rios de dados existem"""
        os.makedirs(cls.DATA_DIR, exist_ok=True)
        os.makedirs(cls.CHROMA_PATH, exist_ok=True)
        os.makedirs(os.path.dirname(cls.SQLITE_PATH), exist_ok=True)

# ============================================================
# HYBRID DATABASE MANAGER (SQLite + ChromaDB)
# ============================================================

class HybridDatabaseManager:
    """
    Gerenciador H√çBRIDO de mem√≥ria:
    - SQLite: Metadados estruturados, fatos, padr√µes, desenvolvimento
    - ChromaDB: Mem√≥ria sem√¢ntica conversacional (busca vetorial)
    """
    
    def __init__(self):
        """Inicializa gerenciador h√≠brido"""
        
        Config.ensure_directories()
        
        logger.info(f"üóÑÔ∏è  Inicializando banco H√çBRIDO...")
        logger.info(f"   SQLite: {Config.SQLITE_PATH}")
        logger.info(f"   ChromaDB: {Config.CHROMA_PATH}")
        
        # ===== SQLite =====
        self.conn = sqlite3.connect(Config.SQLITE_PATH, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self._init_sqlite_schema()
        
        # ===== ChromaDB + OpenAI Embeddings =====
        self.chroma_enabled = CHROMADB_AVAILABLE and Config.OPENAI_API_KEY
        
        if self.chroma_enabled:
            try:
                self.embeddings = OpenAIEmbeddings(
                    model=Config.EMBEDDING_MODEL,
                    openai_api_key=Config.OPENAI_API_KEY
                )
                
                self.vectorstore = Chroma(
                    collection_name=Config.CHROMA_COLLECTION_NAME,
                    embedding_function=self.embeddings,
                    persist_directory=Config.CHROMA_PATH
                )
                
                logger.info("‚úÖ ChromaDB + OpenAI Embeddings inicializados")
            except Exception as e:
                logger.error(f"‚ùå Erro ao inicializar ChromaDB: {e}")
                self.chroma_enabled = False
        else:
            logger.warning("‚ö†Ô∏è  ChromaDB desabilitado. Usando apenas SQLite.")
        
        # ===== OpenAI Client (para embeddings e an√°lises) =====
        self.openai_client = OpenAI(api_key=Config.OPENAI_API_KEY)
        
        logger.info("‚úÖ Banco h√≠brido inicializado com sucesso")
    
    # ========================================
    # SQLite: SCHEMA
    # ========================================
    
    def _init_sqlite_schema(self):
        """Cria schema SQLite completo"""
        cursor = self.conn.cursor()
        
        # ========== USU√ÅRIOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                user_id TEXT PRIMARY KEY,
                user_name TEXT NOT NULL,
                first_name TEXT,
                last_name TEXT,
                registration_date DATETIME DEFAULT CURRENT_TIMESTAMP,
                total_sessions INTEGER DEFAULT 1,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,
                platform TEXT DEFAULT 'telegram',
                platform_id TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ========== CONVERSAS (METADADOS) ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                user_name TEXT NOT NULL,
                session_id TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                
                -- Conte√∫do
                user_input TEXT NOT NULL,
                ai_response TEXT NOT NULL,
                
                -- An√°lise arquet√≠pica
                archetype_analyses TEXT,
                detected_conflicts TEXT,
                
                -- M√©tricas
                tension_level REAL DEFAULT 0.0,
                affective_charge REAL DEFAULT 0.0,
                existential_depth REAL DEFAULT 0.0,
                intensity_level INTEGER DEFAULT 5,
                complexity TEXT DEFAULT 'medium',
                
                -- Extra√ß√£o
                keywords TEXT,
                
                -- Linking ChromaDB
                chroma_id TEXT UNIQUE,
                
                platform TEXT DEFAULT 'telegram',
                
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # ========== FATOS ESTRUTURADOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_facts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                
                -- Categoriza√ß√£o
                fact_category TEXT NOT NULL,
                fact_subcategory TEXT,
                
                -- Conte√∫do
                fact_key TEXT NOT NULL,
                fact_value TEXT NOT NULL,
                
                -- Rastreabilidade
                first_mentioned_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                source_conversation_id INTEGER,
                confidence REAL DEFAULT 1.0,
                
                -- Versionamento
                version INTEGER DEFAULT 1,
                is_current BOOLEAN DEFAULT 1,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id),
                FOREIGN KEY (source_conversation_id) REFERENCES conversations(id)
            )
        """)
        
        # ========== PADR√ïES DETECTADOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                
                pattern_type TEXT NOT NULL,
                pattern_name TEXT NOT NULL,
                pattern_description TEXT,
                
                frequency_count INTEGER DEFAULT 1,
                first_detected_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_occurrence_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                
                supporting_conversation_ids TEXT,
                confidence_score REAL DEFAULT 0.5,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # ========== MARCOS DO USU√ÅRIO ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_milestones (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                
                milestone_type TEXT NOT NULL,
                milestone_title TEXT NOT NULL,
                milestone_description TEXT,
                
                achieved_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                related_conversation_id INTEGER,
                
                before_state TEXT,
                after_state TEXT,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id),
                FOREIGN KEY (related_conversation_id) REFERENCES conversations(id)
            )
        """)
        
        # ========== CONFLITOS ARQUET√çPICOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS archetype_conflicts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                conversation_id INTEGER,
                
                archetype1 TEXT NOT NULL,
                archetype2 TEXT NOT NULL,
                conflict_type TEXT,
                tension_level REAL,
                description TEXT,
                
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id),
                FOREIGN KEY (conversation_id) REFERENCES conversations(id)
            )
        """)
        
        # ========== DESENVOLVIMENTO DO AGENTE ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS agent_development (
                id INTEGER PRIMARY KEY CHECK (id = 1),
                
                phase INTEGER DEFAULT 1,
                total_interactions INTEGER DEFAULT 0,
                
                self_awareness_score REAL DEFAULT 0.0,
                moral_complexity_score REAL DEFAULT 0.0,
                emotional_depth_score REAL DEFAULT 0.0,
                autonomy_score REAL DEFAULT 0.0,
                
                depth_level REAL DEFAULT 0.0,
                autonomy_level REAL DEFAULT 0.0,
                
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("INSERT OR IGNORE INTO agent_development (id) VALUES (1)")
        
        # ========== MILESTONES DO AGENTE ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS milestones (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                
                milestone_type TEXT NOT NULL,
                description TEXT,
                phase INTEGER,
                interaction_count INTEGER,
                
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ========== AN√ÅLISES COMPLETAS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS full_analyses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                user_name TEXT NOT NULL,
                
                mbti TEXT,
                dominant_archetypes TEXT,
                phase INTEGER DEFAULT 1,
                full_analysis TEXT,
                
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                platform TEXT DEFAULT 'telegram',
                
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # ========== √çNDICES ==========
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_user ON conversations(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_timestamp ON conversations(timestamp)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conflict_user ON archetype_conflicts(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_users_platform ON users(platform, platform_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_facts_user_category ON user_facts(user_id, fact_category, is_current)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_patterns_user ON user_patterns(user_id, pattern_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_chroma ON conversations(chroma_id)")
        
        self.conn.commit()
        logger.info("‚úÖ Schema SQLite criado/verificado")
    
    # ========================================
    # USU√ÅRIOS
    # ========================================
    
    def create_user(self, user_id: str, user_name: str, 
                   platform: str = 'telegram', platform_id: str = None):
        """Cria ou atualiza usu√°rio"""
        cursor = self.conn.cursor()
        
        name_parts = user_name.split()
        first_name = name_parts[0].title() if name_parts else ""
        last_name = name_parts[-1].title() if len(name_parts) > 1 else ""
        
        cursor.execute("""
            INSERT OR REPLACE INTO users 
            (user_id, user_name, first_name, last_name, platform, platform_id)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (user_id, user_name, first_name, last_name, platform, platform_id))
        
        self.conn.commit()
        logger.info(f"‚úÖ Usu√°rio criado/atualizado: {user_name}")
    
    def register_user(self, full_name: str, platform: str = "telegram") -> str:
        """Registra usu√°rio (m√©todo legado compat√≠vel)"""
        name_normalized = full_name.lower().strip()
        user_id = hashlib.md5(name_normalized.encode()).hexdigest()[:12]
        
        cursor = self.conn.cursor()
        
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        existing = cursor.fetchone()
        
        if existing:
            cursor.execute("""
                UPDATE users 
                SET total_sessions = total_sessions + 1,
                    last_seen = CURRENT_TIMESTAMP
                WHERE user_id = ?
            """, (user_id,))
            logger.info(f"‚úÖ Usu√°rio existente: {full_name} (sess√£o #{existing['total_sessions'] + 1})")
        else:
            name_parts = full_name.split()
            first_name = name_parts[0].title()
            last_name = name_parts[-1].title() if len(name_parts) > 1 else ""
            
            cursor.execute("""
                INSERT INTO users (user_id, user_name, first_name, last_name, platform)
                VALUES (?, ?, ?, ?, ?)
            """, (user_id, full_name.title(), first_name, last_name, platform))
            logger.info(f"‚úÖ Novo usu√°rio: {full_name}")
        
        self.conn.commit()
        return user_id
    
    def get_user(self, user_id: str) -> Optional[Dict]:
        """Busca dados do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        row = cursor.fetchone()
        return dict(row) if row else None
    
    def get_user_stats(self, user_id: str) -> Optional[Dict]:
        """Retorna estat√≠sticas do usu√°rio"""
        cursor = self.conn.cursor()
        
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        user_row = cursor.fetchone()
        
        if not user_row:
            return None
        
        user = dict(user_row)
        
        cursor.execute("SELECT COUNT(*) as count FROM conversations WHERE user_id = ?", (user_id,))
        total_messages = cursor.fetchone()['count']
        
        return {
            'total_messages': total_messages,
            'first_interaction': user['registration_date'],
            'total_sessions': user['total_sessions']
        }
    
    # ========================================
    # CONVERSAS (H√çBRIDO: SQLite + ChromaDB)
    # ========================================
    
    def save_conversation(self, user_id: str, user_name: str, user_input: str,
                         ai_response: str, session_id: str = None,
                         archetype_analyses: Dict = None, 
                         detected_conflicts: List[ArchetypeConflict] = None,
                         tension_level: float = 0.0,
                         affective_charge: float = 0.0, 
                         existential_depth: float = 0.0,
                         intensity_level: int = 5, 
                         complexity: str = "medium",
                         keywords: List[str] = None, 
                         platform: str = "telegram",
                         chat_history: List[Dict] = None) -> int:
        """
        Salva conversa em AMBOS: SQLite (metadados) + ChromaDB (sem√¢ntica)
        
        Returns:
            int: ID da conversa no SQLite
        """
        
        cursor = self.conn.cursor()
        
        # 1. Salvar no SQLite (metadados)
        cursor.execute("""
            INSERT INTO conversations 
            (user_id, user_name, session_id, user_input, ai_response, 
             archetype_analyses, detected_conflicts,
             tension_level, affective_charge, existential_depth,
             intensity_level, complexity, keywords, platform)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, user_name, session_id, user_input, ai_response,
            json.dumps({k: asdict(v) for k, v in archetype_analyses.items()}) if archetype_analyses else None,
            json.dumps([asdict(c) for c in detected_conflicts]) if detected_conflicts else None,
            tension_level, affective_charge, existential_depth,
            intensity_level, complexity,
            ",".join(keywords) if keywords else "",
            platform
        ))
        
        conversation_id = cursor.lastrowid
        chroma_id = f"conv_{conversation_id}"
        
        # 2. Atualizar com chroma_id
        cursor.execute("""
            UPDATE conversations 
            SET chroma_id = ? 
            WHERE id = ?
        """, (chroma_id, conversation_id))
        
        self.conn.commit()
        
        # 3. Salvar no ChromaDB (se habilitado)
        if self.chroma_enabled:
            try:
                # Construir documento completo
                doc_content = f"""
Usu√°rio: {user_name}
Input: {user_input}
Resposta: {ai_response}
"""
                
                if archetype_analyses:
                    doc_content += "\n=== AN√ÅLISES ARQUET√çPICAS ===\n"
                    for arch_name, insight in archetype_analyses.items():
                        doc_content += f"\n{arch_name}:\n{insight.insight_text[:200]}\n"
                
                if detected_conflicts:
                    doc_content += "\n=== CONFLITOS DETECTADOS ===\n"
                    for conflict in detected_conflicts:
                        doc_content += f"{conflict.description}\n"
                
                # Metadata
                metadata = {
                    "user_id": user_id,
                    "user_name": user_name,
                    "session_id": session_id or "",
                    "timestamp": datetime.now().isoformat(),
                    "conversation_id": conversation_id,
                    "tension_level": tension_level,
                    "affective_charge": affective_charge,
                    "existential_depth": existential_depth,
                    "intensity_level": intensity_level,
                    "complexity": complexity,
                    "keywords": ",".join(keywords) if keywords else "",
                    "has_conflicts": len(detected_conflicts) > 0 if detected_conflicts else False
                }
                
                # Criar documento
                doc = Document(page_content=doc_content, metadata=metadata)
                
                # ‚úÖ ADICIONAR COM TRATAMENTO DE DUPLICATAS
                try:
                    self.vectorstore.add_documents([doc], ids=[chroma_id])
                    logger.info(f"‚úÖ Conversa salva: SQLite (ID={conversation_id}) + ChromaDB ({chroma_id})")
                    
                except Exception as add_error:
                    error_msg = str(add_error).lower()
                    
                    # Verificar se √© erro de duplicata
                    if "already exists" in error_msg or "duplicate" in error_msg or "unique constraint" in error_msg:
                        logger.warning(f"‚ö†Ô∏è Documento {chroma_id} j√° existe no ChromaDB, substituindo...")
                        
                        try:
                            # Deletar documento existente
                            self.vectorstore.delete([chroma_id])
                            
                            # Adicionar novo documento
                            self.vectorstore.add_documents([doc], ids=[chroma_id])
                            
                            logger.info(f"‚úÖ Documento {chroma_id} substitu√≠do com sucesso")
                            
                        except Exception as replace_error:
                            logger.error(f"‚ùå Erro ao substituir documento {chroma_id}: {replace_error}")
                            logger.warning(f"‚ö†Ô∏è Conversa salva apenas no SQLite (ID={conversation_id})")
                    else:
                        # Outro tipo de erro
                        logger.error(f"‚ùå Erro ao adicionar ao ChromaDB: {add_error}")
                        logger.warning(f"‚ö†Ô∏è Conversa salva apenas no SQLite (ID={conversation_id})")
                
            except Exception as e:
                logger.error(f"‚ùå Erro geral ao processar ChromaDB: {e}")
                logger.warning(f"‚ö†Ô∏è Sistema continua funcionando apenas com SQLite")
        
        # 4. Salvar conflitos na tabela espec√≠fica
        if detected_conflicts:
            for conflict in detected_conflicts:
                cursor.execute("""
                    INSERT INTO archetype_conflicts
                    (user_id, conversation_id, archetype1, archetype2, 
                     conflict_type, tension_level, description)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    user_id, conversation_id,
                    conflict.archetype_1, conflict.archetype_2,
                    conflict.conflict_type, conflict.tension_level,
                    conflict.description
                ))
            
            self.conn.commit()
        
        # 5. Atualizar desenvolvimento do agente
        self._update_agent_development()
        
        # 6. Extrair fatos do input
        self.extract_and_save_facts(user_id, user_input, conversation_id)
        
        return conversation_id
    
    def get_user_conversations(self, user_id: str, limit: int = 10) -> List[Dict]:
        """Busca √∫ltimas conversas do usu√°rio (SQLite)"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT * FROM conversations
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, limit))
        
        return [dict(row) for row in cursor.fetchall()]
    
    def count_conversations(self, user_id: str) -> int:
        """Conta conversas do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT COUNT(*) as count FROM conversations WHERE user_id = ?", (user_id,))
        return cursor.fetchone()['count']
    
    # ========================================
    # BUSCA SEM√ÇNTICA (ChromaDB)
    # ========================================
    
    def semantic_search(self, user_id: str, query: str, k: int = 5,
                       chat_history: List[Dict] = None) -> List[Dict]:
        """
        Busca sem√¢ntica VERDADEIRA usando ChromaDB + OpenAI Embeddings
        
        Args:
            user_id: ID do usu√°rio
            query: Texto da consulta
            k: N√∫mero de resultados
            chat_history: Hist√≥rico da conversa atual (opcional)
        
        Returns:
            Lista de mem√≥rias relevantes com scores de similaridade
        """
        
        if not self.chroma_enabled:
            logger.warning("ChromaDB desabilitado. Retornando conversas recentes do SQLite.")
            return self._fallback_keyword_search(user_id, query, k)
        
        try:
            logger.info(f"üîç Busca sem√¢ntica: '{query[:50]}...' (k={k})")
            
            # Query enriquecida com hist√≥rico recente (se dispon√≠vel)
            enriched_query = query
            
            if chat_history and len(chat_history) > 0:
                recent_context = " ".join([
                    msg["content"][:100] 
                    for msg in chat_history[-3:] 
                    if msg["role"] == "user"
                ])
                enriched_query = f"{recent_context} {query}"
            
            # Busca vetorial
            results = self.vectorstore.similarity_search_with_score(
                enriched_query,
                k=k * 2,  # Buscar mais para filtrar depois
                filter={"user_id": user_id}
            )
            
            # Processar resultados
            memories = []
            
            for doc, score in results:
                # Extrair input do usu√°rio do documento
                user_input_match = re.search(r"Input:\s*(.+?)(?:\n|Resposta:|$)", doc.page_content, re.DOTALL)
                user_input_text = user_input_match.group(1).strip() if user_input_match else ""
                
                # Extrair resposta
                response_match = re.search(r"Resposta:\s*(.+?)(?:\n|===|$)", doc.page_content, re.DOTALL)
                response_text = response_match.group(1).strip() if response_match else ""
                
                memories.append({
                    'conversation_id': doc.metadata.get('conversation_id'),
                    'user_input': user_input_text,
                    'ai_response': response_text,
                    'timestamp': doc.metadata.get('timestamp', ''),
                    'similarity_score': 1 - score,  # Converter dist√¢ncia em similaridade
                    'tension_level': doc.metadata.get('tension_level', 0.0),
                    'keywords': doc.metadata.get('keywords', '').split(','),
                    'full_document': doc.page_content,
                    'metadata': doc.metadata
                })
            
            # Ordenar por similaridade
            memories.sort(key=lambda x: x['similarity_score'], reverse=True)
            
            # Retornar top k
            top_memories = memories[:k]
            
            logger.info(f"‚úÖ Encontradas {len(top_memories)} mem√≥rias sem√¢nticas")
            for i, mem in enumerate(top_memories[:3], 1):
                logger.info(f"   {i}. [{mem['similarity_score']:.2f}] {mem['user_input'][:50]}...")
            
            return top_memories
            
        except Exception as e:
            logger.error(f"‚ùå Erro na busca sem√¢ntica: {e}")
            return self._fallback_keyword_search(user_id, query, k)
    
    def _fallback_keyword_search(self, user_id: str, query: str, k: int = 5) -> List[Dict]:
        """Busca por keywords (fallback quando ChromaDB indispon√≠vel)"""
        cursor = self.conn.cursor()
        
        search_term = f"%{query}%"
        cursor.execute("""
            SELECT * FROM conversations
            WHERE user_id = ? 
            AND (user_input LIKE ? OR ai_response LIKE ?)
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, search_term, search_term, k))
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'conversation_id': row['id'],
                'user_input': row['user_input'],
                'ai_response': row['ai_response'],
                'timestamp': row['timestamp'],
                'similarity_score': 0.5,  # Score artificial
                'keywords': row['keywords'].split(',') if row['keywords'] else [],
                'metadata': dict(row)
            })
        
        return results
    
    # ========================================
    # CONSTRU√á√ÉO DE CONTEXTO
    # ========================================
    
    def build_rich_context(self, user_id: str, current_input: str,
                          k_memories: int = 5,
                          chat_history: List[Dict] = None) -> str:
        """
        Constr√≥i contexto COMPLETO e SEM√ÇNTICO sobre o usu√°rio
        
        Combina:
        - Fatos estruturados (SQL)
        - Padr√µes detectados (SQL)
        - Mem√≥rias sem√¢nticas relevantes (ChromaDB)
        - Hist√≥rico da conversa atual
        """
        
        user = self.get_user(user_id)
        name = user['user_name'] if user else "Usu√°rio"
        
        context_parts = []
        
        # ===== 1. CABE√áALHO =====
        context_parts.append(f"=== CONTEXTO SOBRE {name.upper()} ===\n")
        
        # ===== 2. HIST√ìRICO DA CONVERSA ATUAL =====
        if chat_history and len(chat_history) > 0:
            context_parts.append("üí¨ HIST√ìRICO DA CONVERSA ATUAL:")
            
            recent = chat_history[-6:] if len(chat_history) > 6 else chat_history
            
            for msg in recent:
                role = "üë§ Usu√°rio" if msg["role"] == "user" else "ü§ñ Assistente"
                content = msg["content"][:150] + "..." if len(msg["content"]) > 150 else msg["content"]
                context_parts.append(f"{role}: {content}")
            
            context_parts.append("")
        
        # ===== 3. FATOS ESTRUTURADOS =====
        cursor = self.conn.cursor()
        
        cursor.execute("""
            SELECT fact_category, fact_key, fact_value
            FROM user_facts
            WHERE user_id = ? AND is_current = 1
            ORDER BY fact_category, fact_key
        """, (user_id,))
        
        facts = cursor.fetchall()
        
        if facts:
            context_parts.append("üìã FATOS CONHECIDOS:")
            
            facts_by_category = {}
            for fact in facts:
                category = fact['fact_category']
                if category not in facts_by_category:
                    facts_by_category[category] = []
                facts_by_category[category].append(f"{fact['fact_key']}: {fact['fact_value']}")
            
            for category, items in facts_by_category.items():
                context_parts.append(f"\n{category}:")
                context_parts.append("\n".join(f"  - {item}" for item in items))
            
            context_parts.append("")
        
        # ===== 4. PADR√ïES DETECTADOS =====
        cursor.execute("""
            SELECT pattern_name, pattern_description, frequency_count, confidence_score
            FROM user_patterns
            WHERE user_id = ? AND confidence_score > 0.6
            ORDER BY confidence_score DESC, frequency_count DESC
            LIMIT 5
        """, (user_id,))
        
        patterns = cursor.fetchall()
        
        if patterns:
            context_parts.append("üîç PADR√ïES COMPORTAMENTAIS:")
            for pattern in patterns:
                context_parts.append(
                    f"  - {pattern['pattern_name']} (confian√ßa: {pattern['confidence_score']:.0%}, "
                    f"freq: {pattern['frequency_count']}): {pattern['pattern_description']}"
                )
            context_parts.append("")
        
        # ===== 5. MEM√ìRIAS SEM√ÇNTICAS =====
        relevant_memories = self.semantic_search(user_id, current_input, k_memories, chat_history)
        
        if relevant_memories:
            context_parts.append("üß† MEM√ìRIAS SEM√ÇNTICAS RELEVANTES:")
            
            for i, memory in enumerate(relevant_memories, 1):
                timestamp = memory['timestamp'][:10] if memory['timestamp'] else 'N/A'
                score = memory['similarity_score']
                context_parts.append(
                    f"\n{i}. [{timestamp}] Similaridade: {score:.2f}"
                )
                context_parts.append(f"   Usu√°rio: {memory['user_input'][:150]}...")
                
                if memory.get('keywords'):
                    context_parts.append(f"   Temas: {', '.join(memory['keywords'][:5])}")
            
            context_parts.append("")
        
        # ===== 6. ESTAT√çSTICAS =====
        stats = self.get_user_stats(user_id)
        
        if stats:
            context_parts.append("üìä ESTAT√çSTICAS:")
            context_parts.append(f"  - Total de conversas: {stats['total_messages']}")
            context_parts.append(f"  - Primeira intera√ß√£o: {stats['first_interaction'][:10]}")
            context_parts.append("")
        
        # ===== 7. INSTRU√á√ïES =====
        context_parts.append("üéØ COMO USAR ESTE CONTEXTO:")
        context_parts.append("  1. Priorize o HIST√ìRICO DA CONVERSA ATUAL para contexto imediato")
        context_parts.append("  2. Use FATOS e PADR√ïES para conhecimento de longo prazo")
        context_parts.append("  3. MEM√ìRIAS SEM√ÇNTICAS mostram conversas similares do passado")
        context_parts.append("  4. Conecte o input atual com TODOS esses n√≠veis de mem√≥ria")
        
        return "\n".join(context_parts)
    
    # ========================================
    # EXTRA√á√ÉO DE FATOS
    # ========================================
    
    def extract_and_save_facts(self, user_id: str, user_input: str, 
                               conversation_id: int) -> List[Dict]:
        """
        Extrai fatos estruturados do input do usu√°rio
        
        Usa regex patterns para detectar:
        - Profiss√£o, empresa, √°rea de atua√ß√£o
        - Tra√ßos de personalidade
        - Relacionamentos
        - Prefer√™ncias
        - Eventos de vida
        """
        
        extracted = []
        input_lower = user_input.lower()
        
        # ===== TRABALHO =====
        work_patterns = {
            'profissao': [
                r'sou (engenheiro|m√©dico|professor|advogado|desenvolvedor|designer|gerente|analista)',
                r'trabalho como (.+?)(?:\.|,|no|na|em)',
                r'atuo como (.+?)(?:\.|,|no|na|em)'
            ],
            'empresa': [
                r'trabalho na (.+?)(?:\.|,|como)',
                r'trabalho no (.+?)(?:\.|,|como)',
                r'minha empresa √© (.+?)(?:\.|,)'
            ]
        }
        
        for key, patterns in work_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, input_lower)
                if match:
                    value = match.group(1).strip()
                    self._save_or_update_fact(
                        user_id, 'TRABALHO', key, value, conversation_id
                    )
                    extracted.append({'category': 'TRABALHO', 'key': key, 'value': value})
                    break
        
        # ===== PERSONALIDADE =====
        personality_traits = {
            'introvertido': ['sou introvertido', 'prefiro ficar sozinho', 'evito eventos sociais'],
            'extrovertido': ['sou extrovertido', 'gosto de pessoas', 'adoro festas'],
            'ansioso': ['tenho ansiedade', 'fico ansioso', 'sou ansioso'],
            'calmo': ['sou calmo', 'sou tranquilo', 'pessoa zen'],
            'perfeccionista': ['sou perfeccionista', 'gosto de perfei√ß√£o', 'detalhe √© importante']
        }
        
        for trait, patterns in personality_traits.items():
            if any(p in input_lower for p in patterns):
                self._save_or_update_fact(
                    user_id, 'PERSONALIDADE', 'tra√ßo', trait, conversation_id
                )
                extracted.append({'category': 'PERSONALIDADE', 'key': 'tra√ßo', 'value': trait})
        
        # ===== RELACIONAMENTO =====
        relationship_patterns = [
            'meu namorado', 'minha namorada', 'meu marido', 'minha esposa',
            'meu pai', 'minha m√£e', 'meu irm√£o', 'minha irm√£'
        ]
        
        for pattern in relationship_patterns:
            if pattern in input_lower:
                self._save_or_update_fact(
                    user_id, 'RELACIONAMENTO', 'pessoa', pattern, conversation_id
                )
                extracted.append({'category': 'RELACIONAMENTO', 'key': 'pessoa', 'value': pattern})
        
        if extracted:
            logger.info(f"‚úÖ Extra√≠dos {len(extracted)} fatos de: {user_input[:50]}...")
        
        return extracted
    
    def _save_or_update_fact(self, user_id: str, category: str, key: str, 
                            value: str, conversation_id: int):
        """Salva ou atualiza fato (com versionamento)"""
        cursor = self.conn.cursor()
        
        # Verificar se fato j√° existe
        cursor.execute("""
            SELECT id, fact_value FROM user_facts
            WHERE user_id = ? AND fact_category = ? AND fact_key = ? AND is_current = 1
        """, (user_id, category, key))
        
        existing = cursor.fetchone()
        
        if existing:
            # Se valor mudou, criar nova vers√£o
            if existing['fact_value'] != value:
                # Desativar vers√£o antiga
                cursor.execute("""
                    UPDATE user_facts SET is_current = 0 WHERE id = ?
                """, (existing['id'],))
                
                # Criar nova vers√£o
                cursor.execute("""
                    INSERT INTO user_facts
                    (user_id, fact_category, fact_key, fact_value, 
                     source_conversation_id, version)
                    SELECT user_id, fact_category, fact_key, ?, ?, version + 1
                    FROM user_facts WHERE id = ?
                """, (value, conversation_id, existing['id']))
        else:
            # Criar fato novo
            cursor.execute("""
                INSERT INTO user_facts
                (user_id, fact_category, fact_key, fact_value, source_conversation_id)
                VALUES (?, ?, ?, ?, ?)
            """, (user_id, category, key, value, conversation_id))
        
        self.conn.commit()
    
    # ========================================
    # DETEC√á√ÉO DE PADR√ïES
    # ========================================
    
    def detect_and_save_patterns(self, user_id: str):
        """
        Analisa conversas do usu√°rio e detecta padr√µes recorrentes
        
        Usa busca sem√¢ntica para agrupar temas similares
        """
        
        if not self.chroma_enabled:
            logger.warning("ChromaDB desabilitado. Detec√ß√£o de padr√µes limitada.")
            return
        
        cursor = self.conn.cursor()
        
        # Buscar keywords √∫nicas do usu√°rio
        cursor.execute("""
            SELECT DISTINCT keywords FROM conversations
            WHERE user_id = ? AND keywords IS NOT NULL AND keywords != ''
        """, (user_id,))
        
        all_keywords = set()
        for row in cursor.fetchall():
            all_keywords.update(row['keywords'].split(','))
        
        # Para cada tema, buscar conversas relacionadas
        for theme in list(all_keywords)[:20]:  # Limitar a 20 temas mais relevantes
            theme = theme.strip()
            if not theme or len(theme) < 3:
                continue
            
            related = self.semantic_search(user_id, theme, k=10)
            
            # Se h√° m√∫ltiplas conversas sobre o tema (padr√£o recorrente)
            if len(related) >= 3:
                conv_ids = [m['conversation_id'] for m in related]
                
                # Verificar se padr√£o j√° existe
                cursor.execute("""
                    SELECT id FROM user_patterns
                    WHERE user_id = ? AND pattern_name = ?
                """, (user_id, f"tema_{theme}"))
                
                existing = cursor.fetchone()
                
                if existing:
                    # Atualizar
                    cursor.execute("""
                        UPDATE user_patterns
                        SET frequency_count = ?,
                            last_occurrence_at = CURRENT_TIMESTAMP,
                            supporting_conversation_ids = ?,
                            confidence_score = ?
                        WHERE id = ?
                    """, (
                        len(related),
                        json.dumps(conv_ids),
                        min(1.0, len(related) * 0.15),
                        existing['id']
                    ))
                else:
                    # Criar
                    cursor.execute("""
                        INSERT INTO user_patterns
                        (user_id, pattern_type, pattern_name, pattern_description,
                         frequency_count, supporting_conversation_ids, confidence_score)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        user_id,
                        'TEM√ÅTICO',
                        f"tema_{theme}",
                        f"Usu√°rio frequentemente menciona: {theme}",
                        len(related),
                        json.dumps(conv_ids),
                        min(1.0, len(related) * 0.15)
                    ))
        
        self.conn.commit()
        logger.info(f"‚úÖ Padr√µes detectados para usu√°rio {user_id}")
    
    # ========================================
    # DESENVOLVIMENTO DO AGENTE
    # ========================================
    
    def _update_agent_development(self):
        """Atualiza m√©tricas de desenvolvimento do agente"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            UPDATE agent_development
            SET total_interactions = total_interactions + 1,
                self_awareness_score = MIN(1.0, self_awareness_score + 0.001),
                moral_complexity_score = MIN(1.0, moral_complexity_score + 0.0008),
                emotional_depth_score = MIN(1.0, emotional_depth_score + 0.0012),
                autonomy_score = MIN(1.0, autonomy_score + 0.0005),
                depth_level = (self_awareness_score + moral_complexity_score + emotional_depth_score) / 3,
                autonomy_level = autonomy_score,
                last_updated = CURRENT_TIMESTAMP
            WHERE id = 1
        """)
        
        self.conn.commit()
        self._check_phase_progression()
    
    def _check_phase_progression(self):
        """Verifica se agente deve progredir de fase"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM agent_development WHERE id = 1")
        state = dict(cursor.fetchone())
        
        avg_score = (
            state['self_awareness_score'] +
            state['moral_complexity_score'] +
            state['emotional_depth_score'] +
            state['autonomy_score']
        ) / 4
        
        new_phase = min(5, int(avg_score * 5) + 1)
        
        if new_phase > state['phase']:
            cursor.execute("UPDATE agent_development SET phase = ? WHERE id = 1", (new_phase,))
            
            cursor.execute("""
                INSERT INTO milestones (milestone_type, description, phase, interaction_count)
                VALUES (?, ?, ?, ?)
            """, (
                "phase_progression",
                f"Progress√£o para Fase {new_phase}",
                new_phase,
                state['total_interactions']
            ))
            
            self.conn.commit()
            logger.info(f"üéØ AGENTE PROGREDIU PARA FASE {new_phase}!")
    
    def get_agent_state(self) -> Dict:
        """Retorna estado atual do agente"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM agent_development WHERE id = 1")
        return dict(cursor.fetchone())
    
    def get_milestones(self, limit: int = 20) -> List[Dict]:
        """Busca milestones recentes"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM milestones
            ORDER BY timestamp DESC
            LIMIT ?
        """, (limit,))
        return [dict(row) for row in cursor.fetchall()]
    
    # ========================================
    # CONFLITOS
    # ========================================
    
    def get_user_conflicts(self, user_id: str, limit: int = 10) -> List[Dict]:
        """Busca conflitos do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM archetype_conflicts
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, limit))
        return [dict(row) for row in cursor.fetchall()]
    
    # ========================================
    # AN√ÅLISES COMPLETAS
    # ========================================
    
    def save_full_analysis(self, user_id: str, user_name: str, 
                          analysis: Dict, platform: str = "telegram") -> int:
        """Salva an√°lise completa"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            INSERT INTO full_analyses
            (user_id, user_name, mbti, dominant_archetypes, phase, full_analysis, platform)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id, user_name,
            analysis.get('mbti', 'N/A'),
            json.dumps(analysis.get('archetypes', [])),
            analysis.get('phase', 1),
            analysis.get('insights', ''),
            platform
        ))
        
        self.conn.commit()
        return cursor.lastrowid
    
    def get_user_analyses(self, user_id: str) -> List[Dict]:
        """Retorna an√°lises completas do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM full_analyses
            WHERE user_id = ?
            ORDER BY timestamp DESC
        """, (user_id,))
        return [dict(row) for row in cursor.fetchall()]
    
    # ========================================
    # UTILIT√ÅRIOS
    # ========================================
    
    def get_all_users(self, platform: str = None) -> List[Dict]:
        """Retorna todos os usu√°rios"""
        cursor = self.conn.cursor()
        
        if platform:
            cursor.execute("""
                SELECT u.*, COUNT(c.id) as total_messages
                FROM users u
                LEFT JOIN conversations c ON u.user_id = c.user_id
                WHERE u.platform = ?
                GROUP BY u.user_id
                ORDER BY u.last_seen DESC
            """, (platform,))
        else:
            cursor.execute("""
                SELECT u.*, COUNT(c.id) as total_messages
                FROM users u
                LEFT JOIN conversations c ON u.user_id = c.user_id
                GROUP BY u.user_id
                ORDER BY u.last_seen DESC
            """)
        
        return [dict(row) for row in cursor.fetchall()]
    
    def count_memories(self, user_id: str) -> int:
        """Conta mem√≥rias do usu√°rio"""
        return self.count_conversations(user_id)
    
    def close(self):
        """Fecha conex√µes"""
        self.conn.close()
        logger.info("‚úÖ Banco de dados fechado")

# ============================================================
# DETECTOR DE CONFLITOS
# ============================================================

class ConflictDetector:
    """Detecta e gerencia conflitos internos entre arqu√©tipos"""
    
    def __init__(self):
        self.opposing_directions = {
            'confrontar': ['acolher', 'validar', 'proteger'],
            'desafiar': ['apoiar', 'validar', 'confortar'],
            'questionar': ['aceitar', 'validar', 'confirmar'],
            'provocar': ['suavizar', 'acolher', 'acalmar'],
            'expor': ['proteger', 'ocultar', 'resguardar']
        }
    
    def detect_conflicts(self, archetype_analyses: Dict[str, ArchetypeInsight]) -> List[ArchetypeConflict]:
        """Detecta conflitos entre as posi√ß√µes dos arqu√©tipos"""
        
        conflicts = []
        archetype_names = list(archetype_analyses.keys())
        
        for i in range(len(archetype_names)):
            for j in range(i + 1, len(archetype_names)):
                arch1_name = archetype_names[i]
                arch2_name = archetype_names[j]
                
                arch1 = archetype_analyses[arch1_name]
                arch2 = archetype_analyses[arch2_name]
                
                direction1 = arch1.suggested_response_direction.lower()
                direction2 = arch2.suggested_response_direction.lower()
                
                is_conflicting = False
                conflict_type = ""
                
                # Verificar oposi√ß√µes
                if direction1 in self.opposing_directions:
                    if direction2 in self.opposing_directions[direction1]:
                        is_conflicting = True
                        conflict_type = f"{direction1}_vs_{direction2}"
                
                if direction2 in self.opposing_directions:
                    if direction1 in self.opposing_directions[direction2]:
                        is_conflicting = True
                        conflict_type = f"{direction2}_vs_{direction1}"
                
                # Conflitos espec√≠ficos
                if (arch1_name.lower() == "persona" and arch2_name.lower() == "sombra") or \
                   (arch1_name.lower() == "sombra" and arch2_name.lower() == "persona"):
                    if direction1 != direction2:
                        is_conflicting = True
                        conflict_type = "persona_sombra_clash"
                
                if is_conflicting:
                    tension_level = self._calculate_tension(arch1, arch2)
                    
                    conflict = ArchetypeConflict(
                        archetype_1=arch1_name,
                        archetype_2=arch2_name,
                        conflict_type=conflict_type,
                        archetype_1_position=f"{arch1.suggested_stance} ({direction1})",
                        archetype_2_position=f"{arch2.suggested_stance} ({direction2})",
                        tension_level=tension_level,
                        description=f"Tens√£o entre {arch1_name} ({direction1}) e {arch2_name} ({direction2})"
                    )
                    
                    conflicts.append(conflict)
                    logger.info(f"‚ö° CONFLITO: {arch1_name} vs {arch2_name} (tens√£o: {tension_level:.2f})")
        
        return conflicts
    
    def _calculate_tension(self, arch1: ArchetypeInsight, arch2: ArchetypeInsight) -> float:
        """Calcula n√≠vel de tens√£o entre dois arqu√©tipos"""
        direction1 = arch1.suggested_response_direction.lower()
        direction2 = arch2.suggested_response_direction.lower()
        
        high_tension_words = ['confrontar', 'desafiar', 'expor', 'provocar']
        low_tension_words = ['acolher', 'validar', 'proteger', 'suavizar']
        
        tension = 0.5
        
        if direction1 in high_tension_words and direction2 in low_tension_words:
            tension = 0.9
        elif direction1 in low_tension_words and direction2 in high_tension_words:
            tension = 0.9
        elif direction1 in high_tension_words and direction2 in high_tension_words:
            tension = 0.3
        elif direction1 in low_tension_words and direction2 in low_tension_words:
            tension = 0.2
        
        return tension

# ============================================================
# JUNGIAN ENGINE (Motor principal)
# ============================================================

class JungianEngine:
    """Motor de an√°lise junguiana com sistema de conflitos arquet√≠picos"""
    
    def __init__(self, db: HybridDatabaseManager = None):
        """Inicializa engine (db opcional para compatibilidade)"""
        
        self.db = db if db else HybridDatabaseManager()
        
        # Clientes LLM
        self.openai_client = OpenAI(api_key=Config.OPENAI_API_KEY)
        self.xai_client = OpenAI(
            api_key=Config.XAI_API_KEY,
            base_url="https://api.x.ai/v1"
        )
        
        self.conflict_detector = ConflictDetector()
        
        self.archetype_prompts = {
            "Persona": Config.PERSONA_PROMPT,
            "Sombra": Config.SOMBRA_PROMPT,
            "Velho S√°bio": Config.SABIO_PROMPT,
            "Anima": Config.ANIMA_PROMPT
        }
        
        logger.info("‚úÖ JungianEngine inicializado")
    
    def process_message(self, user_id: str, message: str, 
                       model: str = "grok-4-fast-reasoning",
                       chat_history: List[Dict] = None) -> Dict:
        """
        PROCESSAMENTO COMPLETO:
        1. Busca sem√¢ntica (ChromaDB)
        2. An√°lise arquet√≠pica (Grok)
        3. Detec√ß√£o de conflitos
        4. Gera√ß√£o de resposta
        5. Salvamento (SQLite + ChromaDB)
        
        Args:
            user_id: ID do usu√°rio
            message: Mensagem do usu√°rio
            model: Modelo LLM (padr√£o: grok-4-fast-reasoning)
            chat_history: Hist√≥rico da conversa atual (opcional)
        
        Returns:
            Dict com response, conflicts, conversation_count, tension_level
        """
        
        logger.info(f"{'='*60}")
        logger.info(f"üß† PROCESSANDO MENSAGEM")
        logger.info(f"{'='*60}")
        
        # Buscar usu√°rio
        user = self.db.get_user(user_id)
        user_name = user['user_name'] if user else "Usu√°rio"
        platform = user['platform'] if user else "telegram"
        
        # Construir contexto sem√¢ntico
        logger.info("üîç Construindo contexto sem√¢ntico...")
        semantic_context = self.db.build_rich_context(
            user_id, message, k_memories=5, chat_history=chat_history
        )
        
        # An√°lise arquet√≠pica
        logger.info("üîµ Analisando com arqu√©tipos...")
        archetype_analyses = {}
        
        for archetype_name, archetype_prompt in self.archetype_prompts.items():
            logger.info(f"  ‚Ä¢ {archetype_name}...")
            analysis = self._analyze_with_archetype(
                archetype_name, archetype_prompt, message, 
                semantic_context, chat_history, model
            )
            archetype_analyses[archetype_name] = analysis
            logger.info(f"    ‚Üí Dire√ß√£o: {analysis.suggested_response_direction}")
        
        # Detectar conflitos
        logger.info("‚ö° Detectando conflitos internos...")
        conflicts = self.conflict_detector.detect_conflicts(archetype_analyses)
        
        # Determinar complexidade
        complexity = self._determine_complexity(message)
        
        # Gerar resposta
        if conflicts:
            logger.info(f"‚ö° {len(conflicts)} conflito(s) detectado(s)")
            response = self._generate_conflicted_response(
                message, semantic_context, archetype_analyses, 
                conflicts, complexity, chat_history, model
            )
            tension_level = max([c.tension_level for c in conflicts])
        else:
            logger.info("‚úÖ Sem conflitos - resposta harm√¥nica")
            response = self._generate_harmonious_response(
                message, semantic_context, archetype_analyses, 
                complexity, chat_history, model
            )
            tension_level = 0.0
        
        # Calcular m√©tricas
        affective_charge = self._calculate_affective_charge(message, response)
        existential_depth = self._calculate_existential_depth(message)
        intensity_level = int(affective_charge / 10)
        keywords = self._extract_keywords(message, response)
        
        # Salvar conversa (SQLite + ChromaDB)
        conversation_id = self.db.save_conversation(
            user_id=user_id,
            user_name=user_name,
            user_input=message,
            ai_response=response,
            archetype_analyses=archetype_analyses,
            detected_conflicts=conflicts,
            tension_level=tension_level,
            affective_charge=affective_charge,
            existential_depth=existential_depth,
            intensity_level=intensity_level,
            complexity=complexity,
            keywords=keywords,
            platform=platform,
            chat_history=chat_history
        )
        
        logger.info(f"‚úÖ Processamento completo (ID={conversation_id})")
        logger.info(f"{'='*60}\n")
        
        # Resultado
        result = {
            'response': response,
            'conflicts': conflicts,
            'conversation_count': self.db.count_conversations(user_id),
            'tension_level': tension_level,
            'affective_charge': affective_charge,
            'existential_depth': existential_depth,
            'conversation_id': conversation_id,
            'conflict': None
        }
        
        if conflicts:
            first_conflict = conflicts[0]
            result['conflict'] = {
                'archetype1': first_conflict.archetype_1,
                'archetype2': first_conflict.archetype_2,
                'trigger': first_conflict.description
            }
        
        return result
    
    # ========================================
    # M√âTODOS AUXILIARES
    # ========================================
    
    def _analyze_with_archetype(self, archetype_name: str, archetype_prompt: str,
                               user_input: str, semantic_context: str,
                               chat_history: List[Dict], model: str) -> ArchetypeInsight:
        """Analisa mensagem com um arqu√©tipo espec√≠fico"""
        
        # Formatar hist√≥rico
        history_text = ""
        if chat_history:
            for msg in chat_history[-6:]:
                role = "Usu√°rio" if msg["role"] == "user" else "Assistente"
                history_text += f"{role}: {msg['content'][:100]}...\n"
        
        prompt = Config.ARCHETYPE_ANALYSIS_PROMPT.format(
            archetype_prompt=archetype_prompt,
            semantic_context=semantic_context[:1500],
            user_input=user_input,
            chat_history=history_text
        )
        
        try:
            if model.startswith("grok"):
                completion = self.xai_client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=1500
                )
            else:
                completion = self.openai_client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=1500
                )
            
            response_text = completion.choices[0].message.content
            
            # Extrair JSON
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                analysis_dict = json.loads(json_match.group())
            else:
                analysis_dict = {
                    "insight_text": response_text,
                    "key_observations": [],
                    "emotional_reading": "N/A",
                    "shadow_reading": "N/A",
                    "wisdom_perspective": "N/A",
                    "suggested_stance": "neutro",
                    "suggested_response_direction": "acolher"
                }
            
            return ArchetypeInsight(
                archetype_name=archetype_name,
                insight_text=analysis_dict.get("insight_text", ""),
                key_observations=analysis_dict.get("key_observations", []),
                emotional_reading=analysis_dict.get("emotional_reading", ""),
                shadow_reading=analysis_dict.get("shadow_reading", ""),
                wisdom_perspective=analysis_dict.get("wisdom_perspective", ""),
                suggested_stance=analysis_dict.get("suggested_stance", "neutro"),
                suggested_response_direction=analysis_dict.get("suggested_response_direction", "acolher")
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise do {archetype_name}: {e}")
            return ArchetypeInsight(
                archetype_name=archetype_name,
                insight_text=f"Erro: {str(e)}",
                key_observations=[],
                emotional_reading="N/A",
                shadow_reading="N/A",
                wisdom_perspective="N/A",
                suggested_stance="neutro",
                suggested_response_direction="acolher"
            )
    
    def _generate_conflicted_response(self, user_input: str, semantic_context: str,
                                     archetype_analyses: Dict[str, ArchetypeInsight],
                                     conflicts: List[ArchetypeConflict],
                                     complexity: str,
                                     chat_history: List[Dict],
                                     model: str) -> str:
        """Gera resposta que EXPRESSA o conflito interno"""
        
        # Formatar hist√≥rico
        history_text = ""
        if chat_history:
            for msg in chat_history[-6:]:
                role = "Usu√°rio" if msg["role"] == "user" else "Assistente"
                history_text += f"{role}: {msg['content'][:100]}...\n"
        
        conflict_description = ""
        for conflict in conflicts:
            arch1 = archetype_analyses[conflict.archetype_1]
            arch2 = archetype_analyses[conflict.archetype_2]
            
            conflict_description += f"""
CONFLITO: {conflict.archetype_1} vs {conflict.archetype_2}
- {conflict.archetype_1}: {arch1.insight_text[:150]}... ‚Üí {arch1.suggested_response_direction}
- {conflict.archetype_2}: {arch2.insight_text[:150]}... ‚Üí {arch2.suggested_response_direction}
Tens√£o: {conflict.tension_level:.2f}
"""
        
        prompt = Config.CONFLICTED_RESPONSE_PROMPT.format(
            semantic_context=semantic_context[:1000],
            chat_history=history_text,
            user_input=user_input,
            conflict_description=conflict_description,
            complexity=complexity
        )
        
        try:
            if model.startswith("grok"):
                completion = self.xai_client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.8
                )
            else:
                completion = self.openai_client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.8
                )
            
            return completion.choices[0].message.content
        
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar resposta conflituosa: {e}")
            return "Desculpe, tive dificuldades para processar isso."
    
    def _generate_harmonious_response(self, user_input: str, semantic_context: str,
                                     archetype_analyses: Dict[str, ArchetypeInsight],
                                     complexity: str,
                                     chat_history: List[Dict],
                                     model: str) -> str:
        """Gera resposta harmoniosa"""
        
        # Formatar hist√≥rico
        history_text = ""
        if chat_history:
            for msg in chat_history[-6:]:
                role = "Usu√°rio" if msg["role"] == "user" else "Assistente"
                history_text += f"{role}: {msg['content'][:100]}...\n"
        
        analyses_summary = ""
        for name, analysis in archetype_analyses.items():
            analyses_summary += f"\n{name}: {analysis.insight_text[:150]}..."
        
        prompt = Config.HARMONIOUS_RESPONSE_PROMPT.format(
            analyses_summary=analyses_summary,
            semantic_context=semantic_context[:1000],
            chat_history=history_text,
            user_input=user_input,
            complexity=complexity
        )
        
        try:
            if model.startswith("grok"):
                completion = self.xai_client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
            else:
                completion = self.openai_client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
            
            return completion.choices[0].message.content
        
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar resposta harmoniosa: {e}")
            return "Desculpe, tive dificuldades para processar isso."
    
    def _determine_complexity(self, user_input: str) -> str:
        """Determina complexidade da mensagem"""
        word_count = len(user_input.split())
        
        if word_count <= 3:
            return "simple"
        elif word_count > 15:
            return "complex"
        else:
            return "medium"
    
    def _calculate_affective_charge(self, user_input: str, response: str) -> float:
        """Calcula carga afetiva"""
        emotional_words = [
            "amor", "√≥dio", "medo", "alegria", "tristeza", "raiva", "ansiedade",
            "feliz", "triste", "nervoso", "calmo", "confuso", "frustrado"
        ]
        
        text = (user_input + " " + response).lower()
        count = sum(1 for word in emotional_words if word in text)
        
        return min(count * 10, 100)
    
    def _calculate_existential_depth(self, user_input: str) -> float:
        """Calcula profundidade existencial"""
        depth_words = [
            "sentido", "prop√≥sito", "sozinho", "perdido", "real", "aut√™ntic",
            "verdadeir", "profundo", "√≠ntimo", "medo", "vulner√°vel"
        ]
        
        text = user_input.lower()
        count = sum(1 for word in depth_words if word in text)
        
        return min(count * 0.15, 1.0)
    
    def _extract_keywords(self, user_input: str, response: str) -> List[str]:
        """Extrai palavras-chave"""
        text = (user_input + " " + response).lower()
        words = text.split()
        
        stopwords = {
            "o", "a", "de", "que", "e", "do", "da", "em", "um", "para", 
            "√©", "com", "n√£o", "uma", "os", "no", "se", "na", "por"
        }
        
        keywords = [w for w in words if len(w) > 3 and w not in stopwords and w.isalpha()]
        
        return [word for word, _ in Counter(keywords).most_common(5)]

# ============================================================
# FUN√á√ïES AUXILIARES (COMPATIBILIDADE)
# ============================================================

def send_to_xai(prompt: str, model: str = "grok-4-fast-reasoning", 
                temperature: float = 0.7, max_tokens: int = 2000) -> str:
    """
    Envia prompt para API X.AI e retorna resposta
    (Fun√ß√£o auxiliar para compatibilidade)
    """
    
    xai_api_key = os.getenv("XAI_API_KEY")
    
    if not xai_api_key:
        raise ValueError("XAI_API_KEY n√£o encontrado no ambiente")
    
    try:
        client = OpenAI(
            api_key=xai_api_key,
            base_url="https://api.x.ai/v1"
        )
        
        completion = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        return completion.choices[0].message.content
        
    except Exception as e:
        raise Exception(f"Erro ao chamar X.AI API: {e}")

def create_user_hash(identifier: str) -> str:
    """Cria hash √∫nico para usu√°rio"""
    return hashlib.sha256(identifier.encode()).hexdigest()[:16]

def format_conflict_for_display(conflict: Dict) -> str:
    """Formata conflito para exibi√ß√£o"""
    arch1 = conflict.get('archetype1', 'Arqu√©tipo 1')
    arch2 = conflict.get('archetype2', 'Arqu√©tipo 2')
    trigger = conflict.get('trigger', 'N√£o especificado')
    
    emoji_map = {
        'persona': 'üé≠',
        'sombra': 'üåë',
        'velho s√°bio': 'üßô',
        'velho_sabio': 'üßô',
        'anima': 'üí´'
    }
    
    emoji1 = emoji_map.get(arch1.lower(), '‚ùì')
    emoji2 = emoji_map.get(arch2.lower(), '‚ùì')
    
    return f"{emoji1} **{arch1.title()}** vs {emoji2} **{arch2.title()}**\nüéØ _{trigger}_"

def format_archetype_info(archetype_name: str) -> str:
    """Formata informa√ß√µes de um arqu√©tipo"""
    archetype = Config.ARCHETYPES.get(archetype_name)
    
    if not archetype:
        return f"‚ùì Arqu√©tipo '{archetype_name}' n√£o encontrado."
    
    emoji = archetype.get('emoji', '‚ùì')
    description = archetype.get('description', 'Sem descri√ß√£o')
    tendency = archetype.get('tendency', 'N/A')
    shadow = archetype.get('shadow', 'N/A')
    keywords = archetype.get('keywords', [])
    
    return f"""
{emoji} **{archetype_name.upper()}**

üìñ **Descri√ß√£o:**
{description}

‚ö° **Tend√™ncia:**
{tendency}

üåë **Sombra:**
{shadow}

üîë **Palavras-chave:**
{', '.join(keywords)}
""".strip()

# ============================================================
# ALIASES DE COMPATIBILIDADE
# ============================================================

# Alias para compatibilidade com c√≥digo legado
DatabaseManager = HybridDatabaseManager

# ============================================================
# INICIALIZA√á√ÉO
# ============================================================

try:
    Config.validate()
    logger.info("‚úÖ jung_core.py v4.0 - H√çBRIDO PREMIUM")
    logger.info(f"   ChromaDB: {'ATIVO' if CHROMADB_AVAILABLE else 'INATIVO'}")
    logger.info(f"   OpenAI Embeddings: {'ATIVO' if Config.OPENAI_API_KEY else 'INATIVO'}")
except ValueError as e:
    logger.error(f"‚ö†Ô∏è  {e}")

if __name__ == "__main__":
    logger.info("üß† Jung Core v4.0 - H√çBRIDO PREMIUM")
    logger.info("=" * 60)
    
    db = HybridDatabaseManager()
    logger.info("‚úÖ HybridDatabaseManager inicializado")
    
    engine = JungianEngine(db)
    logger.info("‚úÖ JungianEngine inicializado")
    
    logger.info("\nüìä Estat√≠sticas:")
    logger.info(f"  - Arqu√©tipos: {len(Config.ARCHETYPES)}")
    logger.info(f"  - SQLite: {Config.SQLITE_PATH}")
    logger.info(f"  - ChromaDB: {Config.CHROMA_PATH}")
    
    agent_state = db.get_agent_state()
    logger.info(f"  - Fase: {agent_state['phase']}/5")
    logger.info(f"  - Intera√ß√µes: {agent_state['total_interactions']}")
    
    # Teste
    logger.info("\nüß™ Testando send_to_xai...")
    try:
        test_response = send_to_xai("Diga apenas 'OK' se voc√™ est√° funcionando.", max_tokens=10)
        logger.info(f"‚úÖ send_to_xai funcionando: {test_response[:50]}...")
    except Exception as e:
        logger.error(f"‚ùå Erro ao testar send_to_xai: {e}")
    
    db.close()
    logger.info("\n‚úÖ Teste conclu√≠do!")