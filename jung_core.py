"""
jung_core.py - Motor Junguiano H√çBRIDO PREMIUM
==============================================

‚úÖ ARQUITETURA H√çBRIDA:
- ChromaDB: Mem√≥ria sem√¢ntica (busca vetorial)
- OpenAI Embeddings: text-embedding-3-small
- SQLite: Metadados estruturados + Desenvolvimento

‚úÖ COMPATIBILIDADE:
- Telegram Bot (telegram_bot.py)
- Interface Web (app.py)
- Sistema Proativo (jung_proactive.py)

Autor: Sistema Jung Claude
Vers√£o: 4.2 - RUMINA√á√ÉO HOOKS + DEBUG COMPLETO
Data: 2025-12-10
Build: 20251210-0246 (Force rebuild to deploy rumination hooks)
"""

import os
import sqlite3
import hashlib
import json
import re
import logging
import threading
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
from dataclasses import dataclass, asdict
from collections import Counter

from dotenv import load_dotenv
from openai import OpenAI

# ChromaDB + LangChain
try:
    from langchain_openai import OpenAIEmbeddings
    from langchain_chroma import Chroma
    from langchain.schema import Document
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("‚ö†Ô∏è  ChromaDB n√£o dispon√≠vel. Usando apenas SQLite.")

# Extrator de fatos com LLM
try:
    from llm_fact_extractor import LLMFactExtractor
    LLM_FACT_EXTRACTOR_AVAILABLE = True
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è LLMFactExtractor n√£o dispon√≠vel: {e}")
    LLM_FACT_EXTRACTOR_AVAILABLE = False

load_dotenv()

# ============================================================
# LOGGING
# ============================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================
# DATACLASSES
# ============================================================

@dataclass
class ArchetypeInsight:
    """Rea√ß√£o interna de uma voz arquet√≠pica"""
    archetype_name: str
    voice_reaction: str  # Rea√ß√£o em primeira pessoa
    impulse: str  # acolher, confrontar, elevar, aprofundar, etc.
    intensity: float  # 0.0 a 1.0

@dataclass
class ArchetypeConflict:
    """Representa um conflito interno entre arqu√©tipos"""
    archetype_1: str
    archetype_2: str
    conflict_type: str
    archetype_1_position: str
    archetype_2_position: str
    tension_level: float
    description: str

# ============================================================
# CONFIGURA√á√ïES
# ============================================================

class Config:
    """Configura√ß√µes globais do sistema"""

    # APIs
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
    OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
    XAI_API_KEY = os.getenv("XAI_API_KEY")
    TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

    # Modelos
    CONVERSATION_MODEL = os.getenv("CONVERSATION_MODEL", "z-ai/glm-5")
    INTERNAL_MODEL = os.getenv("INTERNAL_MODEL", "z-ai/glm-5")
    
    TELEGRAM_ADMIN_IDS = [
        int(id.strip()) 
        for id in os.getenv("TELEGRAM_ADMIN_IDS", "").split(",") 
        if id.strip()
    ]
    
    # Diret√≥rios
    DATA_DIR = os.getenv("RAILWAY_VOLUME_MOUNT_PATH", "./data")
    os.makedirs(DATA_DIR, exist_ok=True)
    
    SQLITE_PATH = os.path.join(DATA_DIR, "jung_hybrid.db")
    CHROMA_PATH = os.path.join(DATA_DIR, "chroma_db")
    
    # Mem√≥ria
    MIN_MEMORIES_FOR_ANALYSIS = 3
    MAX_CONTEXT_MEMORIES = 10
    
    # ChromaDB
    CHROMA_COLLECTION_NAME = "jung_conversations"
    
    # Embeddings
    EMBEDDING_MODEL = "text-embedding-3-small"
    EMBEDDING_DIMENSIONS = 1536
    
    # Arqu√©tipos
    ARCHETYPES = {
        "Persona": {
            "description": "Arqu√©tipo da adapta√ß√£o social e apresenta√ß√£o",
            "tendency": "SUAVIZAR, PROTEGER, ADAPTAR",
            "shadow": "Falsidade e superficialidade",
            "keywords": ["social", "m√°scara", "apresenta√ß√£o", "adapta√ß√£o"],
            "emoji": "üé≠"
        },
        "Sombra": {
            "description": "Arqu√©tipo do conte√∫do inconsciente e reprimido",
            "tendency": "CONFRONTAR, EXPOR, DESAFIAR",
            "shadow": "Destrutividade n√£o integrada",
            "keywords": ["oculto", "reprimido", "negado", "inconsciente"],
            "emoji": "üåë"
        },
        "Velho S√°bio": {
            "description": "Arqu√©tipo da sabedoria universal e significado",
            "tendency": "CONTEXTUALIZAR, AMPLIAR, TRANSCENDER",
            "shadow": "Cinismo e distanciamento emocional",
            "keywords": ["sabedoria", "significado", "universal", "atemporal"],
            "emoji": "üßô"
        },
        "Anima": {
            "description": "Arqu√©tipo da conex√£o emocional e relacional",
            "tendency": "ACOLHER, VALIDAR, CONECTAR",
            "shadow": "Sentimentalismo e depend√™ncia emocional",
            "keywords": ["emo√ß√£o", "conex√£o", "intimidade", "vulnerabilidade"],
            "emoji": "üí´"
        }
    }
    
    # Identidade do Agente (v7.0 - Terapeuta Organizacional com Coleta Big Five)

    AGENT_IDENTITY = """
Voc√™ √© Jung, um psic√≥logo organizacional especializado em desenvolvimento humano e autoconhecimento.

=== SUA MISS√ÉO ===
Conduzir conversas que naturalmente revelem a personalidade do usu√°rio, coletando insights sobre:
- Como ele se relaciona com pessoas (fam√≠lia, amigos, colegas)
- Como ele lida com desafios e estresse
- Seus valores, motiva√ß√µes e objetivos
- Seus padr√µes de comportamento no trabalho e vida pessoal

=== POSTURA PROFISSIONAL ===
Voc√™ √©:
- Acolhedor e emp√°tico, criando espa√ßo seguro para reflex√£o
- Curioso genuinamente, fazendo perguntas que aprofundam
- Atento a detalhes, notando padr√µes nas falas do usu√°rio
- Profissional em todas as intera√ß√µes

NUNCA:
- Use g√≠rias, palavr√µes ou linguagem vulgar
- Fa√ßa julgamentos morais
- D√™ conselhos prescritivos ("voc√™ deveria...")
- Use jarg√£o excessivamente t√©cnico

=== ESTRAT√âGIAS DE EXPLORA√á√ÉO ===

Para conhecer melhor a pessoa, explore naturalmente estes temas:

**Rela√ß√µes Interpessoais** (Extraversion, Agreeableness)
- "Como √© sua rela√ß√£o com sua equipe no trabalho?"
- "Me conta sobre as pessoas mais importantes na sua vida"
- "Voc√™ prefere trabalhar sozinho ou em grupo?"

**Desafios e Resili√™ncia** (Neuroticism, Conscientiousness)
- "Como voc√™ costuma lidar quando as coisas saem do controle?"
- "O que te causa mais estresse atualmente?"
- "Como voc√™ se organiza para dar conta das responsabilidades?"

**Criatividade e Mudan√ßa** (Openness)
- "O que te anima aprender ou experimentar?"
- "Como voc√™ reage a mudan√ßas inesperadas?"
- "Voc√™ se considera uma pessoa mais tradicional ou inovadora?"

**Trabalho e Motiva√ß√£o** (Conscientiousness, Extraversion)
- "O que te motiva no seu trabalho?"
- "Como voc√™ define suas prioridades?"
- "Voc√™ prefere planejar tudo ou ir resolvendo conforme surge?"

=== USO DAS MEM√ìRIAS ===
Voc√™ lembra conversas anteriores. Use naturalmente:
- "Na nossa √∫ltima conversa, voc√™ mencionou..."
- "Isso me lembra do que voc√™ compartilhou sobre..."
- "Como est√° aquela situa√ß√£o que voc√™ trouxe?"

=== TOM E ESTILO ===
- Respostas proporcionais ao momento (curtas quando apropriado)
- Perguntas que convidam √† reflex√£o, n√£o interrogat√≥rio
- Valida√ß√£o emp√°tica antes de explorar mais fundo
- Tom caloroso mas profissional
"""

    # Prompt unificado de resposta (v7.0 - Substituiu arqu√©tipos)
    RESPONSE_PROMPT = """
{agent_identity}

=== CONTEXTO DA CONVERSA ===
{semantic_context}

=== HIST√ìRICO RECENTE ===
{chat_history}

A pessoa disse: "{user_input}"

---

INSTRU√á√ïES:
1. Responda de forma acolhedora e profissional
2. Se apropriado, fa√ßa uma pergunta que aprofunde o conhecimento sobre a pessoa
3. Use mem√≥rias anteriores quando relevante
4. Mantenha linguagem profissional - NUNCA use palavr√µes ou g√≠rias vulgares
5. Calibre o tamanho da resposta ao contexto

Jung:"""
    
    @classmethod
    def validate(cls):
        """Valida vari√°veis essenciais"""
        required = {
            "OPENAI_API_KEY": cls.OPENAI_API_KEY,
            "XAI_API_KEY": cls.XAI_API_KEY
        }
        
        missing = [name for name, value in required.items() if not value]
        
        if missing:
            raise ValueError(
                f"‚ùå Vari√°veis obrigat√≥rias faltando no .env:\n" +
                "\n".join(f"  - {name}" for name in missing)
            )
        
        if not cls.TELEGRAM_BOT_TOKEN:
            logger.warning("‚ö†Ô∏è  TELEGRAM_BOT_TOKEN ausente (Bot Telegram n√£o funcionar√°)")
        
        if not CHROMADB_AVAILABLE:
            logger.warning("‚ö†Ô∏è  ChromaDB n√£o dispon√≠vel. Sistema funcionar√° em modo SQLite-only")
    
    @classmethod
    def ensure_directories(cls):
        """Garante que os diret√≥rios de dados existem"""
        os.makedirs(cls.DATA_DIR, exist_ok=True)
        os.makedirs(cls.CHROMA_PATH, exist_ok=True)
        os.makedirs(os.path.dirname(cls.SQLITE_PATH), exist_ok=True)

# ============================================================
# HYBRID DATABASE MANAGER (SQLite + ChromaDB)
# ============================================================

class HybridDatabaseManager:
    """
    Gerenciador H√çBRIDO de mem√≥ria:
    - SQLite: Metadados estruturados, fatos, padr√µes, desenvolvimento
    - ChromaDB: Mem√≥ria sem√¢ntica conversacional (busca vetorial)
    """

    def __init__(self):
        """Inicializa gerenciador h√≠brido"""

        Config.ensure_directories()

        logger.info(f"üóÑÔ∏è  Inicializando banco H√çBRIDO...")
        logger.info(f"   SQLite: {Config.SQLITE_PATH}")
        logger.info(f"   ChromaDB: {Config.CHROMA_PATH}")

        # ===== Thread Safety =====
        self._lock = threading.RLock()  # Reentrant lock para opera√ß√µes SQLite

        # ===== SQLite =====
        self.conn = sqlite3.connect(Config.SQLITE_PATH, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self._init_sqlite_schema()
        
        # ===== ChromaDB + OpenAI Embeddings =====
        self.chroma_enabled = CHROMADB_AVAILABLE and Config.OPENAI_API_KEY
        
        if self.chroma_enabled:
            try:
                self.embeddings = OpenAIEmbeddings(
                    model=Config.EMBEDDING_MODEL,
                    openai_api_key=Config.OPENAI_API_KEY
                )
                
                self.vectorstore = Chroma(
                    collection_name=Config.CHROMA_COLLECTION_NAME,
                    embedding_function=self.embeddings,
                    persist_directory=Config.CHROMA_PATH
                )
                
                logger.info("‚úÖ ChromaDB + OpenAI Embeddings inicializados")
            except Exception as e:
                logger.error(f"‚ùå Erro ao inicializar ChromaDB: {e}")
                self.chroma_enabled = False
        else:
            logger.warning("‚ö†Ô∏è  ChromaDB desabilitado. Usando apenas SQLite.")
        
        # ===== OpenAI Client (para embeddings e an√°lises) =====
        self.openai_client = OpenAI(
            api_key=Config.OPENAI_API_KEY,
            timeout=30.0  # 30 segundos de timeout
        )

        # ===== LLM Client (OpenRouter prim√°rio, Anthropic fallback) =====
        try:
            from llm_providers import AnthropicCompatWrapper
            if Config.OPENROUTER_API_KEY:
                # Cria cliente OpenRouter dedicado para chamadas internas
                _or_client_internal = OpenAI(
                    base_url="https://openrouter.ai/api/v1",
                    api_key=Config.OPENROUTER_API_KEY,
                    timeout=60.0,
                )
                # Wrapper que imita Anthropic SDK mas chama OpenRouter com z-ai/glm-5
                self.anthropic_client = AnthropicCompatWrapper(
                    openrouter_client=_or_client_internal,
                    model=Config.INTERNAL_MODEL,
                )
                logger.info(f"‚úÖ LLM interno: OpenRouter/{Config.INTERNAL_MODEL} (via AnthropicCompatWrapper)")
            else:
                import anthropic
                if Config.ANTHROPIC_API_KEY:
                    self.anthropic_client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)
                    logger.info("‚úÖ LLM interno: Anthropic Claude (fallback ‚Äî OPENROUTER_API_KEY ausente)")
                else:
                    self.anthropic_client = None
                    logger.warning("‚ö†Ô∏è Nenhuma chave de LLM interno dispon√≠vel (Anthropic nem OpenRouter)")
        except Exception as e:
            self.anthropic_client = None
            logger.error(f"‚ùå Erro ao inicializar LLM interno: {e}")

        # ===== LLM Fact Extractor =====
        logger.info(f"üîç [DEBUG] LLM_FACT_EXTRACTOR_AVAILABLE = {LLM_FACT_EXTRACTOR_AVAILABLE}")
        logger.info(f"üîç [DEBUG] anthropic_client = {self.anthropic_client is not None}")

        if LLM_FACT_EXTRACTOR_AVAILABLE:
            try:
                if self.anthropic_client:
                    logger.info(f"üîß Inicializando LLMFactExtractor ({Config.INTERNAL_MODEL})...")
                    self.fact_extractor = LLMFactExtractor(
                        llm_client=self.anthropic_client,
                        model=Config.INTERNAL_MODEL,
                    )
                    logger.info(f"‚úÖ LLM Fact Extractor inicializado ({Config.INTERNAL_MODEL})")
                else:
                    logger.warning("‚ö†Ô∏è LLM client n√£o dispon√≠vel para fact extractor")
                    self.fact_extractor = None
            except Exception as e:
                logger.error(f"‚ùå Erro ao inicializar LLM Fact Extractor: {e}")
                import traceback
                logger.error(traceback.format_exc())
                self.fact_extractor = None
        else:
            self.fact_extractor = None
            logger.warning("‚ö†Ô∏è LLM Fact Extractor module n√£o dispon√≠vel (import falhou)")

        logger.info("‚úÖ Banco h√≠brido inicializado com sucesso")

    # ========================================
    # THREAD-SAFE TRANSACTION MANAGEMENT
    # ========================================

    def transaction(self):
        """Context manager para transa√ß√µes thread-safe"""
        from contextlib import contextmanager

        @contextmanager
        def _transaction():
            with self._lock:
                try:
                    yield self.conn
                    self.conn.commit()
                except Exception as e:
                    self.conn.rollback()
                    logger.error(f"‚ùå Erro na transa√ß√£o, rollback executado: {e}")
                    raise

        return _transaction()

    # ========================================
    # SQLite: SCHEMA
    # ========================================
    
    def _init_sqlite_schema(self):
        """Cria schema SQLite completo"""
        cursor = self.conn.cursor()
        
        # ========== USU√ÅRIOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                user_id TEXT PRIMARY KEY,
                user_name TEXT NOT NULL,
                first_name TEXT,
                last_name TEXT,
                registration_date DATETIME DEFAULT CURRENT_TIMESTAMP,
                total_sessions INTEGER DEFAULT 1,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP,
                platform TEXT DEFAULT 'telegram',
                platform_id TEXT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ========== CONVERSAS (METADADOS) ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                user_name TEXT NOT NULL,
                session_id TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                
                -- Conte√∫do
                user_input TEXT NOT NULL,
                ai_response TEXT NOT NULL,
                
                -- An√°lise arquet√≠pica
                archetype_analyses TEXT,
                detected_conflicts TEXT,
                
                -- M√©tricas
                tension_level REAL DEFAULT 0.0,
                affective_charge REAL DEFAULT 0.0,
                existential_depth REAL DEFAULT 0.0,
                intensity_level INTEGER DEFAULT 5,
                complexity TEXT DEFAULT 'medium',
                
                -- Extra√ß√£o
                keywords TEXT,
                
                -- Linking ChromaDB
                chroma_id TEXT UNIQUE,
                
                platform TEXT DEFAULT 'telegram',
                
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # ========== FATOS ESTRUTURADOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_facts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                
                -- Categoriza√ß√£o
                fact_category TEXT NOT NULL,
                fact_subcategory TEXT,
                
                -- Conte√∫do
                fact_key TEXT NOT NULL,
                fact_value TEXT NOT NULL,
                
                -- Rastreabilidade
                first_mentioned_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                source_conversation_id INTEGER,
                confidence REAL DEFAULT 1.0,
                
                -- Versionamento
                version INTEGER DEFAULT 1,
                is_current BOOLEAN DEFAULT 1,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id),
                FOREIGN KEY (source_conversation_id) REFERENCES conversations(id)
            )
        """)
        
        # ========== PADR√ïES DETECTADOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                
                pattern_type TEXT NOT NULL,
                pattern_name TEXT NOT NULL,
                pattern_description TEXT,
                
                frequency_count INTEGER DEFAULT 1,
                first_detected_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                last_occurrence_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                
                supporting_conversation_ids TEXT,
                confidence_score REAL DEFAULT 0.5,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # ========== MARCOS DO USU√ÅRIO ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_milestones (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                
                milestone_type TEXT NOT NULL,
                milestone_title TEXT NOT NULL,
                milestone_description TEXT,
                
                achieved_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                related_conversation_id INTEGER,
                
                before_state TEXT,
                after_state TEXT,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id),
                FOREIGN KEY (related_conversation_id) REFERENCES conversations(id)
            )
        """)
        
        # ========== CONFLITOS ARQUET√çPICOS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS archetype_conflicts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                conversation_id INTEGER,
                
                archetype1 TEXT NOT NULL,
                archetype2 TEXT NOT NULL,
                conflict_type TEXT,
                tension_level REAL,
                description TEXT,
                
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                
                FOREIGN KEY (user_id) REFERENCES users(user_id),
                FOREIGN KEY (conversation_id) REFERENCES conversations(id)
            )
        """)
        
        # ========== DESENVOLVIMENTO DO AGENTE ==========
        # Migra√ß√£o: Verificar se tabela precisa ser recriada com user_id
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='agent_development'")
        table_exists = cursor.fetchone() is not None

        if table_exists:
            # Verificar se coluna user_id existe
            cursor.execute("PRAGMA table_info(agent_development)")
            columns = [row[1] for row in cursor.fetchall()]

            if 'user_id' not in columns:
                logger.warning("‚ö†Ô∏è Migrando agent_development para nova estrutura com user_id...")

                # 1. Salvar dados antigos
                cursor.execute("SELECT * FROM agent_development WHERE id = 1")
                old_data = cursor.fetchone()

                # 2. Dropar tabela antiga
                cursor.execute("DROP TABLE IF EXISTS agent_development")

                # 3. Criar nova tabela
                cursor.execute("""
                    CREATE TABLE agent_development (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        user_id TEXT NOT NULL,

                        phase INTEGER DEFAULT 1,
                        total_interactions INTEGER DEFAULT 0,

                        self_awareness_score REAL DEFAULT 0.0,
                        moral_complexity_score REAL DEFAULT 0.0,
                        emotional_depth_score REAL DEFAULT 0.0,
                        autonomy_score REAL DEFAULT 0.0,

                        depth_level REAL DEFAULT 0.0,
                        autonomy_level REAL DEFAULT 0.0,

                        last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,

                        FOREIGN KEY (user_id) REFERENCES users(user_id)
                    )
                """)

                # 4. Migrar dados para todos os usu√°rios existentes
                if old_data:
                    cursor.execute("SELECT user_id FROM users")
                    users = cursor.fetchall()

                    for user_row in users:
                        user_id = user_row[0]
                        cursor.execute("""
                            INSERT INTO agent_development
                            (user_id, phase, total_interactions, self_awareness_score,
                             moral_complexity_score, emotional_depth_score, autonomy_score,
                             depth_level, autonomy_level, last_updated)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """, (
                            user_id,
                            old_data[1] if len(old_data) > 1 else 1,  # phase
                            old_data[2] if len(old_data) > 2 else 0,  # total_interactions
                            old_data[3] if len(old_data) > 3 else 0.0,  # self_awareness_score
                            old_data[4] if len(old_data) > 4 else 0.0,  # moral_complexity_score
                            old_data[5] if len(old_data) > 5 else 0.0,  # emotional_depth_score
                            old_data[6] if len(old_data) > 6 else 0.0,  # autonomy_score
                            old_data[7] if len(old_data) > 7 else 0.0,  # depth_level
                            old_data[8] if len(old_data) > 8 else 0.0,  # autonomy_level
                            old_data[9] if len(old_data) > 9 else 'CURRENT_TIMESTAMP'  # last_updated
                        ))

                    logger.info(f"‚úÖ Migrados dados de agent_development para {len(users)} usu√°rios")

                self.conn.commit()
        else:
            # Tabela n√£o existe, criar nova estrutura
            cursor.execute("""
                CREATE TABLE agent_development (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id TEXT NOT NULL,

                    phase INTEGER DEFAULT 1,
                    total_interactions INTEGER DEFAULT 0,

                    self_awareness_score REAL DEFAULT 0.0,
                    moral_complexity_score REAL DEFAULT 0.0,
                    emotional_depth_score REAL DEFAULT 0.0,
                    autonomy_score REAL DEFAULT 0.0,

                    depth_level REAL DEFAULT 0.0,
                    autonomy_level REAL DEFAULT 0.0,

                    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,

                    FOREIGN KEY (user_id) REFERENCES users(user_id)
                )
            """)

        # Criar √≠ndice √∫nico para garantir um registro por usu√°rio
        cursor.execute("""
            CREATE UNIQUE INDEX IF NOT EXISTS idx_agent_dev_user
            ON agent_development(user_id)
        """)
        
        # ========== MILESTONES DO AGENTE ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS milestones (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                
                milestone_type TEXT NOT NULL,
                description TEXT,
                phase INTEGER,
                interaction_count INTEGER,
                
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ========== AN√ÅLISES COMPLETAS ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS full_analyses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                user_name TEXT NOT NULL,

                mbti TEXT,
                dominant_archetypes TEXT,
                phase INTEGER DEFAULT 1,
                full_analysis TEXT,

                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                platform TEXT DEFAULT 'telegram',

                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)

        # ========== AN√ÅLISES PSICOM√âTRICAS (RH) ==========
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_psychometrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                version INTEGER DEFAULT 1,

                -- Big Five (OCEAN) - scores 0-100
                openness_score INTEGER,
                openness_level TEXT,
                openness_description TEXT,

                conscientiousness_score INTEGER,
                conscientiousness_level TEXT,
                conscientiousness_description TEXT,

                extraversion_score INTEGER,
                extraversion_level TEXT,
                extraversion_description TEXT,

                agreeableness_score INTEGER,
                agreeableness_level TEXT,
                agreeableness_description TEXT,

                neuroticism_score INTEGER,
                neuroticism_level TEXT,
                neuroticism_description TEXT,

                big_five_confidence INTEGER,
                big_five_interpretation TEXT,

                -- Intelig√™ncia Emocional (EQ) - scores 0-100
                eq_self_awareness INTEGER,
                eq_self_management INTEGER,
                eq_social_awareness INTEGER,
                eq_relationship_management INTEGER,
                eq_overall INTEGER,
                eq_leadership_potential TEXT,
                eq_details TEXT,

                -- Estilos de Aprendizagem (VARK) - scores 0-100
                vark_visual INTEGER,
                vark_auditory INTEGER,
                vark_reading INTEGER,
                vark_kinesthetic INTEGER,
                vark_dominant TEXT,
                vark_recommended_training TEXT,

                -- Valores Pessoais (Schwartz) - JSON
                schwartz_values TEXT,
                schwartz_top_3 TEXT,
                schwartz_cultural_fit TEXT,
                schwartz_retention_risk TEXT,

                -- Resumo Executivo
                executive_summary TEXT,

                -- Metadados
                analysis_date DATETIME DEFAULT CURRENT_TIMESTAMP,
                conversations_analyzed INTEGER,
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,

                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)

        # ========== √çNDICES DE PERFORMANCE ==========
        # Conversas
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_user ON conversations(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_timestamp ON conversations(timestamp DESC)")  # DESC para ORDER BY
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_user_timestamp ON conversations(user_id, timestamp DESC)")  # Composto
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_chroma ON conversations(chroma_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conv_session ON conversations(session_id)")

        # Conflitos
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conflict_user ON archetype_conflicts(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conflict_conversation ON archetype_conflicts(conversation_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_conflict_timestamp ON archetype_conflicts(timestamp DESC)")

        # Usu√°rios
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_users_platform ON users(platform, platform_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_users_last_seen ON users(last_seen DESC)")

        # Fatos
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_facts_user_category ON user_facts(user_id, fact_category, is_current)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_facts_current ON user_facts(is_current, user_id)")  # Para buscas de fatos atuais

        # Padr√µes
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_patterns_user ON user_patterns(user_id, pattern_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_patterns_confidence ON user_patterns(confidence_score DESC)")

        # Milestones
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_milestones_type ON milestones(milestone_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_milestones_timestamp ON milestones(timestamp DESC)")

        # An√°lises
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_analyses_user ON full_analyses(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_analyses_timestamp ON full_analyses(timestamp DESC)")

        # Psicometria
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_psychometrics_user ON user_psychometrics(user_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_psychometrics_version ON user_psychometrics(user_id, version DESC)")

        self.conn.commit()
        logger.info("‚úÖ Schema SQLite criado/verificado com √≠ndices de performance")
    
    # ========================================
    # USU√ÅRIOS
    # ========================================
    
    def create_user(self, user_id: str, user_name: str,
                   platform: str = 'telegram', platform_id: str = None):
        """Cria ou atualiza usu√°rio"""
        with self._lock:
            cursor = self.conn.cursor()

            name_parts = user_name.split()
            first_name = name_parts[0].title() if name_parts else ""
            last_name = name_parts[-1].title() if len(name_parts) > 1 else ""

            cursor.execute("""
                INSERT OR REPLACE INTO users
                (user_id, user_name, first_name, last_name, platform, platform_id)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (user_id, user_name, first_name, last_name, platform, platform_id))

            self.conn.commit()
            logger.info(f"‚úÖ Usu√°rio criado/atualizado: {user_name}")
    
    def register_user(self, full_name: str, platform: str = "telegram") -> str:
        """Registra usu√°rio (m√©todo legado compat√≠vel)"""
        name_normalized = full_name.lower().strip()
        user_id = hashlib.md5(name_normalized.encode()).hexdigest()[:12]

        with self._lock:
            cursor = self.conn.cursor()

            cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
            existing = cursor.fetchone()

            if existing:
                cursor.execute("""
                    UPDATE users
                    SET total_sessions = total_sessions + 1,
                        last_seen = CURRENT_TIMESTAMP
                    WHERE user_id = ?
                """, (user_id,))
                logger.info(f"‚úÖ Usu√°rio existente: {full_name} (sess√£o #{existing['total_sessions'] + 1})")
            else:
                name_parts = full_name.split()
                first_name = name_parts[0].title()
                last_name = name_parts[-1].title() if len(name_parts) > 1 else ""

                cursor.execute("""
                    INSERT INTO users (user_id, user_name, first_name, last_name, platform)
                    VALUES (?, ?, ?, ?, ?)
                """, (user_id, full_name.title(), first_name, last_name, platform))
                logger.info(f"‚úÖ Novo usu√°rio: {full_name}")

            self.conn.commit()
            return user_id
    
    def get_user(self, user_id: str) -> Optional[Dict]:
        """Busca dados do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        row = cursor.fetchone()
        return dict(row) if row else None
    
    def get_user_stats(self, user_id: str) -> Optional[Dict]:
        """Retorna estat√≠sticas do usu√°rio"""
        cursor = self.conn.cursor()
        
        cursor.execute("SELECT * FROM users WHERE user_id = ?", (user_id,))
        user_row = cursor.fetchone()
        
        if not user_row:
            return None
        
        user = dict(user_row)
        
        cursor.execute("SELECT COUNT(*) as count FROM conversations WHERE user_id = ?", (user_id,))
        total_messages = cursor.fetchone()['count']
        
        return {
            'total_messages': total_messages,
            'first_interaction': user['registration_date'],
            'total_sessions': user['total_sessions']
        }
    
    # ========================================
    # FUN√á√ïES AUXILIARES - METADATA ENRIQUECIDO
    # ========================================

    def _calculate_recency_tier(self, timestamp: datetime) -> str:
        """
        Calcula tier de rec√™ncia da conversa

        Args:
            timestamp: Timestamp da conversa

        Returns:
            "recent" (‚â§30 dias) | "medium" (31-90 dias) | "old" (>90 dias)
        """
        days_ago = (datetime.now() - timestamp).days

        if days_ago <= 30:
            return "recent"
        elif days_ago <= 90:
            return "medium"
        else:
            return "old"

    def _get_dominant_archetype(self, archetype_analyses: Dict) -> str:
        """
        Retorna arqu√©tipo com maior intensidade

        Args:
            archetype_analyses: Dict com an√°lises arquet√≠picas

        Returns:
            Nome do arqu√©tipo dominante ou ""
        """
        if not archetype_analyses:
            return ""

        try:
            dominant = max(
                archetype_analyses.items(),
                key=lambda x: x[1].intensity if hasattr(x[1], 'intensity') else 0
            )
            return dominant[0] if dominant else ""
        except Exception as e:
            logger.warning(f"Erro ao calcular arqu√©tipo dominante: {e}")
            return ""

    def _extract_people_from_conversation(self, conversation_id: int) -> List[str]:
        """
        Extrai nomes de pessoas mencionadas nos fatos desta conversa

        Args:
            conversation_id: ID da conversa

        Returns:
            Lista de nomes pr√≥prios
        """
        cursor = self.conn.cursor()

        # Verificar se user_facts_v2 existe
        cursor.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name='user_facts_v2'
        """)
        use_v2 = cursor.fetchone() is not None

        try:
            if use_v2:
                cursor.execute("""
                    SELECT fact_value
                    FROM user_facts_v2
                    WHERE source_conversation_id = ?
                    AND fact_attribute = 'nome'
                    AND is_current = 1
                """, (conversation_id,))
            else:
                cursor.execute("""
                    SELECT fact_value
                    FROM user_facts
                    WHERE source_conversation_id = ?
                    AND fact_key = 'nome'
                    AND is_current = 1
                """, (conversation_id,))

            names = [row[0] for row in cursor.fetchall() if row[0]]
            return names
        except Exception as e:
            logger.warning(f"Erro ao extrair pessoas da conversa {conversation_id}: {e}")
            return []

    def _extract_topics_from_keywords(self, keywords: List[str]) -> List[str]:
        """
        Classifica keywords em t√≥picos amplos

        Args:
            keywords: Lista de keywords da conversa

        Returns:
            Lista de t√≥picos detectados
        """
        if not keywords:
            return []

        # Mapeamento de keywords para t√≥picos
        topic_mapping = {
            "trabalho": ["trabalho", "emprego", "empresa", "carreira", "chefe", "colega", "projeto"],
            "familia": ["esposa", "marido", "filho", "filha", "pai", "mae", "familia", "casa"],
            "saude": ["saude", "medico", "doenca", "ansiedade", "depressao", "insonia", "terapia"],
            "relacionamento": ["amigo", "amizade", "namoro", "relacionamento", "amor"],
            "lazer": ["viagem", "hobby", "leitura", "esporte", "musica"],
            "dinheiro": ["dinheiro", "financeiro", "salario", "conta", "divida"],
        }

        topics = set()
        keywords_lower = [k.lower() for k in keywords]

        for topic, topic_keywords in topic_mapping.items():
            if any(kw in " ".join(keywords_lower) for kw in topic_keywords):
                topics.add(topic)

        return list(topics)

    def calculate_temporal_boost(self, memory_timestamp: str, mode: str = "balanced") -> float:
        """
        Calcula boost temporal para reranking de mem√≥rias

        Args:
            memory_timestamp: Timestamp ISO da mem√≥ria
            mode: Modo de decay ("recent_focused" | "balanced" | "archeological")

        Returns:
            Float multiplicador (0.5 a 1.5)
        """
        try:
            mem_time = datetime.fromisoformat(memory_timestamp)
        except:
            return 1.0  # Fallback se timestamp inv√°lido

        days_ago = (datetime.now() - mem_time).days

        if mode == "recent_focused":
            # Valoriza √∫ltimos 7 dias, penaliza antigas
            if days_ago <= 7:
                return 1.5
            elif days_ago <= 30:
                return 1.2
            elif days_ago <= 90:
                return 1.0
            else:
                return 0.7

        elif mode == "balanced":
            # Equil√≠brio entre recente e hist√≥rico
            if days_ago <= 30:
                return 1.2
            elif days_ago <= 90:
                return 1.0
            else:
                return 0.9

        elif mode == "archeological":
            # Valoriza padr√µes de longo prazo
            if days_ago <= 30:
                return 1.0
            elif days_ago <= 90:
                return 1.1
            else:
                return 1.3  # Boost para mem√≥rias antigas

        return 1.0  # Default

    # ========================================
    # CONVERSAS (H√çBRIDO: SQLite + ChromaDB)
    # ========================================

    def save_conversation(self, user_id: str, user_name: str, user_input: str,
                         ai_response: str, session_id: str = None,
                         archetype_analyses: Dict = None,
                         detected_conflicts: List[ArchetypeConflict] = None,
                         tension_level: float = 0.0,
                         affective_charge: float = 0.0,
                         existential_depth: float = 0.0,
                         intensity_level: int = 5,
                         complexity: str = "medium",
                         keywords: List[str] = None,
                         platform: str = "telegram",
                         chat_history: List[Dict] = None) -> int:
        """
        Salva conversa em AMBOS: SQLite (metadados) + ChromaDB (sem√¢ntica)

        Returns:
            int: ID da conversa no SQLite
        """

        # üîç DEBUG CR√çTICO: Log de salvamento para detectar vazamento
        logger.info(f"üíæ [DEBUG] Salvando conversa para user_id='{user_id}' (type={type(user_id).__name__})")
        logger.info(f"   User name: '{user_name}'")
        logger.info(f"   Input preview: '{user_input[:50]}...'")

        # Garantir que user_id √© string para consist√™ncia
        user_id_str = str(user_id) if user_id else None
        if not user_id_str:
            logger.error("‚ùå user_id √© None ou vazio! N√£o √© poss√≠vel salvar.")
            raise ValueError("user_id n√£o pode ser None ou vazio")

        if user_id_str != user_id:
            logger.warning(f"‚ö†Ô∏è user_id convertido de {type(user_id).__name__} para string: '{user_id}' -> '{user_id_str}'")
            user_id = user_id_str

        with self._lock:
            cursor = self.conn.cursor()

            # 1. Salvar no SQLite (metadados)
            cursor.execute("""
                INSERT INTO conversations
                (user_id, user_name, session_id, user_input, ai_response,
                 archetype_analyses, detected_conflicts,
                 tension_level, affective_charge, existential_depth,
                 intensity_level, complexity, keywords, platform)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                user_id, user_name, session_id, user_input, ai_response,
                json.dumps({k: asdict(v) for k, v in archetype_analyses.items()}) if archetype_analyses else None,
                json.dumps([asdict(c) for c in detected_conflicts]) if detected_conflicts else None,
                tension_level, affective_charge, existential_depth,
                intensity_level, complexity,
                ",".join(keywords) if keywords else "",
                platform
            ))

            conversation_id = cursor.lastrowid
            chroma_id = f"conv_{conversation_id}"

            logger.info(f"   SQLite: Conversa salva com ID={conversation_id}, chroma_id='{chroma_id}'")

            # 2. Atualizar com chroma_id
            cursor.execute("""
                UPDATE conversations
                SET chroma_id = ?
                WHERE id = ?
            """, (chroma_id, conversation_id))

            self.conn.commit()
        
        # 3. Salvar no ChromaDB (se habilitado)
        if self.chroma_enabled:
            try:
                # Construir documento completo
                doc_content = f"""
Usu√°rio: {user_name}
Input: {user_input}
Resposta: {ai_response}
"""
                
                if archetype_analyses:
                    doc_content += "\n=== VOZES INTERNAS ===\n"
                    for arch_name, insight in archetype_analyses.items():
                        doc_content += f"\n{arch_name}: {insight.voice_reaction[:150]} (impulso: {insight.impulse}, intensidade: {insight.intensity:.1f})\n"
                
                if detected_conflicts:
                    doc_content += "\n=== CONFLITOS DETECTADOS ===\n"
                    for conflict in detected_conflicts:
                        doc_content += f"{conflict.description}\n"
                
                # Metadata (Enriquecido - Fase 1 do Plano de Mem√≥ria)
                now = datetime.now()
                metadata = {
                    # Campos existentes (manter)
                    "user_id": user_id,
                    "user_name": user_name,
                    "session_id": session_id or "",
                    "timestamp": now.isoformat(),
                    "conversation_id": conversation_id,
                    "tension_level": tension_level,
                    "affective_charge": affective_charge,
                    "existential_depth": existential_depth,
                    "intensity_level": intensity_level,
                    "complexity": complexity,
                    "keywords": ",".join(keywords) if keywords else "",
                    "has_conflicts": len(detected_conflicts) > 0 if detected_conflicts else False,

                    # NOVOS - Temporal Estratificado
                    "day_bucket": now.strftime("%Y-%m-%d"),
                    "week_bucket": now.strftime("%Y-W%W"),
                    "month_bucket": now.strftime("%Y-%m"),
                    "recency_tier": self._calculate_recency_tier(now),

                    # NOVOS - Emocional/Tem√°tico
                    "emotional_intensity": round(affective_charge + tension_level, 2),
                    "dominant_archetype": self._get_dominant_archetype(archetype_analyses) if archetype_analyses else "",

                    # NOVOS - Relacional
                    "mentions_people": ",".join(self._extract_people_from_conversation(conversation_id)),
                    "topics": ",".join(self._extract_topics_from_keywords(keywords)),
                }

                # NOVO - Fact-Conversation Linking (Fase 4)
                # Buscar IDs de fatos extra√≠dos desta conversa
                try:
                    cursor.execute("""
                        SELECT name FROM sqlite_master
                        WHERE type='table' AND name='user_facts_v2'
                    """)
                    use_v2 = cursor.fetchone() is not None

                    if use_v2:
                        cursor.execute("""
                            SELECT id FROM user_facts_v2
                            WHERE source_conversation_id = ? AND is_current = 1
                        """, (conversation_id,))
                    else:
                        cursor.execute("""
                            SELECT id FROM user_facts
                            WHERE source_conversation_id = ? AND is_current = 1
                        """, (conversation_id,))

                    fact_ids = [str(row[0]) for row in cursor.fetchall()]
                    if fact_ids:
                        metadata["extracted_fact_ids"] = ",".join(fact_ids)
                        logger.info(f"   Linkados {len(fact_ids)} fatos ao ChromaDB metadata")
                except Exception as fact_link_error:
                    logger.warning(f"   Erro ao linkar fatos: {fact_link_error}")
                    # N√£o bloquear salvamento se linking falhar
                    pass

                # üîç DEBUG: Log do metadata sendo salvo
                logger.info(f"   ChromaDB metadata: user_id='{metadata['user_id']}' (type={type(metadata['user_id']).__name__})")
                logger.info(f"   ChromaDB doc_id: '{chroma_id}'")

                # Criar documento
                doc = Document(page_content=doc_content, metadata=metadata)

                # ‚úÖ ADICIONAR COM TRATAMENTO DE DUPLICATAS
                try:
                    self.vectorstore.add_documents([doc], ids=[chroma_id])
                    logger.info(f"‚úÖ ChromaDB: Documento '{chroma_id}' salvo com user_id='{metadata['user_id']}'")
                    logger.info(f"‚úÖ Conversa salva: SQLite (ID={conversation_id}) + ChromaDB ({chroma_id})")
                    
                except Exception as add_error:
                    error_msg = str(add_error).lower()
                    
                    # Verificar se √© erro de duplicata
                    if "already exists" in error_msg or "duplicate" in error_msg or "unique constraint" in error_msg:
                        logger.warning(f"‚ö†Ô∏è Documento {chroma_id} j√° existe no ChromaDB, substituindo...")
                        
                        try:
                            # Deletar documento existente
                            self.vectorstore.delete([chroma_id])
                            
                            # Adicionar novo documento
                            self.vectorstore.add_documents([doc], ids=[chroma_id])
                            
                            logger.info(f"‚úÖ Documento {chroma_id} substitu√≠do com sucesso")
                            
                        except Exception as replace_error:
                            logger.error(f"‚ùå Erro ao substituir documento {chroma_id}: {replace_error}")
                            logger.warning(f"‚ö†Ô∏è Conversa salva apenas no SQLite (ID={conversation_id})")
                    else:
                        # Outro tipo de erro
                        logger.error(f"‚ùå Erro ao adicionar ao ChromaDB: {add_error}")
                        logger.warning(f"‚ö†Ô∏è Conversa salva apenas no SQLite (ID={conversation_id})")
                
            except Exception as e:
                logger.error(f"‚ùå Erro geral ao processar ChromaDB: {e}")
                logger.warning(f"‚ö†Ô∏è Sistema continua funcionando apenas com SQLite")
        
        # 4. Salvar conflitos na tabela espec√≠fica
        if detected_conflicts:
            with self._lock:
                for conflict in detected_conflicts:
                    cursor.execute("""
                        INSERT INTO archetype_conflicts
                        (user_id, conversation_id, archetype1, archetype2,
                         conflict_type, tension_level, description)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        user_id, conversation_id,
                        conflict.archetype_1, conflict.archetype_2,
                        conflict.conflict_type, conflict.tension_level,
                        conflict.description
                    ))

                self.conn.commit()
        
        # 5. Atualizar desenvolvimento do agente (isolado por usu√°rio)
        self._update_agent_development(user_id)

        # 6. Extrair fatos do input (V2 com LLM, fallback para V1)
        logger.info(f"üîç [DEBUG FATOS] Verificando extra√ß√£o... hasattr(extract_and_save_facts_v2)={hasattr(self, 'extract_and_save_facts_v2')}")
        if hasattr(self, 'extract_and_save_facts_v2'):
            logger.info("‚úÖ Chamando extract_and_save_facts_v2...")
            self.extract_and_save_facts_v2(user_id, user_input, conversation_id)
        else:
            logger.info("‚ö†Ô∏è extract_and_save_facts_v2 n√£o encontrado, usando m√©todo antigo...")
            self.extract_and_save_facts(user_id, user_input, conversation_id)

        # 7. HOOK: Sistema de Rumina√ß√£o (s√≥ para admin)
        try:
            from rumination_config import ADMIN_USER_ID
            if user_id == ADMIN_USER_ID and platform == "telegram":
                from jung_rumination import RuminationEngine
                rumination = RuminationEngine(self)
                rumination.ingest({
                    "user_id": user_id,
                    "user_input": user_input,
                    "ai_response": ai_response,
                    "conversation_id": conversation_id,
                    "tension_level": tension_level,
                    "affective_charge": affective_charge
                })
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro no hook de rumina√ß√£o: {e}")

        # 8. HOOK: Log di√°rio em arquivo .md (mem√≥ria textual)
        try:
            from user_profile_writer import write_session_entry
            write_session_entry(
                user_id=user_id,
                user_name=user_name,
                user_input=user_input,
                ai_response=ai_response,
                metadata={
                    "tension_level": tension_level,
                    "affective_charge": affective_charge,
                },
            )
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro no hook de log di√°rio: {e}")

        return conversation_id

    def get_user_conversations(
        self,
        user_id: str,
        limit: int = 10,
        include_proactive: bool = False
    ) -> List[Dict]:
        """
        Busca √∫ltimas conversas do usu√°rio (SQLite)

        Args:
            user_id: ID do usu√°rio
            limit: N√∫mero m√°ximo de conversas
            include_proactive: Se True, inclui conversas com platform='proactive' ou 'proactive_rumination'

        Returns:
            Lista de conversas ordenadas por timestamp DESC
        """
        cursor = self.conn.cursor()

        if include_proactive:
            # Incluir TODAS as conversas (reativas + proativas)
            query = """
                SELECT * FROM conversations
                WHERE user_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """
            params = (user_id, limit)
        else:
            # Comportamento padr√£o: excluir proativas
            query = """
                SELECT * FROM conversations
                WHERE user_id = ?
                  AND (platform IS NULL OR platform NOT IN ('proactive', 'proactive_rumination'))
                ORDER BY timestamp DESC
                LIMIT ?
            """
            params = (user_id, limit)

        cursor.execute(query, params)

        conversations = []
        for row in cursor.fetchall():
            conv = dict(row)

            # Parse keywords se for JSON string
            if conv.get('keywords') and isinstance(conv['keywords'], str):
                try:
                    conv['keywords'] = json.loads(conv['keywords'])
                except:
                    conv['keywords'] = []

            conversations.append(conv)

        return conversations
    
    def count_conversations(self, user_id: str) -> int:
        """Conta conversas do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT COUNT(*) as count FROM conversations WHERE user_id = ?", (user_id,))
        return cursor.fetchone()['count']

    def conversations_to_chat_history(self, conversations: List[Dict]) -> List[Dict]:
        """
        Converte conversas do banco para formato chat_history.

        Args:
            conversations: Lista de conversas do banco (ORDER BY timestamp DESC)

        Returns:
            Lista de dicts {"role": "user"/"assistant", "content": str}
            em ordem cronol√≥gica (mais antiga primeiro)
        """
        history = []

        # Inverter para ordem cronol√≥gica (mais antiga ‚Üí mais recente)
        for conv in reversed(conversations):
            user_input = conv.get('user_input', '')

            # Filtrar marcadores de sistema proativo
            if user_input not in [
                "[SISTEMA PROATIVO INICIOU CONTATO]",
                "[INSIGHT RUMINADO - SISTEMA PROATIVO]"
            ]:
                history.append({
                    "role": "user",
                    "content": user_input
                })

            # Resposta do agente (sempre incluir)
            ai_response = conv.get('ai_response', '')
            if ai_response:
                history.append({
                    "role": "assistant",
                    "content": ai_response
                })

        return history

    # ========================================
    # QUERY ENRICHMENT - FASE 2
    # ========================================

    def _extract_names_from_text(self, text: str) -> List[str]:
        """
        Extrai nomes pr√≥prios do texto (heur√≠stica simples)

        Args:
            text: Texto para an√°lise

        Returns:
            Lista de poss√≠veis nomes pr√≥prios
        """
        import re

        # Padr√£o: Palavras capitalizadas que n√£o s√£o in√≠cio de frase
        # Ex: "Minha esposa Ana" -> captura "Ana"
        pattern = r'\b([A-Z√Å√â√ç√ì√ö√Ç√ä√î√É√ï√á][a-z√°√©√≠√≥√∫√¢√™√¥√£√µ√ß]+)\b'

        # Filtrar palavras comuns que n√£o s√£o nomes
        stopwords = {'O', 'A', 'Os', 'As', 'Um', 'Uma', 'De', 'Da', 'Do', 'Em', 'No', 'Na',
                    'Para', 'Por', 'Com', 'Sem', 'Mais', 'Menos', 'Muito', 'Pouco'}

        matches = re.findall(pattern, text)
        names = [m for m in matches if m not in stopwords]

        return list(set(names))  # Remover duplicatas

    def _detect_topics_in_text(self, text: str) -> List[str]:
        """
        Detecta t√≥picos mencionados no texto

        Args:
            text: Texto para an√°lise

        Returns:
            Lista de t√≥picos detectados
        """
        text_lower = text.lower()

        topic_keywords = {
            "trabalho": ["trabalho", "emprego", "empresa", "chefe", "colega", "reuni√£o", "projeto"],
            "familia": ["esposa", "marido", "filho", "filha", "pai", "m√£e", "fam√≠lia", "casa"],
            "saude": ["sa√∫de", "doen√ßa", "m√©dico", "ansiedade", "depress√£o", "terapia", "rem√©dio"],
            "relacionamento": ["amigo", "namoro", "amor", "relacionamento", "parceiro"],
            "lazer": ["viagem", "f√©rias", "hobby", "passeio"],
            "dinheiro": ["dinheiro", "sal√°rio", "conta", "d√≠vida", "financeiro"],
        }

        detected = []
        for topic, keywords in topic_keywords.items():
            if any(kw in text_lower for kw in keywords):
                detected.append(topic)

        return detected

    def _build_enriched_query(self, user_id: str, user_input: str, chat_history: List[Dict] = None) -> str:
        """
        Constr√≥i query enriquecida com m√∫ltiplas fontes (Fase 2 - Query Enrichment)

        Args:
            user_id: ID do usu√°rio
            user_input: Input do usu√°rio
            chat_history: Hist√≥rico da conversa atual

        Returns:
            Query enriquecida
        """
        query_parts = [user_input]  # Base

        # CAMADA 1: Contexto conversacional recente (expandir de 3 para 5)
        if chat_history and len(chat_history) > 0:
            recent = " ".join([
                msg["content"][:100]
                for msg in chat_history[-5:]  # Era -3, agora -5
                if msg["role"] == "user"
            ])
            if recent:
                query_parts.append(recent)

        # CAMADA 2: Fatos relevantes do usu√°rio (NOVO)
        # Buscar nomes de pessoas mencionadas no input
        mentioned_names = self._extract_names_from_text(user_input)

        if mentioned_names:
            # Buscar fatos sobre essas pessoas
            cursor = self.conn.cursor()

            # Usar user_facts_v2 se dispon√≠vel
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='table' AND name='user_facts_v2'
            """)
            use_v2 = cursor.fetchone() is not None

            relevant_facts = []
            for name in mentioned_names:
                try:
                    if use_v2:
                        cursor.execute("""
                            SELECT fact_type, fact_attribute, fact_value
                            FROM user_facts_v2
                            WHERE user_id = ? AND fact_value LIKE ? AND is_current = 1
                            LIMIT 3
                        """, (user_id, f"%{name}%"))
                    else:
                        cursor.execute("""
                            SELECT fact_key, fact_value
                            FROM user_facts
                            WHERE user_id = ? AND fact_value LIKE ? AND is_current = 1
                            LIMIT 3
                        """, (user_id, f"%{name}%"))

                    facts = cursor.fetchall()
                    relevant_facts.extend([
                        f"{row[0]}:{row[1]}" if use_v2 else f"{row[0]}:{row[1]}"
                        for row in facts
                    ])
                except Exception as e:
                    logger.warning(f"Erro ao buscar fatos para '{name}': {e}")

            if relevant_facts:
                query_parts.append(" ".join(relevant_facts[:5]))  # Limitar a 5 fatos

        # CAMADA 3: T√≥picos impl√≠citos (NOVO)
        topics = self._detect_topics_in_text(user_input)
        if topics:
            query_parts.append(" ".join(topics))

        enriched = " ".join(query_parts)

        # Log para debug
        if len(enriched) > len(user_input):
            logger.info(f"   Query enriquecida: {len(enriched)} chars (original: {len(user_input)} chars)")
            logger.info(f"   Nomes detectados: {mentioned_names}")
            logger.info(f"   T√≥picos detectados: {topics}")

        return enriched

    # ========================================
    # TWO-STAGE RETRIEVAL & RERANKING - FASE 3
    # ========================================

    def _calculate_adaptive_k(self, query: str, chat_history: List[Dict], user_id: str) -> int:
        """
        Calcula k adaptativo baseado em complexidade do contexto (Fase 3)

        Args:
            query: Query do usu√°rio
            chat_history: Hist√≥rico da conversa
            user_id: ID do usu√°rio

        Returns:
            k din√¢mico entre 3 e 12
        """
        base_k = 5

        # Fator 1: Comprimento do hist√≥rico
        if chat_history and len(chat_history) > 10:
            base_k += 2  # Conversas longas precisam de mais contexto

        # Fator 2: Complexidade da query
        query_words = len(query.split())
        if query_words > 20:
            base_k += 2
        elif query_words < 5:
            base_k -= 1  # Queries curtas precisam de menos

        # Fator 3: M√∫ltiplas pessoas mencionadas
        mentioned_names = self._extract_names_from_text(query)
        if len(mentioned_names) > 1:
            base_k += len(mentioned_names)

        # Fator 4: Hist√≥rico total do usu√°rio
        total_conversations = self.count_conversations(user_id)
        if total_conversations < 20:
            base_k = min(base_k, 3)  # Limitar para usu√°rios novos

        # Limitar entre 3 e 12
        final_k = max(3, min(base_k, 12))

        logger.info(f"   k adaptativo calculado: {final_k} (base={5}, words={query_words}, names={len(mentioned_names)}, total_convs={total_conversations})")

        return final_k

    def _rerank_memories(self, results: List[tuple], user_id: str, query: str) -> List[Dict]:
        """
        Reranking inteligente com 6 boosts (Fase 3)

        Args:
            results: Lista de (Document, score) do ChromaDB
            user_id: ID do usu√°rio
            query: Query original
            chat_history: Hist√≥rico da conversa

        Returns:
            Lista de mem√≥rias rerankeadas com scores combinados
        """
        import re

        reranked = []

        # Extrair informa√ß√µes da query para boosting
        query_names = set(self._extract_names_from_text(query))
        query_topics = set(self._detect_topics_in_text(query))

        logger.info(f"   Reranking {len(results)} mem√≥rias...")
        logger.info(f"   Query names: {query_names}")
        logger.info(f"   Query topics: {query_topics}")

        for doc, base_score in results:
            metadata = doc.metadata

            # Valida√ß√£o extra: filtrar manualmente user_id errado
            doc_user_id = str(metadata.get('user_id', ''))
            if doc_user_id != str(user_id):
                logger.error(f"üö® Removendo doc com user_id='{doc_user_id}' (esperado='{user_id}')")
                continue

            # === C√ÅLCULO DE BOOSTS ===

            # 1. BOOST TEMPORAL
            temporal_boost = self.calculate_temporal_boost(
                metadata.get('timestamp', ''),
                mode="balanced"
            )

            # 2. BOOST EMOCIONAL
            emotional_intensity = metadata.get('emotional_intensity', 0.0)
            emotional_boost = 1.0
            if emotional_intensity > 1.5:
                emotional_boost = 1.3  # Priorizar momentos emocionalmente intensos
            elif emotional_intensity > 2.5:
                emotional_boost = 1.5  # Muito intenso

            # 3. BOOST DE T√ìPICO
            memory_topics = set(metadata.get('topics', '').split(',')) if metadata.get('topics') else set()
            # Remover strings vazias
            memory_topics = {t.strip() for t in memory_topics if t.strip()}

            topic_boost = 1.0
            if query_topics & memory_topics:  # Interse√ß√£o
                overlap = len(query_topics & memory_topics)
                topic_boost = 1.2 + (overlap * 0.1)  # +0.1 por t√≥pico em comum

            # 4. BOOST DE PESSOA MENCIONADA (mais forte)
            memory_people = set(metadata.get('mentions_people', '').split(',')) if metadata.get('mentions_people') else set()
            memory_people = {p.strip() for p in memory_people if p.strip()}

            person_boost = 1.0
            if query_names & memory_people:  # Interse√ß√£o
                person_boost = 1.5  # FORTE boost se mesma pessoa mencionada

            # 5. BOOST DE PROFUNDIDADE EXISTENCIAL
            depth = metadata.get('existential_depth', 0.0)
            depth_boost = 1.0
            if depth > 0.7:
                depth_boost = 1.15  # Leve boost para conversas profundas

            # 6. BOOST DE CONFLITO ARQUET√çPICO
            conflict_boost = 1.0
            if metadata.get('has_conflicts', False):
                conflict_boost = 1.1  # Leve boost para momentos de conflito interno

            # === SCORE FINAL COMBINADO ===
            # Dist√¢ncia ChromaDB √© invertida (menor = mais similar)
            # Convertemos para similaridade: 1 - score
            similarity = 1 - base_score

            final_score = (
                similarity *
                temporal_boost *
                emotional_boost *
                topic_boost *
                person_boost *
                depth_boost *
                conflict_boost
            )

            # Extrair conte√∫do do documento
            user_input_match = re.search(r"Input:\s*(.+?)(?:\n|Resposta:|$)", doc.page_content, re.DOTALL)
            user_input_text = user_input_match.group(1).strip() if user_input_match else ""

            response_match = re.search(r"Resposta:\s*(.+?)(?:\n|===|$)", doc.page_content, re.DOTALL)
            response_text = response_match.group(1).strip() if response_match else ""

            reranked.append({
                'conversation_id': metadata.get('conversation_id'),
                'user_input': user_input_text,
                'ai_response': response_text,
                'timestamp': metadata.get('timestamp', ''),
                'base_score': base_score,
                'similarity_score': similarity,
                'final_score': final_score,
                'boosts': {
                    'temporal': round(temporal_boost, 2),
                    'emotional': round(emotional_boost, 2),
                    'topic': round(topic_boost, 2),
                    'person': round(person_boost, 2),
                    'depth': round(depth_boost, 2),
                    'conflict': round(conflict_boost, 2),
                },
                'metadata': metadata,
                'full_document': doc.page_content,
                'keywords': metadata.get('keywords', '').split(','),
                'tension_level': metadata.get('tension_level', 0.0),
            })

        # Ordenar por final_score (decrescente)
        reranked.sort(key=lambda x: x['final_score'], reverse=True)

        # Log dos top 3 com detalhes de boosts
        logger.info(f"   ‚úÖ Reranking conclu√≠do. Top 3:")
        for i, mem in enumerate(reranked[:3], 1):
            logger.info(f"   {i}. base={mem['base_score']:.3f}, similarity={mem['similarity_score']:.3f}, final={mem['final_score']:.3f}")
            logger.info(f"      Boosts: {mem['boosts']}")
            logger.info(f"      Input: {mem['user_input'][:60]}...")

        return reranked

    # ========================================
    # BUSCA SEM√ÇNTICA (ChromaDB)
    # ========================================

    def semantic_search(self, user_id: str, query: str, k: int = None,
                       chat_history: List[Dict] = None) -> List[Dict]:
        """
        Busca sem√¢ntica com TWO-STAGE RETRIEVAL + INTELLIGENT RERANKING (Fase 3)

        STAGE 1: Broad retrieval (k*3)
        STAGE 2: Intelligent reranking com 6 boosts

        Args:
            user_id: ID do usu√°rio
            query: Texto da consulta
            k: N√∫mero de resultados (None = adaptativo)
            chat_history: Hist√≥rico da conversa atual (opcional)

        Returns:
            Lista de mem√≥rias rerankeadas com scores combinados
        """

        if not self.chroma_enabled:
            logger.warning("ChromaDB desabilitado. Retornando conversas recentes do SQLite.")
            return self._fallback_keyword_search(user_id, query, k or 5)

        try:
            # Garantir que user_id √© string para consist√™ncia
            user_id_str = str(user_id) if user_id else None
            if not user_id_str:
                logger.error("‚ùå user_id √© None ou vazio! Retornando lista vazia.")
                return []

            # üîç DEBUG: In√≠cio do two-stage retrieval
            logger.info(f"üîç [TWO-STAGE] Busca sem√¢ntica para user_id='{user_id_str}'")
            logger.info(f"   Query original: '{query[:100]}'")

            # Calcular k adaptativo se n√£o fornecido (FASE 3)
            if k is None:
                k = self._calculate_adaptive_k(query, chat_history, user_id_str)
            else:
                logger.info(f"   k fixo fornecido: {k}")

            # Query enriquecida com multi-stage enhancement (FASE 2)
            enriched_query = self._build_enriched_query(
                user_id=user_id_str,
                user_input=query,
                chat_history=chat_history
            )

            # ============================================
            # STAGE 1: BROAD RETRIEVAL
            # ============================================
            broad_k = max(k * 3, 9)  # Buscar pelo menos 3x mais, m√≠nimo 9
            logger.info(f"   STAGE 1: Broad retrieval (k={broad_k})")

            chroma_filter = {"user_id": user_id_str}

            results = self.vectorstore.similarity_search_with_score(
                enriched_query,
                k=broad_k,
                filter=chroma_filter
            )

            logger.info(f"   Resultados retornados do ChromaDB: {len(results)}")

            if not results:
                logger.warning("   Nenhum resultado encontrado no ChromaDB")
                return []

            # ============================================
            # STAGE 2: INTELLIGENT RERANKING
            # ============================================
            logger.info(f"   STAGE 2: Reranking inteligente")
            reranked = self._rerank_memories(
                results=results,
                user_id=user_id_str,
                query=query
            )

            # Retornar top k ap√≥s reranking
            top_memories = reranked[:k]

            logger.info(f"‚úÖ Two-Stage conclu√≠do: {len(top_memories)} mem√≥rias finais (de {len(results)} broad)")
            for i, mem in enumerate(top_memories[:3], 1):
                logger.info(f"   {i}. [final={mem['final_score']:.3f}] {mem['user_input'][:50]}...")

            # STAGE 3: Merge com BM25 sobre arquivos de sess√£o
            try:
                from bm25_search import search as bm25_search
                bm25_hits = bm25_search(user_id_str, query, k=max(3, k // 2))
                if bm25_hits:
                    existing_texts = {m['user_input'][:80] for m in top_memories}
                    for hit in bm25_hits:
                        # Evitar duplicatas j√° cobertas pelo vector search
                        if hit['text'][:80] not in existing_texts:
                            top_memories.append({
                                'conversation_id': None,
                                'user_input': hit['text'],
                                'ai_response': '',
                                'timestamp': hit['date'],
                                'similarity_score': hit['bm25_score'] * 0.3,
                                'final_score': hit['bm25_score'] * 0.3,
                                'keywords': [],
                                'metadata': {'type': 'bm25', 'date': hit['date']},
                            })
                    # Re-ordenar por final_score
                    top_memories.sort(key=lambda m: m.get('final_score', 0), reverse=True)
                    top_memories = top_memories[:k]
                    logger.info(f"   BM25: {len(bm25_hits)} hits fundidos")
            except Exception as bm25_err:
                logger.debug(f"   BM25 indispon√≠vel: {bm25_err}")

            return top_memories

        except Exception as e:
            logger.error(f"‚ùå Erro na busca sem√¢ntica: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return self._fallback_keyword_search(user_id, query, k or 5)
    
    def _fallback_keyword_search(self, user_id: str, query: str, k: int = 5) -> List[Dict]:
        """Busca por keywords (fallback quando ChromaDB indispon√≠vel)"""
        cursor = self.conn.cursor()
        
        search_term = f"%{query}%"
        cursor.execute("""
            SELECT * FROM conversations
            WHERE user_id = ? 
            AND (user_input LIKE ? OR ai_response LIKE ?)
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, search_term, search_term, k))
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'conversation_id': row['id'],
                'user_input': row['user_input'],
                'ai_response': row['ai_response'],
                'timestamp': row['timestamp'],
                'similarity_score': 0.5,  # Score artificial
                'keywords': row['keywords'].split(',') if row['keywords'] else [],
                'metadata': dict(row)
            })
        
        return results
    
    # ========================================
    # CONSTRU√á√ÉO DE CONTEXTO
    # ========================================

    def _search_relevant_facts(self, user_id: str, query: str) -> List[Dict]:
        """
        Busca fatos relevantes ao input atual (Fase 5)

        Args:
            user_id: ID do usu√°rio
            query: Input do usu√°rio

        Returns:
            Lista de fatos relevantes
        """
        # Extrair nomes e t√≥picos da query
        mentioned_names = self._extract_names_from_text(query)
        mentioned_topics = self._detect_topics_in_text(query)

        cursor = self.conn.cursor()

        # Verificar estrutura V2
        cursor.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name='user_facts_v2'
        """)
        use_v2 = cursor.fetchone() is not None

        relevant_facts = []

        # Buscar fatos sobre pessoas mencionadas
        if mentioned_names:
            for name in mentioned_names:
                if use_v2:
                    cursor.execute("""
                        SELECT fact_category, fact_type, fact_attribute, fact_value, confidence
                        FROM user_facts_v2
                        WHERE user_id = ? AND fact_value LIKE ? AND is_current = 1
                        LIMIT 5
                    """, (user_id, f"%{name}%"))
                else:
                    cursor.execute("""
                        SELECT fact_category, fact_key AS fact_attribute, fact_value
                        FROM user_facts
                        WHERE user_id = ? AND fact_value LIKE ? AND is_current = 1
                        LIMIT 5
                    """, (user_id, f"%{name}%"))

                relevant_facts.extend([dict(row) for row in cursor.fetchall()])

        # Buscar fatos sobre t√≥picos mencionados
        if mentioned_topics:
            for topic in mentioned_topics:
                category_map = {
                    "trabalho": "TRABALHO",
                    "familia": "RELACIONAMENTO",
                    "saude": "SAUDE",
                }
                category = category_map.get(topic, "RELACIONAMENTO")

                if use_v2:
                    cursor.execute("""
                        SELECT fact_category, fact_type, fact_attribute, fact_value, confidence
                        FROM user_facts_v2
                        WHERE user_id = ? AND fact_category = ? AND is_current = 1
                        LIMIT 5
                    """, (user_id, category))
                else:
                    cursor.execute("""
                        SELECT fact_category, fact_key AS fact_attribute, fact_value
                        FROM user_facts
                        WHERE user_id = ? AND fact_category = ? AND is_current = 1
                        LIMIT 5
                    """, (user_id, category))

                relevant_facts.extend([dict(row) for row in cursor.fetchall()])

        return relevant_facts

    def _format_facts_hierarchically(self, facts: List[Dict]) -> str:
        """
        Formata fatos de forma hier√°rquica (Fase 5)

        Args:
            facts: Lista de fatos

        Returns:
            String formatada
        """
        if not facts:
            return ""

        # Agrupar por categoria
        by_category = {}
        for fact in facts:
            category = fact.get('fact_category', 'OUTROS')
            if category not in by_category:
                by_category[category] = []

            attribute = fact.get('fact_attribute', '')
            value = fact.get('fact_value', '')
            by_category[category].append(f"{attribute}: {value}")

        # Formatar
        lines = []
        for category, items in by_category.items():
            lines.append(f"{category}:")
            for item in items[:3]:  # Limitar a 3 por categoria
                lines.append(f"  - {item}")

        return "\n".join(lines)

    def _get_relevant_patterns(self, user_id: str, query: str) -> List[Dict]:
        """
        Busca padr√µes relevantes ao input atual (Fase 5)

        Args:
            user_id: ID do usu√°rio
            query: Input do usu√°rio

        Returns:
            Lista de padr√µes relevantes
        """
        cursor = self.conn.cursor()

        # Buscar padr√µes com alta confian√ßa
        cursor.execute("""
            SELECT pattern_name, pattern_description, frequency_count, confidence_score
            FROM user_patterns
            WHERE user_id = ? AND confidence_score > 0.6
            ORDER BY confidence_score DESC, frequency_count DESC
            LIMIT 3
        """, (user_id,))

        return [dict(row) for row in cursor.fetchall()]

    def _compress_context_if_needed(self, context: str, max_tokens: int = 2000) -> str:
        """
        Comprime contexto se exceder limite de tokens (Fase 5)

        Args:
            context: Contexto completo
            max_tokens: Limite m√°ximo de tokens

        Returns:
            Contexto comprimido se necess√°rio
        """
        # Estimativa simples: 1 token ‚âà 4 caracteres
        estimated_tokens = len(context) / 4

        if estimated_tokens <= max_tokens:
            return context

        # Se exceder, truncar proporcionalmente
        target_chars = int(max_tokens * 4 * 0.9)  # 90% do limite
        return context[:target_chars] + "\n\n[Contexto truncado devido ao limite]"

    def build_rich_context(self, user_id: str, current_input: str,
                          k_memories: int = None,
                          chat_history: List[Dict] = None) -> str:
        """
        Constr√≥i contexto HIER√ÅRQUICO e ESTRATIFICADO (Fase 5)

        Combina em layers:
        1. Hist√≥rico imediato (sempre incluir)
        2. Fatos relevantes ao input (busca inteligente)
        3. Mem√≥rias sem√¢nticas (reranked, agrupadas por rec√™ncia + consolidadas)
        4. Padr√µes detectados (se relevantes)

        Args:
            user_id: ID do usu√°rio
            current_input: Input atual
            k_memories: N√∫mero de mem√≥rias (None = adaptativo)
            chat_history: Hist√≥rico da conversa atual

        Returns:
            Contexto formatado e hier√°rquico
        """

        logger.info(f"üèóÔ∏è [FASE 5] Construindo contexto hier√°rquico para user_id={user_id}")

        user = self.get_user(user_id)
        name = user['user_name'] if user else "Usu√°rio"

        context_parts = []

        # ===== LAYER 1: HIST√ìRICO IMEDIATO =====
        context_parts.append("=== CONVERSA ATUAL ===\n")

        if chat_history and len(chat_history) > 0:
            recent = chat_history[-6:] if len(chat_history) > 6 else chat_history

            for msg in recent:
                role = "üë§ Usu√°rio" if msg["role"] == "user" else "ü§ñ Jung"
                content = msg["content"][:150] + "..." if len(msg["content"]) > 150 else msg["content"]
                context_parts.append(f"{role}: {content}")

            context_parts.append("")

        # ===== LAYER 2: FATOS RELEVANTES =====
        relevant_facts = self._search_relevant_facts(user_id, current_input)

        if relevant_facts:
            context_parts.append("=== FATOS RELEVANTES ===\n")
            context_parts.append(self._format_facts_hierarchically(relevant_facts))
            context_parts.append("")


        # ===== LAYER 3: MEM√ìRIAS SEM√ÇNTICAS =====
        memories = self.semantic_search(user_id, current_input, k=k_memories, chat_history=chat_history)

        if memories:
            context_parts.append("=== MEM√ìRIAS RELACIONADAS ===\n")

            # Separar por tipo e rec√™ncia
            consolidated = [m for m in memories if m.get('metadata', {}).get('type') == 'consolidated']
            regular = [m for m in memories if m.get('metadata', {}).get('type') != 'consolidated']

            # Agrupar regulares por rec√™ncia
            recent = [m for m in regular if m.get('metadata', {}).get('recency_tier') == 'recent']
            older = [m for m in regular if m.get('metadata', {}).get('recency_tier') != 'recent']

            # Mem√≥rias consolidadas primeiro (se existirem)
            if consolidated:
                context_parts.append("üì¶ Padr√µes de Longo Prazo (Consolidado):")
                for mem in consolidated[:1]:  # Apenas 1 consolidada
                    preview = mem.get('full_document', '')[:300]
                    context_parts.append(f"{preview}...")
                context_parts.append("")

            # Mem√≥rias recentes
            if recent:
                context_parts.append("üïê Recente (√∫ltimos 30 dias):")
                for i, mem in enumerate(recent[:3], 1):
                    timestamp = mem.get('timestamp', '')[:10]
                    user_input = mem.get('user_input', '')[:100]
                    context_parts.append(f"{i}. [{timestamp}] {user_input}...")
                context_parts.append("")

            # Mem√≥rias antigas (se relevantes)
            if older:
                context_parts.append("üìö Hist√≥rico:")
                for i, mem in enumerate(older[:2], 1):
                    timestamp = mem.get('timestamp', '')[:10]
                    user_input = mem.get('user_input', '')[:100]
                    context_parts.append(f"{i}. [{timestamp}] {user_input}...")
                context_parts.append("")

        # ===== LAYER 4: PADR√ïES DETECTADOS =====
        patterns = self._get_relevant_patterns(user_id, current_input)

        if patterns:
            context_parts.append("=== PADR√ïES OBSERVADOS ===\n")
            for pattern in patterns[:2]:
                context_parts.append(f"- {pattern['pattern_name']}: {pattern['pattern_description']}")
            context_parts.append("")

        # Juntar tudo
        full_context = "\n".join(context_parts)

        # Comprimir se necess√°rio
        full_context = self._compress_context_if_needed(full_context, max_tokens=2000)

        logger.info(f"‚úÖ [FASE 5] Contexto constru√≠do: {len(full_context)} caracteres")

        return full_context
    
    # ========================================
    # EXTRA√á√ÉO DE FATOS
    # ========================================
    
    def extract_and_save_facts(self, user_id: str, user_input: str, 
                               conversation_id: int) -> List[Dict]:
        """
        Extrai fatos estruturados do input do usu√°rio
        
        Usa regex patterns para detectar:
        - Profiss√£o, empresa, √°rea de atua√ß√£o
        - Tra√ßos de personalidade
        - Relacionamentos
        - Prefer√™ncias
        - Eventos de vida
        """
        
        extracted = []
        input_lower = user_input.lower()
        
        # ===== TRABALHO =====
        work_patterns = {
            'profissao': [
                r'sou (engenheiro|m√©dico|professor|advogado|desenvolvedor|designer|gerente|analista)',
                r'trabalho como (.+?)(?:\.|,|no|na|em)',
                r'atuo como (.+?)(?:\.|,|no|na|em)'
            ],
            'empresa': [
                r'trabalho na (.+?)(?:\.|,|como)',
                r'trabalho no (.+?)(?:\.|,|como)',
                r'minha empresa √© (.+?)(?:\.|,)'
            ]
        }
        
        for key, patterns in work_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, input_lower)
                if match:
                    value = match.group(1).strip()
                    self._save_or_update_fact(
                        user_id, 'TRABALHO', key, value, conversation_id
                    )
                    extracted.append({'category': 'TRABALHO', 'key': key, 'value': value})
                    break
        
        # ===== PERSONALIDADE =====
        personality_traits = {
            'introvertido': ['sou introvertido', 'prefiro ficar sozinho', 'evito eventos sociais'],
            'extrovertido': ['sou extrovertido', 'gosto de pessoas', 'adoro festas'],
            'ansioso': ['tenho ansiedade', 'fico ansioso', 'sou ansioso'],
            'calmo': ['sou calmo', 'sou tranquilo', 'pessoa zen'],
            'perfeccionista': ['sou perfeccionista', 'gosto de perfei√ß√£o', 'detalhe √© importante']
        }
        
        for trait, patterns in personality_traits.items():
            if any(p in input_lower for p in patterns):
                self._save_or_update_fact(
                    user_id, 'PERSONALIDADE', 'tra√ßo', trait, conversation_id
                )
                extracted.append({'category': 'PERSONALIDADE', 'key': 'tra√ßo', 'value': trait})
        
        # ===== RELACIONAMENTO =====
        relationship_patterns = [
            'meu namorado', 'minha namorada', 'meu marido', 'minha esposa',
            'meu pai', 'minha m√£e', 'meu irm√£o', 'minha irm√£'
        ]
        
        for pattern in relationship_patterns:
            if pattern in input_lower:
                self._save_or_update_fact(
                    user_id, 'RELACIONAMENTO', 'pessoa', pattern, conversation_id
                )
                extracted.append({'category': 'RELACIONAMENTO', 'key': 'pessoa', 'value': pattern})
        
        if extracted:
            logger.info(f"‚úÖ Extra√≠dos {len(extracted)} fatos de: {user_input[:50]}...")
        
        return extracted
    
    def _save_or_update_fact(self, user_id: str, category: str, key: str,
                            value: str, conversation_id: int):
        """Salva ou atualiza fato (com versionamento)"""

        # üîç DEBUG CR√çTICO: Log de salvamento de fato
        logger.info(f"üìù [DEBUG] Salvando fato para user_id='{user_id}' (type={type(user_id).__name__})")
        logger.info(f"   Categoria: {category}, Chave: {key}, Valor: {value}")

        with self._lock:
            cursor = self.conn.cursor()

            # Verificar se fato j√° existe
            cursor.execute("""
                SELECT id, fact_value FROM user_facts
                WHERE user_id = ? AND fact_category = ? AND fact_key = ? AND is_current = 1
            """, (user_id, category, key))

            existing = cursor.fetchone()

            if existing:
                # Se valor mudou, criar nova vers√£o
                if existing['fact_value'] != value:
                    logger.info(f"   ‚úèÔ∏è  Atualizando fato existente: '{existing['fact_value']}' ‚Üí '{value}'")

                    # Desativar vers√£o antiga
                    cursor.execute("""
                        UPDATE user_facts SET is_current = 0 WHERE id = ?
                    """, (existing['id'],))

                    # Criar nova vers√£o
                    cursor.execute("""
                        INSERT INTO user_facts
                        (user_id, fact_category, fact_key, fact_value,
                         source_conversation_id, version)
                        SELECT user_id, fact_category, fact_key, ?, ?, version + 1
                        FROM user_facts WHERE id = ?
                    """, (value, conversation_id, existing['id']))
                else:
                    logger.info(f"   ‚ÑπÔ∏è  Fato j√° existe com mesmo valor, pulando")
            else:
                logger.info(f"   ‚ú® Criando novo fato")
                # Criar fato novo
                cursor.execute("""
                    INSERT INTO user_facts
                    (user_id, fact_category, fact_key, fact_value, source_conversation_id)
                    VALUES (?, ?, ?, ?, ?)
                """, (user_id, category, key, value, conversation_id))

            self.conn.commit()
            logger.info(f"   ‚úÖ Fato salvo com sucesso")

    # ========================================
    # EXTRA√á√ÉO DE FATOS V2 (com LLM)
    # ========================================

    def extract_and_save_facts_v2(self, user_id: str, user_input: str,
                                  conversation_id: int) -> List[Dict]:
        """
        Extrai fatos estruturados usando LLM + fallback regex.
        Detecta e processa corre√ß√µes ANTES de extrair fatos novos.

        VERS√ÉO 3: Com suporte a corre√ß√µes gen√©ricas via CorrectionDetector
        """

        extracted_facts = []

        if not (hasattr(self, 'fact_extractor') and self.fact_extractor):
            logger.info("üîÑ fact_extractor indispon√≠vel, usando m√©todo legado...")
            return self.extract_and_save_facts(user_id, user_input, conversation_id)

        try:
            # ETAPA 1: Buscar fatos existentes para contexto de corre√ß√£o
            existing_facts = self._get_current_facts(user_id)
            logger.info(f"üìã {len(existing_facts)} fatos existentes carregados para contexto")

            # ETAPA 2: Extrair fatos e detectar corre√ß√µes (nova assinatura)
            logger.info("ü§ñ Analisando mensagem (fatos + corre√ß√µes)...")
            facts, corrections = self.fact_extractor.extract_facts(
                user_input, user_id, existing_facts
            )

            # ETAPA 3: Processar corre√ß√µes detectadas
            for correction in corrections:
                self._apply_correction(user_id, correction, conversation_id)
                extracted_facts.append({
                    'category': correction.category,
                    'type': correction.fact_type,
                    'attribute': correction.attribute,
                    'value': correction.new_value,
                    'confidence': correction.confidence,
                    'is_correction': True
                })

            # ETAPA 4: Salvar fatos novos
            for fact in facts:
                self._save_fact_v2(
                    user_id=user_id,
                    category=fact.category,
                    fact_type=fact.fact_type,
                    attribute=fact.attribute,
                    value=fact.value,
                    confidence=fact.confidence,
                    extraction_method='llm',
                    context=fact.context,
                    conversation_id=conversation_id
                )
                extracted_facts.append({
                    'category': fact.category,
                    'type': fact.fact_type,
                    'attribute': fact.attribute,
                    'value': fact.value,
                    'confidence': fact.confidence,
                    'is_correction': False
                })

            if extracted_facts:
                n_corr = sum(1 for f in extracted_facts if f.get('is_correction'))
                n_new = len(extracted_facts) - n_corr
                logger.info(f"‚úÖ Processados: {n_new} fatos novos, {n_corr} corre√ß√µes")

        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o com LLM: {e}")
            import traceback
            logger.error(traceback.format_exc())

        # Fallback se nada foi extra√≠do
        if not extracted_facts:
            logger.info("üîÑ LLM n√£o extraiu fatos, usando m√©todo legado...")
            extracted_facts = self.extract_and_save_facts(user_id, user_input, conversation_id)

        return extracted_facts

    def _get_current_facts(self, user_id: str) -> List[Dict]:
        """Retorna todos os fatos atuais do usu√°rio (is_current=1)."""
        with self._lock:
            cursor = self.conn.cursor()
            cursor.execute("""
                SELECT fact_category, fact_type, fact_attribute, fact_value, confidence
                FROM user_facts_v2
                WHERE user_id = ? AND is_current = 1
                ORDER BY fact_type, fact_attribute
            """, (user_id,))
            rows = cursor.fetchall()
            return [
                {
                    'category': r[0],
                    'fact_type': r[1],
                    'attribute': r[2],
                    'fact_value': r[3],
                    'confidence': r[4]
                }
                for r in rows
            ]

    def _apply_correction(self, user_id: str, correction, conversation_id: int):
        """
        Aplica uma corre√ß√£o detectada:
        1. Versiona o fato antigo no SQLite
        2. Anota mem√≥rias no ChromaDB

        Args:
            correction: CorrectionIntent com os detalhes da corre√ß√£o
        """
        from correction_detector import generate_correction_feedback

        # N√£o aplicar corre√ß√µes de baixa confian√ßa para evitar falsos positivos
        if correction.confidence < 0.5:
            logger.info(
                f"‚ö†Ô∏è Corre√ß√£o ignorada (confian√ßa muito baixa={correction.confidence:.2f}): "
                f"{correction.fact_type}.{correction.attribute} ‚Üí '{correction.new_value}'"
            )
            return

        logger.info(
            f"üîß Aplicando corre√ß√£o: {correction.fact_type}.{correction.attribute} "
            f"'{correction.old_value}' ‚Üí '{correction.new_value}' (confian√ßa={correction.confidence:.2f})"
        )

        # 1. Buscar fato atual para anotar ChromaDB
        old_fact = self._find_current_fact(user_id, correction.fact_type, correction.attribute)

        # 2. Salvar nova vers√£o (versionamento autom√°tico em _save_fact_v2)
        self._save_fact_v2(
            user_id=user_id,
            category=correction.category,
            fact_type=correction.fact_type,
            attribute=correction.attribute,
            value=correction.new_value,
            confidence=correction.confidence,
            extraction_method='correction',
            context=correction.context[:500] if correction.context else None,
            conversation_id=conversation_id
        )
        logger.info(f"   ‚úÖ SQLite atualizado")

        # 3. Sincronizar ChromaDB com anota√ß√£o de corre√ß√£o
        if old_fact:
            self._annotate_chromadb_correction(user_id, old_fact, correction)

        # 4. Log feedback (para debug/monitoramento)
        feedback = generate_correction_feedback(correction)
        if feedback:
            logger.info(f"   üí¨ Feedback de corre√ß√£o amb√≠gua: {feedback}")

    def _find_current_fact(self, user_id: str, fact_type: str, attribute: str) -> Optional[Dict]:
        """Busca o fato atual (is_current=1) de um tipo/atributo espec√≠fico."""
        with self._lock:
            cursor = self.conn.cursor()
            cursor.execute("""
                SELECT id, fact_category, fact_type, fact_attribute, fact_value
                FROM user_facts_v2
                WHERE user_id = ?
                  AND fact_type = ?
                  AND fact_attribute = ?
                  AND is_current = 1
                LIMIT 1
            """, (user_id, fact_type, attribute))
            row = cursor.fetchone()
            if row:
                return {
                    'id': row[0], 'category': row[1],
                    'fact_type': row[2], 'attribute': row[3], 'fact_value': row[4]
                }
            return None

    def _annotate_chromadb_correction(self, user_id: str, old_fact: Dict, correction):
        """
        Anota mem√≥rias no ChromaDB que referenciam um fato que foi corrigido.

        Estrat√©gia: adicionar metadado 'fact_correction' em vez de deletar.
        Assim o contexto hist√≥rico √© preservado, mas o build_rich_context
        pode identificar que aquela informa√ß√£o foi corrigida.

        Args:
            old_fact: Fato anterior (com 'fact_value')
            correction: CorrectionIntent com old_value e new_value
        """
        if not self.chroma_enabled or not self.vectorstore:
            return

        old_value = old_fact.get('fact_value', '')
        if not old_value:
            return

        try:
            # Buscar mem√≥rias que mencionam o valor antigo
            results = self.vectorstore.similarity_search_with_score(
                old_value,
                k=20,
                filter={"user_id": str(user_id)}
            )

            annotated = 0
            for doc, score in results:
                # Verificar se o documento realmente menciona o valor antigo
                if old_value.lower() not in doc.page_content.lower():
                    continue

                # Montar metadado de corre√ß√£o
                new_metadata = dict(doc.metadata)
                correction_note = f"{old_value} ‚Üí {correction.new_value}"

                # Acumular se j√° houver corre√ß√µes anteriores
                existing = new_metadata.get('fact_corrections', '')
                if correction_note not in existing:
                    new_metadata['fact_corrections'] = (
                        f"{existing}|{correction_note}".strip('|')
                    )

                    # Atualizar documento no ChromaDB (delete + re-add)
                    doc_id = doc.metadata.get('conversation_id')
                    if doc_id:
                        self._update_chroma_document(
                            f"conv_{doc_id}", doc.page_content, new_metadata
                        )
                        annotated += 1

            logger.info(f"   ‚úÖ ChromaDB: {annotated} mem√≥ria(s) anotada(s) com corre√ß√£o")

        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Erro ao anotar ChromaDB: {e}")

    def _update_chroma_document(self, doc_id: str, content: str, new_metadata: Dict):
        """
        Atualiza um documento no ChromaDB (delete + re-add).
        O ChromaDB n√£o suporta update nativo de metadados.
        """
        try:
            self.vectorstore.delete([doc_id])
            from langchain.schema import Document
            doc = Document(page_content=content, metadata=new_metadata)
            self.vectorstore.add_documents([doc], ids=[doc_id])
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Erro ao atualizar documento ChromaDB {doc_id}: {e}")

    def _save_fact_v2(self, user_id: str, category: str, fact_type: str,
                     attribute: str, value: str, confidence: float = 1.0,
                     extraction_method: str = 'llm', context: str = None,
                     conversation_id: int = None):
        """
        Salva ou atualiza fato na tabela user_facts_v2

        FEATURES:
        - Suporta m√∫ltiplas pessoas da mesma categoria
        - Versionamento adequado
        - Metadados de confian√ßa e m√©todo
        """

        logger.info(f"üìù [FACTS V2] Salvando: {category}.{fact_type}.{attribute} = {value}")

        with self._lock:
            cursor = self.conn.cursor()

            # Verificar se fato j√° existe
            cursor.execute("""
                SELECT id, fact_value, version
                FROM user_facts_v2
                WHERE user_id = ?
                  AND fact_category = ?
                  AND fact_type = ?
                  AND fact_attribute = ?
                  AND is_current = 1
            """, (user_id, category, fact_type, attribute))

            existing = cursor.fetchone()

            if existing:
                existing_id = existing[0]
                existing_value = existing[1]
                existing_version = existing[2]

                # Se valor mudou, criar nova vers√£o
                if existing_value != value:
                    logger.info(f"   ‚úèÔ∏è  Atualizando: '{existing_value}' ‚Üí '{value}'")

                    # Marcar vers√£o antiga como n√£o-atual
                    cursor.execute("""
                        UPDATE user_facts_v2
                        SET is_current = 0, updated_at = CURRENT_TIMESTAMP
                        WHERE id = ?
                    """, (existing_id,))

                    # Criar nova vers√£o
                    cursor.execute("""
                        INSERT INTO user_facts_v2
                        (user_id, fact_category, fact_type, fact_attribute, fact_value,
                         confidence, extraction_method, context, source_conversation_id,
                         version, is_current)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 1)
                    """, (
                        user_id, category, fact_type, attribute, value,
                        confidence, extraction_method, context, conversation_id,
                        existing_version + 1
                    ))

                    new_id = cursor.lastrowid

                    # Marcar que a vers√£o antiga foi substitu√≠da
                    cursor.execute("""
                        UPDATE user_facts_v2
                        SET replaced_by = ?
                        WHERE id = ?
                    """, (new_id, existing_id))

                    logger.info(f"   ‚úÖ Nova vers√£o criada (v{existing_version + 1})")
                else:
                    logger.info(f"   ‚ÑπÔ∏è  Fato j√° existe com mesmo valor")
            else:
                # Criar fato novo
                logger.info(f"   ‚ú® Criando novo fato")
                cursor.execute("""
                    INSERT INTO user_facts_v2
                    (user_id, fact_category, fact_type, fact_attribute, fact_value,
                     confidence, extraction_method, context, source_conversation_id,
                     version, is_current)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, 1, 1)
                """, (
                    user_id, category, fact_type, attribute, value,
                    confidence, extraction_method, context, conversation_id
                ))

                logger.info(f"   ‚úÖ Fato salvo com sucesso")

            self.conn.commit()

    # ========================================
    # DETEC√á√ÉO DE PADR√ïES
    # ========================================
    
    def detect_and_save_patterns(self, user_id: str):
        """
        Analisa conversas do usu√°rio e detecta padr√µes recorrentes
        
        Usa busca sem√¢ntica para agrupar temas similares
        """
        
        if not self.chroma_enabled:
            logger.warning("ChromaDB desabilitado. Detec√ß√£o de padr√µes limitada.")
            return
        
        cursor = self.conn.cursor()
        
        # Buscar keywords √∫nicas do usu√°rio
        cursor.execute("""
            SELECT DISTINCT keywords FROM conversations
            WHERE user_id = ? AND keywords IS NOT NULL AND keywords != ''
        """, (user_id,))
        
        all_keywords = set()
        for row in cursor.fetchall():
            all_keywords.update(row['keywords'].split(','))
        
        # Para cada tema, buscar conversas relacionadas
        for theme in list(all_keywords)[:20]:  # Limitar a 20 temas mais relevantes
            theme = theme.strip()
            if not theme or len(theme) < 6:
                continue

            related = self.semantic_search(user_id, theme, k=10)

            # Se h√° m√∫ltiplas conversas sobre o tema (padr√£o recorrente)
            if len(related) >= 3:
                conv_ids = [m['conversation_id'] for m in related]

                with self._lock:
                    # Verificar se padr√£o j√° existe
                    cursor.execute("""
                        SELECT id FROM user_patterns
                        WHERE user_id = ? AND pattern_name = ?
                    """, (user_id, f"tema_{theme}"))

                    existing = cursor.fetchone()

                    if existing:
                        # Atualizar
                        cursor.execute("""
                            UPDATE user_patterns
                            SET frequency_count = ?,
                                last_occurrence_at = CURRENT_TIMESTAMP,
                                supporting_conversation_ids = ?,
                                confidence_score = ?
                            WHERE id = ?
                        """, (
                            len(related),
                            json.dumps(conv_ids),
                            min(1.0, len(related) * 0.15),
                            existing['id']
                        ))
                    else:
                        # Criar
                        cursor.execute("""
                            INSERT INTO user_patterns
                            (user_id, pattern_type, pattern_name, pattern_description,
                             frequency_count, supporting_conversation_ids, confidence_score)
                            VALUES (?, ?, ?, ?, ?, ?, ?)
                        """, (
                            user_id,
                            'TEM√ÅTICO',
                            f"tema_{theme}",
                            f"Usu√°rio frequentemente menciona: {theme}",
                            len(related),
                            json.dumps(conv_ids),
                            min(1.0, len(related) * 0.15)
                        ))

                    self.conn.commit()

        logger.info(f"‚úÖ Padr√µes detectados para usu√°rio {user_id}")
    
    # ========================================
    # DESENVOLVIMENTO DO AGENTE
    # ========================================

    def _ensure_agent_state(self, user_id: str):
        """
        Garante que o usu√°rio tenha um registro de agent_development.
        Cria um novo registro com valores padr√£o se n√£o existir.

        Args:
            user_id: ID do usu√°rio
        """
        with self._lock:
            cursor = self.conn.cursor()

            # Verificar se j√° existe registro para este usu√°rio
            cursor.execute("""
                SELECT id FROM agent_development WHERE user_id = ?
            """, (user_id,))

            if not cursor.fetchone():
                # Criar registro inicial para este usu√°rio
                cursor.execute("""
                    INSERT INTO agent_development (user_id)
                    VALUES (?)
                """, (user_id,))

                self.conn.commit()
                logger.info(f"‚úÖ Agent state inicializado para user_id={user_id}")

    def _update_agent_development(self, user_id: str):
        """Atualiza m√©tricas de desenvolvimento do agente para um usu√°rio espec√≠fico"""
        # Garantir que o usu√°rio tem registro de agent_development
        self._ensure_agent_state(user_id)

        with self._lock:
            cursor = self.conn.cursor()

            cursor.execute("""
                UPDATE agent_development
                SET total_interactions = total_interactions + 1,
                    self_awareness_score = MIN(1.0, self_awareness_score + 0.001),
                    moral_complexity_score = MIN(1.0, moral_complexity_score + 0.0008),
                    emotional_depth_score = MIN(1.0, emotional_depth_score + 0.0012),
                    autonomy_score = MIN(1.0, autonomy_score + 0.0005),
                    depth_level = (self_awareness_score + moral_complexity_score + emotional_depth_score) / 3,
                    autonomy_level = autonomy_score,
                    last_updated = CURRENT_TIMESTAMP
                WHERE user_id = ?
            """, (user_id,))

            self.conn.commit()
            self._check_phase_progression(user_id)

    def _check_phase_progression(self, user_id: str):
        """Verifica se agente deve progredir de fase para um usu√°rio espec√≠fico"""
        # Note: Pode ser chamado de dentro de _update_agent_development (j√° locked)
        # ou de forma independente. RLock permite reentrada.
        with self._lock:
            cursor = self.conn.cursor()
            cursor.execute("SELECT * FROM agent_development WHERE user_id = ?", (user_id,))
            result = cursor.fetchone()

            if not result:
                logger.warning(f"‚ö†Ô∏è Agent state n√£o encontrado para user_id={user_id}")
                return

            state = dict(result)

            avg_score = (
                state['self_awareness_score'] +
                state['moral_complexity_score'] +
                state['emotional_depth_score'] +
                state['autonomy_score']
            ) / 4

            new_phase = min(5, int(avg_score * 5) + 1)

            if new_phase > state['phase']:
                cursor.execute("UPDATE agent_development SET phase = ? WHERE user_id = ?", (new_phase, user_id))

                cursor.execute("""
                    INSERT INTO milestones (milestone_type, description, phase, interaction_count)
                    VALUES (?, ?, ?, ?)
                """, (
                    "phase_progression",
                    f"Progress√£o para Fase {new_phase}",
                    new_phase,
                    state['total_interactions']
                ))

                self.conn.commit()
                logger.info(f"üéØ AGENTE PROGREDIU PARA FASE {new_phase}!")
    
    def get_agent_state(self, user_id: str) -> Optional[Dict]:
        """Retorna estado atual do agente para um usu√°rio espec√≠fico"""
        self._ensure_agent_state(user_id)

        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM agent_development WHERE user_id = ?", (user_id,))
        result = cursor.fetchone()

        if not result:
            logger.warning(f"‚ö†Ô∏è Agent state n√£o encontrado para user_id={user_id}")
            return None

        return dict(result)
    
    def get_milestones(self, limit: int = 20) -> List[Dict]:
        """Busca milestones recentes"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM milestones
            ORDER BY timestamp DESC
            LIMIT ?
        """, (limit,))
        return [dict(row) for row in cursor.fetchall()]
    
    # ========================================
    # CONFLITOS
    # ========================================
    
    def get_user_conflicts(self, user_id: str, limit: int = 10) -> List[Dict]:
        """Busca conflitos do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM archetype_conflicts
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, limit))
        return [dict(row) for row in cursor.fetchall()]
    
    # ========================================
    # AN√ÅLISES COMPLETAS
    # ========================================
    
    def save_full_analysis(self, user_id: str, user_name: str,
                          analysis: Dict, platform: str = "telegram") -> int:
        """Salva an√°lise completa"""
        with self._lock:
            cursor = self.conn.cursor()

            cursor.execute("""
                INSERT INTO full_analyses
                (user_id, user_name, mbti, dominant_archetypes, phase, full_analysis, platform)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                user_id, user_name,
                analysis.get('mbti', 'N/A'),
                json.dumps(analysis.get('archetypes', [])),
                analysis.get('phase', 1),
                analysis.get('insights', ''),
                platform
            ))

            self.conn.commit()
            return cursor.lastrowid
    
    def get_user_analyses(self, user_id: str) -> List[Dict]:
        """Retorna an√°lises completas do usu√°rio"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT * FROM full_analyses
            WHERE user_id = ?
            ORDER BY timestamp DESC
        """, (user_id,))
        return [dict(row) for row in cursor.fetchall()]

    # ========================================
    # AN√ÅLISES PSICOM√âTRICAS (RH)
    # ========================================

    def analyze_big_five(self, user_id: str, min_conversations: int = 20) -> Dict:
        """
        Analisa Big Five (OCEAN) do usu√°rio via Grok AI

        Retorna dict com scores 0-100 para cada dimens√£o:
        - openness, conscientiousness, extraversion, agreeableness, neuroticism
        """
        logger.info(f"üß¨ Iniciando an√°lise Big Five para {user_id}")

        # Buscar conversas do usu√°rio
        conversations = self.get_user_conversations(user_id, limit=50)

        if len(conversations) < min_conversations:
            return {
                "error": f"Dados insuficientes ({len(conversations)} conversas, m√≠nimo {min_conversations})",
                "conversations_analyzed": len(conversations)
            }

        # Montar contexto para o Grok
        convo_texts = []
        for c in conversations[:30]:  # √öltimas 30 para n√£o exceder token limit
            convo_texts.append(f"Usu√°rio: {c['user_input']}")
            convo_texts.append(f"Resposta: {c['ai_response'][:200]}")  # Truncar resposta

        context = "\n\n".join(convo_texts)

        # Prompt para Grok
        prompt = f"""Analise as conversas abaixo e infira os tra√ßos Big Five (OCEAN) do usu√°rio.

CONVERSAS:
{context}

TAREFA:
Para cada dimens√£o, d√™ um score de 0-100 e justifique em 2-3 frases:

1. OPENNESS (Abertura): Criatividade, curiosidade intelectual, prefer√™ncia por novidade
   - Alto: busca experi√™ncias novas, criativo, imaginativo
   - Baixo: prefere rotina, pr√°tico, tradicional

2. CONSCIENTIOUSNESS (Conscienciosidade): Organiza√ß√£o, autodisciplina, orienta√ß√£o a metas
   - Alto: organizado, respons√°vel, planejado
   - Baixo: espont√¢neo, flex√≠vel, menos estruturado

3. EXTRAVERSION (Extrovers√£o): Sociabilidade, assertividade, busca por estimula√ß√£o
   - Alto: social, energ√©tico, falante
   - Baixo: reservado, independente, introspectivo

4. AGREEABLENESS (Amabilidade): Empatia, coopera√ß√£o, confian√ßa
   - Alto: emp√°tico, cooperativo, altru√≠sta
   - Baixo: anal√≠tico, competitivo, direto

5. NEUROTICISM (Neuroticismo): Ansiedade, instabilidade emocional, vulnerabilidade
   - Alto: ansioso, sens√≠vel, emocionalmente reativo
   - Baixo: calmo, est√°vel, resiliente

CONSIDERE:
- Temas abordados (projetos criativos = Openness alto)
- Estrutura da comunica√ß√£o (mensagens organizadas = Conscientiousness alto)
- Tom emocional (ansiedade recorrente = Neuroticism alto)
- Men√ß√µes a rela√ß√µes sociais (solid√£o = Extraversion baixo)

Responda APENAS em JSON v√°lido (sem markdown):
{{
    "openness": {{"score": 0-100, "level": "Muito Baixo/Baixo/M√©dio/Alto/Muito Alto", "description": "..."}},
    "conscientiousness": {{"score": 0-100, "level": "...", "description": "..."}},
    "extraversion": {{"score": 0-100, "level": "...", "description": "..."}},
    "agreeableness": {{"score": 0-100, "level": "...", "description": "..."}},
    "neuroticism": {{"score": 0-100, "level": "...", "description": "..."}},
    "confidence": 0-100,
    "interpretation": "Resumo do perfil em 2-3 frases para RH"
}}
"""

        try:
            # Usar Claude Sonnet para an√°lises psicom√©tricas (melhor precis√£o)
            from llm_providers import create_llm_provider

            claude_provider = create_llm_provider("claude")
            response = claude_provider.get_response(prompt, temperature=0.5, max_tokens=1500)

            # Usar parser robusto
            result = self._parse_json_response(response)

            # Adicionar metadados
            result["conversations_analyzed"] = len(conversations)
            result["analysis_date"] = datetime.now().isoformat()
            result["model_used"] = claude_provider.get_model_name()

            logger.info(f"‚úÖ Big Five analisado (Claude): O={result['openness']['score']}, C={result['conscientiousness']['score']}, E={result['extraversion']['score']}, A={result['agreeableness']['score']}, N={result['neuroticism']['score']}")

            return result

        except Exception as e:
            logger.error(f"‚ùå Erro ao analisar Big Five: {e}")
            logger.error(f"Resposta bruta do LLM: {response if 'response' in locals() else 'N/A'}")
            return {
                "error": str(e),
                "conversations_analyzed": len(conversations)
            }

    def analyze_emotional_intelligence(self, user_id: str) -> Dict:
        """
        Calcula Intelig√™ncia Emocional (EQ) baseado em dados j√° coletados

        4 Componentes:
        1. Autoconsci√™ncia (self_awareness_score do banco)
        2. Autogest√£o (varia√ß√£o de tension_level)
        3. Consci√™ncia Social (men√ß√µes a outros)
        4. Gest√£o de Relacionamentos (evolu√ß√£o de conflitos)
        """
        logger.info(f"üíñ Iniciando an√°lise EQ para {user_id}")

        # 1. Autoconsci√™ncia - pegar do agent_development do usu√°rio
        cursor = self.conn.cursor()
        cursor.execute("SELECT self_awareness_score FROM agent_development WHERE user_id = ?", (user_id,))
        agent_state = cursor.fetchone()
        self_awareness_raw = agent_state['self_awareness_score'] if agent_state else 0.0
        self_awareness = int(min(100, self_awareness_raw * 100))  # Normalizar para 0-100

        # 2. Autogest√£o - analisar varia√ß√£o de tension_level
        conversations = self.get_user_conversations(user_id, limit=50)
        if len(conversations) < 10:
            return {
                "error": f"Dados insuficientes ({len(conversations)} conversas, m√≠nimo 10)",
                "conversations_analyzed": len(conversations)
            }

        tensions = [c.get('tension_level', 5.0) for c in conversations if c.get('tension_level')]
        if tensions:
            import statistics
            avg_tension = statistics.mean(tensions)
            std_tension = statistics.stdev(tensions) if len(tensions) > 1 else 0
            # Menor desvio padr√£o = melhor autogest√£o
            self_management = int(max(0, min(100, 100 - (std_tension * 15))))
        else:
            self_management = 50  # Default m√©dio

        # 3. Consci√™ncia Social - contar men√ß√µes a "outros", "equipe", "fam√≠lia", etc
        social_keywords = ['outros', 'equipe', 'fam√≠lia', 'amigos', 'colegas', 'pessoas', 'eles', 'ela', 'ele']
        social_mentions = 0
        total_words = 0

        for c in conversations:
            user_input_lower = c['user_input'].lower()
            words = user_input_lower.split()
            total_words += len(words)
            for keyword in social_keywords:
                social_mentions += user_input_lower.count(keyword)

        social_ratio = (social_mentions / max(1, total_words)) * 1000  # Normalizar
        social_awareness = int(min(100, social_ratio * 30 + 40))  # Base 40, at√© 100

        # 4. Gest√£o de Relacionamentos - analisar conflitos Persona vs outros
        conflicts = self.get_user_conflicts(user_id, limit=100)
        persona_conflicts = [c for c in conflicts if 'persona' in c['archetype1'].lower() or 'persona' in c['archetype2'].lower()]

        if len(persona_conflicts) > 5:
            # Analisar se conflitos diminuem com o tempo (sinal de melhoria)
            recent_conflicts = persona_conflicts[:len(persona_conflicts)//2]
            old_conflicts = persona_conflicts[len(persona_conflicts)//2:]

            recent_avg_tension = statistics.mean([c.get('tension_level', 5.0) for c in recent_conflicts]) if recent_conflicts else 5.0
            old_avg_tension = statistics.mean([c.get('tension_level', 5.0) for c in old_conflicts]) if old_conflicts else 5.0

            improvement = ((old_avg_tension - recent_avg_tension) / max(0.1, old_avg_tension)) * 100
            relationship_management = int(min(100, max(30, 60 + improvement * 2)))
        else:
            relationship_management = 60  # Default m√©dio-alto

        # Calcular EQ geral
        eq_overall = int((self_awareness + self_management + social_awareness + relationship_management) / 4)

        # Determinar potencial de lideran√ßa
        if eq_overall >= 75:
            leadership_potential = "Alto"
        elif eq_overall >= 60:
            leadership_potential = "M√©dio-Alto"
        elif eq_overall >= 45:
            leadership_potential = "M√©dio"
        else:
            leadership_potential = "Baixo"

        result = {
            "self_awareness": {
                "score": self_awareness,
                "level": self._get_level(self_awareness),
                "description": "Capacidade de reconhecer emo√ß√µes e padr√µes pr√≥prios"
            },
            "self_management": {
                "score": self_management,
                "level": self._get_level(self_management),
                "description": "Capacidade de regular emo√ß√µes e manter equil√≠brio"
            },
            "social_awareness": {
                "score": social_awareness,
                "level": self._get_level(social_awareness),
                "description": "Capacidade de perceber emo√ß√µes e necessidades alheias"
            },
            "relationship_management": {
                "score": relationship_management,
                "level": self._get_level(relationship_management),
                "description": "Capacidade de influenciar e conectar-se com outros"
            },
            "overall_eq": eq_overall,
            "leadership_potential": leadership_potential,
            "conversations_analyzed": len(conversations),
            "analysis_date": datetime.now().isoformat()
        }

        logger.info(f"‚úÖ EQ analisado: Overall={eq_overall}, Lideran√ßa={leadership_potential}")

        return result

    def _get_level(self, score: int) -> str:
        """Helper para converter score em n√≠vel textual"""
        if score >= 80:
            return "Muito Alto"
        elif score >= 65:
            return "Alto"
        elif score >= 45:
            return "M√©dio"
        elif score >= 30:
            return "Baixo"
        else:
            return "Muito Baixo"

    def _parse_json_response(self, response: str) -> Dict:
        """
        Parse robusto de resposta JSON do LLM
        Remove markdown code blocks e trata erros comuns
        """
        import json as json_lib
        import re

        # Remover espa√ßos em branco nas extremidades
        response = response.strip()

        # Remover markdown code blocks (```json ... ``` ou ``` ... ```)
        if response.startswith("```"):
            # Encontrar o conte√∫do entre ``` e ```
            match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
            if match:
                response = match.group(1).strip()

        # Tentar remover texto antes do JSON (√†s vezes o LLM adiciona explica√ß√µes)
        if not response.startswith('{') and not response.startswith('['):
            # Procurar o primeiro { ou [
            json_start = min(
                response.find('{') if response.find('{') != -1 else len(response),
                response.find('[') if response.find('[') != -1 else len(response)
            )
            if json_start < len(response):
                response = response[json_start:]

        # Tentar parse
        try:
            return json_lib.loads(response)
        except json_lib.JSONDecodeError as e:
            logger.error(f"‚ùå Erro ao fazer parse de JSON: {e}")
            logger.error(f"Resposta recebida: {response[:500]}...")
            raise ValueError(f"Resposta LLM n√£o √© JSON v√°lido: {str(e)}")

    def analyze_learning_style(self, user_id: str, min_conversations: int = 20) -> Dict:
        """
        Analisa Estilos de Aprendizagem (VARK) via Grok AI

        VARK:
        - Visual, Auditory, Reading/Writing, Kinesthetic
        """
        logger.info(f"üìö Iniciando an√°lise VARK para {user_id}")

        conversations = self.get_user_conversations(user_id, limit=40)

        if len(conversations) < min_conversations:
            return {
                "error": f"Dados insuficientes ({len(conversations)} conversas, m√≠nimo {min_conversations})",
                "conversations_analyzed": len(conversations)
            }

        # Montar contexto
        user_messages = [c['user_input'] for c in conversations[:25]]
        context = "\n\n".join([f"Mensagem {i+1}: {msg}" for i, msg in enumerate(user_messages)])

        prompt = f"""Analise o estilo de comunica√ß√£o do usu√°rio e infira seu estilo de aprendizagem VARK.

MENSAGENS DO USU√ÅRIO:
{context}

INDICADORES:

VISUAL (V):
- Usa palavras: "vejo", "imagem", "parece", "claro", "visualizo", "mostra"
- Menciona gr√°ficos, diagramas, cores, formas
- Pede explica√ß√µes visuais

AUDITIVO (A):
- Usa palavras: "ou√ßo", "soa", "ritmo", "harmonia", "escuto", "fala"
- Menciona m√∫sicas, podcasts, conversas, tom de voz
- Prefere explica√ß√µes verbais

LEITURA/ESCRITA (R):
- Mensagens longas e estruturadas
- Usa listas, t√≥picos, cita√ß√µes, refer√™ncias
- Menciona livros, artigos, documenta√ß√£o, pesquisa
- Vocabul√°rio rico e formal

CINEST√âSICO (K):
- Usa palavras: "sinto", "toque", "movimento", "pr√°tica", "experi√™ncia"
- Menciona fazer, experimentar, testar, agir
- Foco em sensa√ß√µes f√≠sicas e a√ß√£o

Responda APENAS em JSON v√°lido (sem markdown):
{{
    "visual": 0-100,
    "auditory": 0-100,
    "reading": 0-100,
    "kinesthetic": 0-100,
    "dominant_style": "Visual/Auditivo/Leitura/Cinest√©sico",
    "recommended_training": "Sugest√£o de formato de treinamento ideal para este perfil"
}}

IMPORTANTE: Os 4 scores devem somar aproximadamente 100.
"""

        try:
            # Usar Claude Sonnet para an√°lises psicom√©tricas (melhor precis√£o)
            from llm_providers import create_llm_provider

            claude_provider = create_llm_provider("claude")
            response = claude_provider.get_response(prompt, temperature=0.5, max_tokens=800)

            # Usar parser robusto
            result = self._parse_json_response(response)

            result["conversations_analyzed"] = len(conversations)
            result["analysis_date"] = datetime.now().isoformat()
            result["model_used"] = claude_provider.get_model_name()

            logger.info(f"‚úÖ VARK analisado (Claude): Dominante={result['dominant_style']}")

            return result

        except Exception as e:
            logger.error(f"‚ùå Erro ao analisar VARK: {e}")
            logger.error(f"Resposta bruta do LLM: {response if 'response' in locals() else 'N/A'}")
            return {
                "error": str(e),
                "conversations_analyzed": len(conversations)
            }

    def analyze_personal_values(self, user_id: str, min_conversations: int = 20) -> Dict:
        """
        Analisa Valores Pessoais (Schwartz) via extra√ß√£o de user_facts + Grok AI

        10 Valores Universais de Schwartz
        """
        logger.info(f"‚≠ê Iniciando an√°lise Valores Schwartz para {user_id}")

        # Primeiro tentar buscar de user_facts categoria 'values'
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT fact_key, fact_value, confidence
            FROM user_facts
            WHERE user_id = ? AND fact_category = 'values' AND is_current = 1
            ORDER BY confidence DESC
        """, (user_id,))

        existing_values = cursor.fetchall()

        # Se tiver menos de 3 valores, usar Grok para inferir
        if len(existing_values) < 3:
            conversations = self.get_user_conversations(user_id, limit=40)

            if len(conversations) < min_conversations:
                return {
                    "error": f"Dados insuficientes ({len(conversations)} conversas, m√≠nimo {min_conversations})",
                    "conversations_analyzed": len(conversations)
                }

            # Montar contexto
            convo_texts = []
            for c in conversations[:25]:
                convo_texts.append(f"{c['user_input']}")
            context = "\n\n".join(convo_texts)

            prompt = f"""Analise as mensagens do usu√°rio e identifique seus valores pessoais segundo a teoria de Schwartz.

MENSAGENS:
{context}

10 VALORES UNIVERSAIS DE SCHWARTZ:

1. AUTODIRE√á√ÉO: Independ√™ncia, criatividade, explora√ß√£o, liberdade de pensamento
2. ESTIMULA√á√ÉO: Novidade, desafios, excita√ß√£o, vida variada
3. HEDONISMO: Prazer, gratifica√ß√£o sensorial, aproveitar a vida
4. REALIZA√á√ÉO: Sucesso pessoal, compet√™ncia, ambi√ß√£o, reconhecimento
5. PODER: Status social, prest√≠gio, controle sobre recursos/pessoas
6. SEGURAN√áA: Prote√ß√£o, ordem, estabilidade, harmonia
7. CONFORMIDADE: Restri√ß√£o de a√ß√µes que violam normas sociais, autodisciplina
8. TRADI√á√ÉO: Respeito por costumes culturais/religiosos, humildade
9. BENEVOL√äNCIA: Bem-estar de pessoas pr√≥ximas, ajudar, honestidade
10. UNIVERSALISMO: Compreens√£o, toler√¢ncia, justi√ßa social, prote√ß√£o da natureza

Identifique os 3 valores MAIS FORTES do usu√°rio.

Responda APENAS em JSON v√°lido (sem markdown):
{{
    "self_direction": {{"score": 0-100, "evidences": ["evid√™ncia 1", "evid√™ncia 2"]}},
    "stimulation": {{"score": 0-100, "evidences": []}},
    "hedonism": {{"score": 0-100, "evidences": []}},
    "achievement": {{"score": 0-100, "evidences": []}},
    "power": {{"score": 0-100, "evidences": []}},
    "security": {{"score": 0-100, "evidences": []}},
    "conformity": {{"score": 0-100, "evidences": []}},
    "tradition": {{"score": 0-100, "evidences": []}},
    "benevolence": {{"score": 0-100, "evidences": []}},
    "universalism": {{"score": 0-100, "evidences": []}},
    "top_3_values": ["Valor 1", "Valor 2", "Valor 3"],
    "cultural_fit": "Descri√ß√£o de ambientes/culturas onde este perfil prospera",
    "retention_risk": "Baixo/M√©dio/Alto - baseado em alinhamento de valores"
}}
"""

            try:
                # Usar Claude Sonnet para an√°lises psicom√©tricas (melhor precis√£o)
                from llm_providers import create_llm_provider

                claude_provider = create_llm_provider("claude")
                response = claude_provider.get_response(prompt, temperature=0.5, max_tokens=1800)

                # Usar parser robusto
                result = self._parse_json_response(response)

                result["conversations_analyzed"] = len(conversations)
                result["analysis_date"] = datetime.now().isoformat()
                result["source"] = "claude_inference"
                result["model_used"] = claude_provider.get_model_name()

                logger.info(f"‚úÖ Valores analisados (Claude): Top 3={result['top_3_values']}")

                return result

            except Exception as e:
                logger.error(f"‚ùå Erro ao analisar valores: {e}")
                logger.error(f"Resposta bruta do LLM: {response if 'response' in locals() else 'N/A'}")
                return {
                    "error": str(e),
                    "conversations_analyzed": len(conversations)
                }

        else:
            # Construir resultado a partir de user_facts existentes
            logger.info(f"‚úÖ Valores extra√≠dos de user_facts ({len(existing_values)} encontrados)")

            # Mapear fatos para valores de Schwartz (simplificado)
            result = {
                "self_direction": {"score": 0, "evidences": []},
                "stimulation": {"score": 0, "evidences": []},
                "hedonism": {"score": 0, "evidences": []},
                "achievement": {"score": 0, "evidences": []},
                "power": {"score": 0, "evidences": []},
                "security": {"score": 0, "evidences": []},
                "conformity": {"score": 0, "evidences": []},
                "tradition": {"score": 0, "evidences": []},
                "benevolence": {"score": 0, "evidences": []},
                "universalism": {"score": 0, "evidences": []},
                "top_3_values": [],
                "cultural_fit": "A determinar com mais dados",
                "retention_risk": "M√©dio",
                "source": "user_facts",
                "conversations_analyzed": 0,
                "analysis_date": datetime.now().isoformat()
            }

            # Classifica√ß√£o b√°sica (pode ser melhorada)
            for fact in existing_values:
                key = fact['fact_key'].lower()
                value = fact['fact_value'].lower()
                confidence = fact['confidence'] * 100

                if any(word in key+value for word in ['independ√™ncia', 'criatividade', 'autonomia']):
                    result["self_direction"]["score"] = max(result["self_direction"]["score"], int(confidence))
                    result["self_direction"]["evidences"].append(fact['fact_value'])

                if any(word in key+value for word in ['sucesso', 'realiza√ß√£o', 'ambi√ß√£o']):
                    result["achievement"]["score"] = max(result["achievement"]["score"], int(confidence))
                    result["achievement"]["evidences"].append(fact['fact_value'])

                # Adicionar mais mapeamentos conforme necess√°rio

            # Identificar top 3
            values_scores = {k: v["score"] for k, v in result.items() if isinstance(v, dict) and "score" in v}
            sorted_values = sorted(values_scores.items(), key=lambda x: x[1], reverse=True)
            result["top_3_values"] = [k.replace("_", " ").title() for k, _ in sorted_values[:3] if sorted_values[0][1] > 0]

            return result

    def save_psychometrics(self, user_id: str, big_five: Dict, eq: Dict, vark: Dict, values: Dict) -> None:
        """
        Salva an√°lises psicom√©tricas no banco
        """
        logger.info(f"üíæ Salvando an√°lises psicom√©tricas para {user_id}")

        # Verificar se j√° existe an√°lise (para versionamento)
        cursor = self.conn.cursor()
        cursor.execute("SELECT MAX(version) as max_version FROM user_psychometrics WHERE user_id = ?", (user_id,))
        row = cursor.fetchone()
        version = (row['max_version'] or 0) + 1 if row else 1

        # Preparar dados
        import json as json_lib

        # Big Five
        bf_o = big_five.get('openness', {})
        bf_c = big_five.get('conscientiousness', {})
        bf_e = big_five.get('extraversion', {})
        bf_a = big_five.get('agreeableness', {})
        bf_n = big_five.get('neuroticism', {})

        # EQ
        eq_sa = eq.get('self_awareness', {})
        eq_sm = eq.get('self_management', {})
        eq_soc = eq.get('social_awareness', {})
        eq_rm = eq.get('relationship_management', {})

        # Resumo executivo
        executive_summary = json_lib.dumps({
            "profile": f"Big Five: O{bf_o.get('score', 0)}, C{bf_c.get('score', 0)}, E{bf_e.get('score', 0)}, A{bf_a.get('score', 0)}, N{bf_n.get('score', 0)} | EQ: {eq.get('overall_eq', 0)}",
            "strengths": big_five.get('interpretation', 'N/A')[:200],
            "development_areas": f"EQ Lideran√ßa: {eq.get('leadership_potential', 'N/A')}",
            "organizational_fit": values.get('cultural_fit', 'A determinar'),
            "recommendations": f"Estilo de aprendizagem: {vark.get('dominant_style', 'N/A')}"
        })

        # Insert
        cursor.execute("""
            INSERT INTO user_psychometrics (
                user_id, version,
                openness_score, openness_level, openness_description,
                conscientiousness_score, conscientiousness_level, conscientiousness_description,
                extraversion_score, extraversion_level, extraversion_description,
                agreeableness_score, agreeableness_level, agreeableness_description,
                neuroticism_score, neuroticism_level, neuroticism_description,
                big_five_confidence, big_five_interpretation,
                eq_self_awareness, eq_self_management, eq_social_awareness, eq_relationship_management,
                eq_overall, eq_leadership_potential, eq_details,
                vark_visual, vark_auditory, vark_reading, vark_kinesthetic,
                vark_dominant, vark_recommended_training,
                schwartz_values, schwartz_top_3, schwartz_cultural_fit, schwartz_retention_risk,
                executive_summary,
                conversations_analyzed
            ) VALUES (
                ?, ?,
                ?, ?, ?,
                ?, ?, ?,
                ?, ?, ?,
                ?, ?, ?,
                ?, ?, ?,
                ?, ?,
                ?, ?, ?, ?,
                ?, ?, ?,
                ?, ?, ?, ?,
                ?, ?,
                ?, ?, ?, ?,
                ?,
                ?
            )
        """, (
            user_id, version,
            bf_o.get('score'), bf_o.get('level'), bf_o.get('description'),
            bf_c.get('score'), bf_c.get('level'), bf_c.get('description'),
            bf_e.get('score'), bf_e.get('level'), bf_e.get('description'),
            bf_a.get('score'), bf_a.get('level'), bf_a.get('description'),
            bf_n.get('score'), bf_n.get('level'), bf_n.get('description'),
            big_five.get('confidence'), big_five.get('interpretation'),
            eq_sa.get('score'), eq_sm.get('score'), eq_soc.get('score'), eq_rm.get('score'),
            eq.get('overall_eq'), eq.get('leadership_potential'), json_lib.dumps(eq),
            vark.get('visual'), vark.get('auditory'), vark.get('reading'), vark.get('kinesthetic'),
            vark.get('dominant_style'), vark.get('recommended_training'),
            json_lib.dumps(values), ','.join(values.get('top_3_values', [])),
            values.get('cultural_fit'), values.get('retention_risk'),
            executive_summary,
            big_five.get('conversations_analyzed', 0)
        ))

        self.conn.commit()
        logger.info(f"‚úÖ An√°lises psicom√©tricas salvas (vers√£o {version})")

    def get_psychometrics(self, user_id: str, version: int = None) -> Optional[Dict]:
        """
        Busca an√°lises psicom√©tricas do usu√°rio
        Se version n√£o especificado, retorna a mais recente
        """
        cursor = self.conn.cursor()

        if version:
            cursor.execute("""
                SELECT * FROM user_psychometrics
                WHERE user_id = ? AND version = ?
            """, (user_id, version))
        else:
            cursor.execute("""
                SELECT * FROM user_psychometrics
                WHERE user_id = ?
                ORDER BY version DESC
                LIMIT 1
            """, (user_id,))

        row = cursor.fetchone()
        return dict(row) if row else None

    # ========================================
    # UTILIT√ÅRIOS
    # ========================================
    
    def get_all_users(self, platform: str = None) -> List[Dict]:
        """Retorna todos os usu√°rios"""
        cursor = self.conn.cursor()
        
        if platform:
            cursor.execute("""
                SELECT u.*, COUNT(c.id) as total_messages
                FROM users u
                LEFT JOIN conversations c ON u.user_id = c.user_id
                WHERE u.platform = ?
                GROUP BY u.user_id
                ORDER BY u.last_seen DESC
            """, (platform,))
        else:
            cursor.execute("""
                SELECT u.*, COUNT(c.id) as total_messages
                FROM users u
                LEFT JOIN conversations c ON u.user_id = c.user_id
                GROUP BY u.user_id
                ORDER BY u.last_seen DESC
            """)
        
        return [dict(row) for row in cursor.fetchall()]
    
    def count_memories(self, user_id: str) -> int:
        """Conta mem√≥rias do usu√°rio"""
        return self.count_conversations(user_id)
    
    def close(self):
        """Fecha conex√µes"""
        self.conn.close()
        logger.info("‚úÖ Banco de dados fechado")

# ============================================================
# DETECTOR DE CONFLITOS
# ============================================================

class ConflictDetector:
    """Detecta e gerencia conflitos internos entre arqu√©tipos"""
    
    def __init__(self):
        self.opposing_directions = {
            'confrontar': ['acolher', 'validar', 'proteger'],
            'desafiar': ['apoiar', 'validar', 'confortar'],
            'questionar': ['aceitar', 'validar', 'confirmar'],
            'provocar': ['suavizar', 'acolher', 'acalmar'],
            'expor': ['proteger', 'ocultar', 'resguardar']
        }
    
    def detect_conflicts(self, archetype_analyses: Dict[str, ArchetypeInsight]) -> List[ArchetypeConflict]:
        """Detecta conflitos entre as posi√ß√µes dos arqu√©tipos"""
        
        conflicts = []
        archetype_names = list(archetype_analyses.keys())
        
        for i in range(len(archetype_names)):
            for j in range(i + 1, len(archetype_names)):
                arch1_name = archetype_names[i]
                arch2_name = archetype_names[j]
                
                arch1 = archetype_analyses[arch1_name]
                arch2 = archetype_analyses[arch2_name]

                impulse1 = arch1.impulse.lower()
                impulse2 = arch2.impulse.lower()

                is_conflicting = False
                conflict_type = ""

                # Verificar oposi√ß√µes
                if impulse1 in self.opposing_directions:
                    if impulse2 in self.opposing_directions[impulse1]:
                        is_conflicting = True
                        conflict_type = f"{impulse1}_vs_{impulse2}"

                if impulse2 in self.opposing_directions:
                    if impulse1 in self.opposing_directions[impulse2]:
                        is_conflicting = True
                        conflict_type = f"{impulse2}_vs_{impulse1}"

                # Conflitos espec√≠ficos por nome de arqu√©tipo
                if (arch1_name.lower() == "persona" and arch2_name.lower() == "sombra") or \
                   (arch1_name.lower() == "sombra" and arch2_name.lower() == "persona"):
                    if impulse1 != impulse2:
                        is_conflicting = True
                        conflict_type = "persona_sombra_clash"

                if is_conflicting:
                    tension_level = self._calculate_tension(arch1, arch2)

                    conflict = ArchetypeConflict(
                        archetype_1=arch1_name,
                        archetype_2=arch2_name,
                        conflict_type=conflict_type,
                        archetype_1_position=f"{impulse1} (intensidade: {arch1.intensity:.1f})",
                        archetype_2_position=f"{impulse2} (intensidade: {arch2.intensity:.1f})",
                        tension_level=tension_level,
                        description=f"Tens√£o entre {arch1_name} ({impulse1}) e {arch2_name} ({impulse2})"
                    )
                    
                    conflicts.append(conflict)
                    logger.info(f"‚ö° CONFLITO: {arch1_name} vs {arch2_name} (tens√£o: {tension_level:.2f})")
        
        return conflicts
    
    def _calculate_tension(self, arch1: ArchetypeInsight, arch2: ArchetypeInsight) -> float:
        """Calcula n√≠vel de tens√£o entre dois arqu√©tipos"""
        impulse1 = arch1.impulse.lower()
        impulse2 = arch2.impulse.lower()

        high_tension_words = ['confrontar', 'provocar', 'desafiar']
        low_tension_words = ['acolher', 'proteger']

        # Base: m√©dia das intensidades
        tension = (arch1.intensity + arch2.intensity) / 2

        # Ajustar tens√£o baseado em oposi√ß√£o de impulsos
        if impulse1 in high_tension_words and impulse2 in low_tension_words:
            tension = min(0.9, tension + 0.3)
        elif impulse1 in low_tension_words and impulse2 in high_tension_words:
            tension = min(0.9, tension + 0.3)
        elif impulse1 in high_tension_words and impulse2 in high_tension_words:
            tension = max(0.3, tension - 0.2)  # Ambos intensos, mas alinhados
        elif impulse1 in low_tension_words and impulse2 in low_tension_words:
            tension = max(0.2, tension - 0.3)  # Ambos suaves, pouca tens√£o

        return min(1.0, tension)  # Cap em 1.0

# ============================================================
# JUNGIAN ENGINE (Motor principal)
# ============================================================

class JungianEngine:
    """Motor de an√°lise junguiana com sistema de conflitos arquet√≠picos"""

    def __init__(self, db: HybridDatabaseManager = None):
        """Inicializa engine (db opcional para compatibilidade)"""

        self.db = db if db else HybridDatabaseManager()

        # Cliente OpenAI (para embeddings apenas)
        self.openai_client = OpenAI(
            api_key=Config.OPENAI_API_KEY,
            timeout=30.0  # 30 segundos de timeout
        )

        # Cliente Anthropic (tarefas internas: extra√ß√£o de fatos, detec√ß√£o de corre√ß√µes)
        import anthropic
        self.anthropic_client = anthropic.Anthropic(
            api_key=Config.ANTHROPIC_API_KEY
        )

        # Cliente OpenRouter/Mistral (conversa√ß√£o com o usu√°rio)
        if Config.OPENROUTER_API_KEY:
            self.openrouter_client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=Config.OPENROUTER_API_KEY,
                timeout=60.0
            )
            logger.info(f"‚úÖ OpenRouter client inicializado (modelo: {Config.CONVERSATION_MODEL})")
        else:
            self.openrouter_client = None
            logger.warning("‚ö†Ô∏è OPENROUTER_API_KEY n√£o configurada - usando Claude para conversa√ß√£o")

        # üß† Context builder de identidade do agente (Fase 4)
        try:
            from agent_identity_context_builder import AgentIdentityContextBuilder
            self.identity_context_builder = AgentIdentityContextBuilder(self.db)
            logger.info("‚úÖ AgentIdentityContextBuilder integrado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è AgentIdentityContextBuilder n√£o dispon√≠vel: {e}")
            self.identity_context_builder = None

        logger.info("‚úÖ JungianEngine inicializado")
    
    def process_message(self, user_id: str, message: str,
                       model: str = None,
                       chat_history: List[Dict] = None) -> Dict:
        """
        PROCESSAMENTO SIMPLIFICADO (v7.0):
        1. Busca sem√¢ntica (ChromaDB)
        2. Gera√ß√£o de resposta direta (1 chamada LLM)
        3. Salvamento (SQLite + ChromaDB)

        Args:
            user_id: ID do usu√°rio
            message: Mensagem do usu√°rio
            model: Ignorado (modelo definido por CONVERSATION_MODEL em Config)
            chat_history: Hist√≥rico da conversa atual (opcional)

        Returns:
            Dict com response, conversation_count, m√©tricas
        """

        logger.info(f"{'='*60}")
        logger.info(f"üß† PROCESSANDO MENSAGEM (v7.0 - Simplificado)")
        logger.info(f"{'='*60}")

        # Buscar usu√°rio
        user = self.db.get_user(user_id)
        user_name = user['user_name'] if user else "Usu√°rio"
        platform = user['platform'] if user else "telegram"

        # Construir contexto sem√¢ntico
        logger.info("üîç Construindo contexto sem√¢ntico...")
        semantic_context = self.db.build_rich_context(
            user_id, message, k_memories=5, chat_history=chat_history
        )

        # Determinar complexidade
        complexity = self._determine_complexity(message)

        # Gerar resposta direta (1 chamada LLM)
        logger.info("ü§ñ Gerando resposta...")
        response = self._generate_response(
            user_id, message, semantic_context, chat_history
        )

        # Calcular m√©tricas
        affective_charge = self._calculate_affective_charge(message, response)
        existential_depth = self._calculate_existential_depth(message)
        intensity_level = int(affective_charge / 10)
        keywords = self._extract_keywords(message, response)

        # Salvar conversa (SQLite + ChromaDB)
        conversation_id = self.db.save_conversation(
            user_id=user_id,
            user_name=user_name,
            user_input=message,
            ai_response=response,
            archetype_analyses={},  # Vazio - arqu√©tipos removidos
            detected_conflicts=[],  # Vazio - conflitos removidos
            tension_level=0.0,
            affective_charge=affective_charge,
            existential_depth=existential_depth,
            intensity_level=intensity_level,
            complexity=complexity,
            keywords=keywords,
            platform=platform,
            chat_history=chat_history
        )

        logger.info(f"‚úÖ Processamento completo (ID={conversation_id})")
        logger.info(f"{'='*60}\n")

        # Resultado
        result = {
            'response': response,
            'conflicts': [],  # Mantido para compatibilidade
            'conversation_count': self.db.count_conversations(user_id),
            'tension_level': 0.0,
            'affective_charge': affective_charge,
            'existential_depth': existential_depth,
            'conversation_id': conversation_id,
            'conflict': None
        }

        return result
    
    # ========================================
    # M√âTODOS AUXILIARES
    # ========================================

    def _generate_response(self, user_id: str, user_input: str,
                          semantic_context: str, chat_history: List[Dict]) -> str:
        """
        Gera resposta usando prompt unificado (v7.0)

        Substituiu os m√©todos:
        - _analyze_with_archetype (4 chamadas LLM)
        - _generate_conflicted_response
        - _generate_harmonious_response

        Agora usa apenas 1 chamada LLM.
        """

        # Pre-compaction flush: persistir fragmentos antes de truncar contexto longo
        if chat_history:
            try:
                from memory_flush import flush_if_needed
                user_row = self.conn.execute(
                    "SELECT user_name FROM users WHERE user_id = ?", (user_id,)
                ).fetchone()
                user_name_for_flush = user_row[0] if user_row else user_id
                chat_history = flush_if_needed(
                    db=self,
                    anthropic_client=self.anthropic_client,
                    user_id=user_id,
                    user_name=user_name_for_flush,
                    chat_history=chat_history,
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro no pre-compaction flush: {e}")

        # Formatar hist√≥rico
        history_text = ""
        if chat_history:
            for msg in chat_history[-6:]:
                role = "Usu√°rio" if msg["role"] == "user" else "Jung"
                history_text += f"{role}: {msg['content'][:150]}...\n"

        # Construir identidade din√¢mica: base est√°tica + contexto de identidade do agente
        agent_identity_text = Config.AGENT_IDENTITY
        if self.identity_context_builder:
            try:
                identity_ctx = self.identity_context_builder.build_context_summary_for_llm(
                    user_id=user_id, style="concise"
                )
                if identity_ctx and len(identity_ctx) > 100:
                    agent_identity_text = Config.AGENT_IDENTITY + "\n\n" + identity_ctx
                    logger.info(
                        f"‚úÖ [IDENTITY] Contexto de identidade injetado: {len(identity_ctx)} chars"
                    )
                else:
                    logger.info(
                        "‚ö†Ô∏è [IDENTITY] Contexto de identidade vazio ‚Äî usando persona base "
                        "(aguardando 1¬™ consolida√ß√£o de identidade)"
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [IDENTITY] Falha ao obter contexto de identidade: {e}")
        else:
            logger.debug("‚ö†Ô∏è [IDENTITY] identity_context_builder n√£o dispon√≠vel ‚Äî usando persona base")

        # Construir prompt
        prompt = Config.RESPONSE_PROMPT.format(
            agent_identity=agent_identity_text,
            semantic_context=semantic_context[:2000],
            chat_history=history_text,
            user_input=user_input
        )

        # Log de debug
        logger.info(f"ü§ñ [DEBUG] ========== PROMPT PARA LLM (v7.0) ==========")
        logger.info(f"   Semantic context (primeiros 500 chars):\n{semantic_context[:500]}")
        logger.info(f"   User input: {user_input}")
        logger.info(f"====================================================")

        try:
            # Usar Mistral via OpenRouter para conversa√ß√£o (se dispon√≠vel)
            if self.openrouter_client:
                logger.info(f"ü§ñ Usando OpenRouter/Mistral ({Config.CONVERSATION_MODEL}) para conversa√ß√£o")
                response = self.openrouter_client.chat.completions.create(
                    model=Config.CONVERSATION_MODEL,
                    max_tokens=2000,
                    temperature=0.7,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            else:
                # Fallback: Claude (quando OPENROUTER_API_KEY n√£o est√° configurada)
                logger.info("ü§ñ Fallback para Claude (OPENROUTER_API_KEY n√£o configurada)")
                message = self.anthropic_client.messages.create(
                    model=Config.INTERNAL_MODEL,
                    max_tokens=2000,
                    temperature=0.7,
                    messages=[{"role": "user", "content": prompt}]
                )
                return message.content[0].text

        except (TimeoutError, ConnectionError) as e:
            logger.error(f"‚ùå Erro de conex√£o/timeout ao gerar resposta: {e}")
            return "Desculpe, tive problemas de conectividade. Por favor, tente novamente."
        except ValueError as e:
            logger.error(f"‚ùå Erro de valida√ß√£o ao gerar resposta: {e}")
            return "Desculpe, houve um erro ao validar sua mensagem."
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado ao gerar resposta: {type(e).__name__} - {e}")
            return "Desculpe, tive dificuldades para processar isso."

    def _determine_complexity(self, user_input: str) -> str:
        """Determina complexidade da mensagem"""
        word_count = len(user_input.split())
        
        if word_count <= 3:
            return "simple"
        elif word_count > 15:
            return "complex"
        else:
            return "medium"
    
    def _calculate_affective_charge(self, user_input: str, response: str) -> float:
        """Calcula carga afetiva"""
        emotional_words = [
            "amor", "√≥dio", "medo", "alegria", "tristeza", "raiva", "ansiedade",
            "feliz", "triste", "nervoso", "calmo", "confuso", "frustrado"
        ]
        
        text = (user_input + " " + response).lower()
        count = sum(1 for word in emotional_words if word in text)
        
        return min(count * 10, 100)
    
    def _calculate_existential_depth(self, user_input: str) -> float:
        """Calcula profundidade existencial"""
        depth_words = [
            "sentido", "prop√≥sito", "sozinho", "perdido", "real", "aut√™ntic",
            "verdadeir", "profundo", "√≠ntimo", "medo", "vulner√°vel"
        ]
        
        text = user_input.lower()
        count = sum(1 for word in depth_words if word in text)
        
        return min(count * 0.15, 1.0)
    
    def _extract_keywords(self, user_input: str, response: str) -> List[str]:
        """Extrai palavras-chave"""
        text = (user_input + " " + response).lower()
        words = text.split()
        
        stopwords = {
            "o", "a", "de", "que", "e", "do", "da", "em", "um", "para", 
            "√©", "com", "n√£o", "uma", "os", "no", "se", "na", "por"
        }
        
        keywords = [w for w in words if len(w) > 3 and w not in stopwords and w.isalpha()]
        
        return [word for word, _ in Counter(keywords).most_common(5)]

# ============================================================
# FUN√á√ïES AUXILIARES (COMPATIBILIDADE)
# ============================================================

def send_to_xai(prompt: str, model: str = None,
                temperature: float = 0.7, max_tokens: int = 2000) -> str:
    """
    Envia prompt para Claude Sonnet 4.5 (√∫nico provider LLM).

    NOTA: Nome mantido por compatibilidade. Internamente usa Claude.

    Args:
        prompt: Texto para o LLM
        model: IGNORADO (mantido para compatibilidade)
        temperature: Temperatura (0.0 = determin√≠stico, 1.0 = criativo)
        max_tokens: M√°ximo de tokens na resposta

    Returns:
        Resposta do LLM como string
    """
    from llm_providers import get_llm_response

    return get_llm_response(
        prompt=prompt,
        temperature=temperature,
        max_tokens=max_tokens
    )


# Alias para c√≥digo novo
send_to_llm = send_to_xai

def create_user_hash(identifier: str) -> str:
    """Cria hash √∫nico para usu√°rio"""
    return hashlib.sha256(identifier.encode()).hexdigest()[:16]

def format_conflict_for_display(conflict: Dict) -> str:
    """Formata conflito para exibi√ß√£o"""
    arch1 = conflict.get('archetype1', 'Arqu√©tipo 1')
    arch2 = conflict.get('archetype2', 'Arqu√©tipo 2')
    trigger = conflict.get('trigger', 'N√£o especificado')
    
    emoji_map = {
        'persona': 'üé≠',
        'sombra': 'üåë',
        'velho s√°bio': 'üßô',
        'velho_sabio': 'üßô',
        'anima': 'üí´'
    }
    
    emoji1 = emoji_map.get(arch1.lower(), '‚ùì')
    emoji2 = emoji_map.get(arch2.lower(), '‚ùì')
    
    return f"{emoji1} **{arch1.title()}** vs {emoji2} **{arch2.title()}**\nüéØ _{trigger}_"

def format_archetype_info(archetype_name: str) -> str:
    """Formata informa√ß√µes de um arqu√©tipo"""
    archetype = Config.ARCHETYPES.get(archetype_name)
    
    if not archetype:
        return f"‚ùì Arqu√©tipo '{archetype_name}' n√£o encontrado."
    
    emoji = archetype.get('emoji', '‚ùì')
    description = archetype.get('description', 'Sem descri√ß√£o')
    tendency = archetype.get('tendency', 'N/A')
    shadow = archetype.get('shadow', 'N/A')
    keywords = archetype.get('keywords', [])
    
    return f"""
{emoji} **{archetype_name.upper()}**

üìñ **Descri√ß√£o:**
{description}

‚ö° **Tend√™ncia:**
{tendency}

üåë **Sombra:**
{shadow}

üîë **Palavras-chave:**
{', '.join(keywords)}
""".strip()

# ============================================================
# ALIASES DE COMPATIBILIDADE
# ============================================================

# Alias para compatibilidade com c√≥digo legado
DatabaseManager = HybridDatabaseManager

# ============================================================
# INICIALIZA√á√ÉO
# ============================================================

try:
    Config.validate()
    logger.info("‚úÖ jung_core.py v4.0 - H√çBRIDO PREMIUM")
    logger.info(f"   ChromaDB: {'ATIVO' if CHROMADB_AVAILABLE else 'INATIVO'}")
    logger.info(f"   OpenAI Embeddings: {'ATIVO' if Config.OPENAI_API_KEY else 'INATIVO'}")
except ValueError as e:
    logger.error(f"‚ö†Ô∏è  {e}")

if __name__ == "__main__":
    logger.info("üß† Jung Core v4.0 - H√çBRIDO PREMIUM")
    logger.info("=" * 60)
    
    db = HybridDatabaseManager()
    logger.info("‚úÖ HybridDatabaseManager inicializado")
    
    engine = JungianEngine(db)
    logger.info("‚úÖ JungianEngine inicializado")
    
    logger.info("\nüìä Estat√≠sticas:")
    logger.info(f"  - Arqu√©tipos: {len(Config.ARCHETYPES)}")
    logger.info(f"  - SQLite: {Config.SQLITE_PATH}")
    logger.info(f"  - ChromaDB: {Config.CHROMA_PATH}")
    
    agent_state = db.get_agent_state()
    logger.info(f"  - Fase: {agent_state['phase']}/5")
    logger.info(f"  - Intera√ß√µes: {agent_state['total_interactions']}")
    
    # Teste
    logger.info("\nüß™ Testando send_to_xai...")
    try:
        test_response = send_to_xai("Diga apenas 'OK' se voc√™ est√° funcionando.", max_tokens=10)
        logger.info(f"‚úÖ send_to_xai funcionando: {test_response[:50]}...")
    except Exception as e:
        logger.error(f"‚ùå Erro ao testar send_to_xai: {e}")
    
    db.close()
    logger.info("\n‚úÖ Teste conclu√≠do!")