"""
An√°lise dos dados baixados do Railway
"""
import json
from datetime import datetime
from collections import Counter

print("="*80)
print("üî¨ AN√ÅLISE DE DADOS DO JUNG LAB (RAILWAY)")
print("="*80)

# Carregar dados
try:
    with open("railway_fragments.json", "r", encoding="utf-8") as f:
        fragments_data = json.load(f)
        fragments = fragments_data.get("fragments", [])
except FileNotFoundError:
    print("‚ùå Arquivo railway_fragments.json n√£o encontrado")
    fragments = []

try:
    with open("railway_tensions.json", "r", encoding="utf-8") as f:
        tensions_data = json.load(f)
        tensions = tensions_data.get("tensions", [])
except FileNotFoundError:
    print("‚ùå Arquivo railway_tensions.json n√£o encontrado")
    tensions = []

try:
    with open("railway_insights.json", "r", encoding="utf-8") as f:
        insights_data = json.load(f)
        insights = insights_data.get("insights", [])
except FileNotFoundError:
    print("‚ùå Arquivo railway_insights.json n√£o encontrado")
    insights = []

# ============================================================================
# AN√ÅLISE DE FRAGMENTOS
# ============================================================================
print("\nüìù FRAGMENTOS DE RUMINA√á√ÉO")
print("-" * 80)
print(f"Total de fragmentos: {len(fragments)}")

if fragments:
    # Estat√≠sticas de peso emocional
    weights = [f.get("emotional_weight", 0) for f in fragments]
    avg_weight = sum(weights) / len(weights) if weights else 0
    max_weight = max(weights) if weights else 0
    min_weight = min(weights) if weights else 0

    print(f"Peso emocional m√©dio: {avg_weight:.2f}")
    print(f"Peso emocional m√°ximo: {max_weight:.2f}")
    print(f"Peso emocional m√≠nimo: {min_weight:.2f}")

    # Tipos de contexto
    context_types = [f.get("context_type", "unknown") for f in fragments]
    context_counter = Counter(context_types)
    print(f"\nDistribui√ß√£o por tipo de contexto:")
    for ctx, count in context_counter.most_common():
        print(f"  - {ctx}: {count}")

    # Fragmentos mais recentes
    print(f"\nüìå 5 fragmentos mais recentes:")
    for i, f in enumerate(fragments[:5], 1):
        content = f.get("content", "")
        if len(content) > 80:
            content = content[:77] + "..."
        print(f"{i}. [{f.get('detected_at', 'N/A')}] (peso: {f.get('emotional_weight', 0):.2f}) {content}")

# ============================================================================
# AN√ÅLISE DE TENS√ïES
# ============================================================================
print("\n\n‚ö° TENS√ïES PSICOL√ìGICAS")
print("-" * 80)
print(f"Total de tens√µes: {len(tensions)}")

if tensions:
    # Status das tens√µes
    statuses = [t.get("status", "unknown") for t in tensions]
    status_counter = Counter(statuses)
    print(f"\nDistribui√ß√£o por status:")
    for status, count in status_counter.most_common():
        print(f"  - {status}: {count}")

    # Tipos de tens√£o
    types = [t.get("tension_type", "unknown") for t in tensions]
    type_counter = Counter(types)
    print(f"\nDistribui√ß√£o por tipo:")
    for ttype, count in type_counter.most_common():
        print(f"  - {ttype}: {count}")

    # Estat√≠sticas de maturidade
    maturities = [t.get("maturity_score", 0) for t in tensions]
    avg_maturity = sum(maturities) / len(maturities) if maturities else 0
    max_maturity = max(maturities) if maturities else 0

    print(f"\nMaturidade m√©dia: {avg_maturity:.3f}")
    print(f"Maturidade m√°xima: {max_maturity:.3f}")

    # Estat√≠sticas de evid√™ncias
    evidences = [t.get("evidence_count", 0) for t in tensions]
    avg_evidence = sum(evidences) / len(evidences) if evidences else 0
    max_evidence = max(evidences) if evidences else 0

    print(f"\nEvid√™ncias m√©dias: {avg_evidence:.2f}")
    print(f"Evid√™ncias m√°ximas: {max_evidence}")

    # An√°lise detalhada de cada tens√£o
    print(f"\nüìä AN√ÅLISE DETALHADA DAS TENS√ïES:")
    print("="*80)

    for idx, t in enumerate(tensions, 1):
        print(f"\nüî∏ TENS√ÉO #{idx}")
        print(f"   ID: {t.get('id')}")
        print(f"   Tipo: {t.get('tension_type')}")
        print(f"   Status: {t.get('status')}")

        # Polos
        pole_a = t.get('pole_a', '')
        pole_b = t.get('pole_b', '')
        if len(pole_a) > 60:
            pole_a = pole_a[:57] + "..."
        if len(pole_b) > 60:
            pole_b = pole_b[:57] + "..."
        print(f"   Polo A: {pole_a}")
        print(f"   Polo B: {pole_b}")

        # M√©tricas
        print(f"   Intensidade: {t.get('intensity', 0):.2f}")
        print(f"   Maturidade: {t.get('maturity_score', 0):.3f}")
        print(f"   Evid√™ncias: {t.get('evidence_count', 0)}")
        print(f"   Revisitas: {t.get('revisit_count', 0)}")

        # Fragmentos associados
        pole_a_ids = t.get('pole_a_fragment_ids', '[]')
        pole_b_ids = t.get('pole_b_fragment_ids', '[]')
        try:
            pole_a_list = json.loads(pole_a_ids) if isinstance(pole_a_ids, str) else pole_a_ids
            pole_b_list = json.loads(pole_b_ids) if isinstance(pole_b_ids, str) else pole_b_ids
            total_fragment_ids = len(pole_a_list) + len(pole_b_list)
            print(f"   Fragmentos associados: {total_fragment_ids} ({len(pole_a_list)} no polo A, {len(pole_b_list)} no polo B)")
        except:
            print(f"   Fragmentos associados: Erro ao parsear")

        # Datas
        first_detected = t.get('first_detected_at', '')
        last_revisited = t.get('last_revisited_at', '')
        last_evidence = t.get('last_evidence_at', '')

        if first_detected:
            try:
                detected_dt = datetime.fromisoformat(first_detected.replace('Z', '+00:00'))
                days_old = (datetime.now() - detected_dt.replace(tzinfo=None)).days
                print(f"   Idade: {days_old} dias (desde {first_detected[:10]})")
            except:
                print(f"   Primeira detec√ß√£o: {first_detected}")

        if last_revisited:
            print(f"   √öltima revisita: {last_revisited}")
        if last_evidence:
            print(f"   √öltima evid√™ncia: {last_evidence}")

        # Metadata
        metadata = t.get('metadata', '{}')
        try:
            metadata_dict = json.loads(metadata) if isinstance(metadata, str) else metadata
            if metadata_dict:
                print(f"   Metadata: {json.dumps(metadata_dict, ensure_ascii=False)[:100]}")
        except:
            pass

        print("-" * 80)

# ============================================================================
# AN√ÅLISE DE INSIGHTS
# ============================================================================
print("\n\nüí° INSIGHTS GERADOS")
print("-" * 80)
print(f"Total de insights: {len(insights)}")

if insights:
    # Status dos insights
    statuses = [i.get("status", "unknown") for i in insights]
    status_counter = Counter(statuses)
    print(f"\nDistribui√ß√£o por status:")
    for status, count in status_counter.most_common():
        print(f"  - {status}: {count}")

    # Tipos de insight
    types = [i.get("insight_type", "unknown") for i in insights]
    type_counter = Counter(types)
    print(f"\nDistribui√ß√£o por tipo:")
    for itype, count in type_counter.most_common():
        print(f"  - {itype}: {count}")

    # Insights detalhados
    print(f"\nüìå Insights gerados:")
    for i, insight in enumerate(insights[:5], 1):
        content = insight.get("content", "")
        if len(content) > 100:
            content = content[:97] + "..."
        print(f"{i}. [{insight.get('generated_at', 'N/A')}] (conf: {insight.get('confidence_score', 0):.2f}) {content}")

# ============================================================================
# DIAGN√ìSTICO
# ============================================================================
print("\n\nüêõ DIAGN√ìSTICO DO PROBLEMA")
print("="*80)

if len(tensions) == 0:
    print("‚ùå PROBLEMA: Nenhuma tens√£o detectada")
    print("   Solu√ß√£o: Sistema precisa detectar tens√µes primeiro")
elif len(insights) > 0:
    print("‚úÖ Sistema est√° gerando insights corretamente!")
else:
    print("üîç Tens√µes detectadas mas nenhum insight gerado")
    print("\nAnalisando motivos poss√≠veis...\n")

    # Verificar se alguma tens√£o est√° pronta para s√≠ntese
    MIN_MATURITY = 0.75
    MIN_EVIDENCE = 3
    MIN_DAYS = 2

    ready_count = 0
    for t in tensions:
        maturity = t.get('maturity_score', 0)
        evidence = t.get('evidence_count', 0)
        days_old = 0

        first_detected = t.get('first_detected_at', '')
        if first_detected:
            try:
                detected_dt = datetime.fromisoformat(first_detected.replace('Z', '+00:00'))
                days_old = (datetime.now() - detected_dt.replace(tzinfo=None)).days
            except:
                pass

        is_ready = (maturity >= MIN_MATURITY and
                   evidence >= MIN_EVIDENCE and
                   days_old >= MIN_DAYS)

        if is_ready:
            ready_count += 1

    print(f"Tens√µes prontas para s√≠ntese: {ready_count}/{len(tensions)}")

    if ready_count == 0:
        print("\n‚ö†Ô∏è NENHUMA TENS√ÉO EST√Å PRONTA PARA S√çNTESE")
        print("\nRequisitos para s√≠ntese:")
        print(f"  - Maturidade >= {MIN_MATURITY}")
        print(f"  - Evid√™ncias >= {MIN_EVIDENCE}")
        print(f"  - Idade >= {MIN_DAYS} dias")

        print("\nStatus atual das tens√µes:")
        for idx, t in enumerate(tensions, 1):
            maturity = t.get('maturity_score', 0)
            evidence = t.get('evidence_count', 0)
            days_old = 0

            first_detected = t.get('first_detected_at', '')
            if first_detected:
                try:
                    detected_dt = datetime.fromisoformat(first_detected.replace('Z', '+00:00'))
                    days_old = (datetime.now() - detected_dt.replace(tzinfo=None)).days
                except:
                    pass

            print(f"\n  Tens√£o #{idx}:")
            print(f"    Maturidade: {maturity:.3f} {'‚úÖ' if maturity >= MIN_MATURITY else '‚ùå'}")
            print(f"    Evid√™ncias: {evidence} {'‚úÖ' if evidence >= MIN_EVIDENCE else '‚ùå'}")
            print(f"    Idade: {days_old} dias {'‚úÖ' if days_old >= MIN_DAYS else '‚ùå'}")

        # Identificar o principal bloqueio
        avg_maturity = sum(t.get('maturity_score', 0) for t in tensions) / len(tensions)
        avg_evidence = sum(t.get('evidence_count', 0) for t in tensions) / len(tensions)
        avg_days = 0

        for t in tensions:
            first_detected = t.get('first_detected_at', '')
            if first_detected:
                try:
                    detected_dt = datetime.fromisoformat(first_detected.replace('Z', '+00:00'))
                    avg_days += (datetime.now() - detected_dt.replace(tzinfo=None)).days
                except:
                    pass
        avg_days = avg_days / len(tensions) if tensions else 0

        print(f"\nüìä M√âDIAS:")
        print(f"  - Maturidade m√©dia: {avg_maturity:.3f} (precisa: {MIN_MATURITY})")
        print(f"  - Evid√™ncias m√©dias: {avg_evidence:.2f} (precisa: {MIN_EVIDENCE})")
        print(f"  - Idade m√©dia: {avg_days:.1f} dias (precisa: {MIN_DAYS})")

        # Identificar principal bloqueio
        if avg_evidence < MIN_EVIDENCE:
            print(f"\nüéØ PRINCIPAL BLOQUEIO: Evid√™ncias insuficientes")
            print(f"   üìå evidence_count est√° em m√©dia {avg_evidence:.1f}, precisa de {MIN_EVIDENCE}")
            print(f"   üìå Isso confirma o bug: _count_related_fragments() retorna 0")
            print(f"\n   üîß SOLU√á√ÉO: Implementar busca sem√¢ntica de fragmentos relacionados")

print("\n" + "="*80)
print("‚úÖ An√°lise conclu√≠da!")
print("="*80)
