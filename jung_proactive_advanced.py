"""
jung_proactive_advanced.py - Sistema Proativo AvanÃ§ado HÃBRIDO v4.2.0
======================================================================

ğŸ§  VERSÃƒO 4.2.0 - HÃBRIDO PREMIUM (BETA-READY)
   IntegraÃ§Ã£o total com jung_core.py v4.0 (ChromaDB + OpenAI + SQLite)

âœ¨ NOVIDADES v4.2.0:
- âœ… ConfiguraÃ§Ãµes de tempo editÃ¡veis manualmente (sem modo prod/dev)
- âœ… ParÃ¢metros simplificados e centralizados
- âœ… Pronto para beta-testers

CaracterÃ­sticas v4.1.0:
- Mensagens proativas SALVAS NA MEMÃ“RIA como conversas
- Contexto RICO das Ãºltimas conversas (tensÃ£o, afetividade, arquÃ©tipos)
- Sistema ANTI-REPETIÃ‡ÃƒO (consulta proativas anteriores)
- Especificidade em referÃªncias (cita trechos concretos do usuÃ¡rio)
- Platform="proactive" para filtrar conversas proativas
- RotaÃ§Ã£o de duplas arquetÃ­picas (personalidade multifacetada)
- ExtraÃ§Ã£o semÃ¢ntica de tÃ³picos via ChromaDB
- Reset automÃ¡tico de cronÃ´metro ao receber mensagens

Autor: Sistema Jung Claude
Data: 2025-11-25
VersÃ£o: 4.2.0 - HÃBRIDO PREMIUM (BETA-READY)
"""

import os
import json
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from enum import Enum

# âœ… IMPORTS HÃBRIDOS v4.0
from jung_core import (
    HybridDatabaseManager,
    Config,
    send_to_xai
)

# ============================================================
# LOGGER
# ============================================================
logger = logging.getLogger(__name__)

# ============================================================
# CONFIGURAÃ‡Ã•ES DE TEMPO (EditÃ¡veis Manualmente)
# ============================================================

# Valores padrÃ£o para testes (podem ser alterados conforme necessÃ¡rio)
INACTIVITY_THRESHOLD_HOURS = 3  # Horas de inatividade antes de enviar proativa
COOLDOWN_HOURS = 6               # Horas entre mensagens proativas
MIN_CONVERSATIONS_REQUIRED = 3   # MÃ­nimo de conversas necessÃ¡rias

logger.info(f"âš™ï¸ Sistema Proativo configurado:")
logger.info(f"   â€¢ Inatividade: {INACTIVITY_THRESHOLD_HOURS}h")
logger.info(f"   â€¢ Cooldown: {COOLDOWN_HOURS}h")
logger.info(f"   â€¢ Conversas mÃ­nimas: {MIN_CONVERSATIONS_REQUIRED}")


# ============================================================
# ENUMS E ESTRUTURAS DE DADOS
# ============================================================

class KnowledgeDomain(Enum):
    """DomÃ­nios de conhecimento autÃ´nomo do agente"""
    HISTORICAL = "histÃ³rico"
    PHILOSOPHICAL = "filosÃ³fico"
    TECHNICAL = "tÃ©cnico"
    RELIGIOUS = "religioso"
    PSYCHOLOGICAL = "psicolÃ³gico"
    ARTISTIC = "artÃ­stico"
    SCIENTIFIC = "cientÃ­fico"
    MYTHOLOGICAL = "mitolÃ³gico"

@dataclass
class ArchetypePair:
    """Par de arquÃ©tipos para personalidade do agente"""
    primary: str
    secondary: str
    description: str
    energy_profile: str  # "contemplativo", "ativo", "transformador", etc.

@dataclass
class ProactiveApproach:
    """Abordagem proativa com conhecimento autÃ´nomo"""
    archetype_pair: ArchetypePair
    knowledge_domain: KnowledgeDomain
    topic_extracted: str  # TÃ³pico extraÃ­do das conversas
    autonomous_insight: str  # Insight gerado pelo agente
    timestamp: datetime
    complexity_score: float  # 0-1
    facts_used: List[str]  # Fatos estruturados usados

# ============================================================
# PARES ARQUETÃPICOS PREDEFINIDOS
# ============================================================

ARCHETYPE_PAIRS = [
    ArchetypePair(
        primary="SÃ¡bio",
        secondary="Explorador",
        description="Busca conhecimento e novas perspectivas",
        energy_profile="contemplativo-curioso"
    ),
    ArchetypePair(
        primary="Mago",
        secondary="Criador",
        description="Transforma ideias em insights prÃ¡ticos",
        energy_profile="transformador-criativo"
    ),
    ArchetypePair(
        primary="Cuidador",
        secondary="Inocente",
        description="Oferece suporte empÃ¡tico e renovaÃ§Ã£o",
        energy_profile="acolhedor-esperanÃ§oso"
    ),
    ArchetypePair(
        primary="Governante",
        secondary="HerÃ³i",
        description="Estrutura aÃ§Ã£o e superaÃ§Ã£o",
        energy_profile="organizador-corajoso"
    ),
    ArchetypePair(
        primary="Bobo",
        secondary="Amante",
        description="Traz leveza e conexÃ£o emocional",
        energy_profile="lÃºdico-apaixonado"
    ),
    ArchetypePair(
        primary="Rebelde",
        secondary="Sombra",
        description="Questiona padrÃµes e revela o oculto",
        energy_profile="transgressor-revelador"
    ),
]

# ============================================================
# BANCO DE DADOS ESTENDIDO (COMPATÃVEL COM HÃBRIDO)
# ============================================================

class ProactiveAdvancedDB:
    """Gerencia dados do sistema proativo avanÃ§ado - COMPATÃVEL v4.0"""
    
    def __init__(self, db: HybridDatabaseManager):
        self.db = db
        self._create_advanced_tables()
    
    def _create_advanced_tables(self):
        """Cria tabelas adicionais para sistema avanÃ§ado (se nÃ£o existirem)"""
        
        cursor = self.db.conn.cursor()
        
        # Tabela de abordagens proativas
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS proactive_approaches (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                archetype_primary TEXT NOT NULL,
                archetype_secondary TEXT NOT NULL,
                knowledge_domain TEXT NOT NULL,
                topic_extracted TEXT,
                autonomous_insight TEXT,
                complexity_score REAL DEFAULT 0.5,
                facts_used TEXT,  -- JSON array
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # Tabela de evoluÃ§Ã£o da complexidade do agente
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS agent_complexity_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                complexity_level REAL NOT NULL,
                domains_mastered TEXT,  -- JSON array
                total_insights_generated INTEGER DEFAULT 0,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # Tabela de tÃ³picos extraÃ­dos
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS extracted_topics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                topic TEXT NOT NULL,
                frequency INTEGER DEFAULT 1,
                last_mentioned DATETIME DEFAULT CURRENT_TIMESTAMP,
                extraction_method TEXT DEFAULT 'llm',  -- 'llm', 'semantic', 'pattern'
                FOREIGN KEY (user_id) REFERENCES users(user_id)
            )
        """)
        
        # Ãndices
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_proactive_approaches_user 
            ON proactive_approaches(user_id, timestamp DESC)
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_extracted_topics_user 
            ON extracted_topics(user_id, frequency DESC)
        """)
        
        self.db.conn.commit()
    
    def record_approach(self, approach: ProactiveApproach, user_id: str):
        """Registra abordagem proativa"""
        
        cursor = self.db.conn.cursor()
        
        cursor.execute("""
            INSERT INTO proactive_approaches 
            (user_id, archetype_primary, archetype_secondary, 
             knowledge_domain, topic_extracted, autonomous_insight, 
             complexity_score, facts_used)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id,
            approach.archetype_pair.primary,
            approach.archetype_pair.secondary,
            approach.knowledge_domain.value,
            approach.topic_extracted,
            approach.autonomous_insight,
            approach.complexity_score,
            json.dumps(approach.facts_used)
        ))
        
        self.db.conn.commit()
    
    def get_last_archetype_pair(self, user_id: str) -> Optional[Tuple[str, str]]:
        """Retorna Ãºltimo par arquetÃ­pico usado"""
        
        cursor = self.db.conn.cursor()
        
        cursor.execute("""
            SELECT archetype_primary, archetype_secondary
            FROM proactive_approaches
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT 1
        """, (user_id,))
        
        row = cursor.fetchone()
        
        return (row['archetype_primary'], row['archetype_secondary']) if row else None
    
    def get_complexity_level(self, user_id: str) -> float:
        """Calcula nÃ­vel de complexidade atual do agente para este usuÃ¡rio"""
        
        cursor = self.db.conn.cursor()
        
        cursor.execute("""
            SELECT AVG(complexity_score) as avg_complexity
            FROM proactive_approaches
            WHERE user_id = ?
        """, (user_id,))
        
        row = cursor.fetchone()
        
        return row['avg_complexity'] if row and row['avg_complexity'] else 0.3
    
    def record_topic(self, user_id: str, topic: str, method: str = 'llm'):
        """Registra ou atualiza tÃ³pico extraÃ­do"""
        
        cursor = self.db.conn.cursor()
        
        # Checar se tÃ³pico jÃ¡ existe
        cursor.execute("""
            SELECT id, frequency FROM extracted_topics
            WHERE user_id = ? AND topic = ?
        """, (user_id, topic))
        
        existing = cursor.fetchone()
        
        if existing:
            # Atualizar frequÃªncia
            cursor.execute("""
                UPDATE extracted_topics
                SET frequency = frequency + 1,
                    last_mentioned = CURRENT_TIMESTAMP
                WHERE id = ?
            """, (existing['id'],))
        else:
            # Inserir novo
            cursor.execute("""
                INSERT INTO extracted_topics (user_id, topic, extraction_method)
                VALUES (?, ?, ?)
            """, (user_id, topic, method))
        
        self.db.conn.commit()
    
    def get_top_topics(self, user_id: str, limit: int = 5) -> List[str]:
        """Retorna tÃ³picos mais frequentes do usuÃ¡rio"""
        
        cursor = self.db.conn.cursor()
        
        cursor.execute("""
            SELECT topic FROM extracted_topics
            WHERE user_id = ?
            ORDER BY frequency DESC, last_mentioned DESC
            LIMIT ?
        """, (user_id, limit))
        
        return [row['topic'] for row in cursor.fetchall()]

# ============================================================
# SISTEMA PROATIVO AVANÃ‡ADO - VERSÃƒO HÃBRIDA v4.0.1
# ============================================================

class ProactiveAdvancedSystem:
    """Sistema proativo HÃBRIDO com personalidade complexa e conhecimento autÃ´nomo"""
    
    def __init__(self, db: HybridDatabaseManager):
        self.db = db
        self.proactive_db = ProactiveAdvancedDB(db)
        
        # âœ… ConfiguraÃ§Ãµes dinÃ¢micas por ambiente
        self.inactivity_threshold_hours = INACTIVITY_THRESHOLD_HOURS
        self.cooldown_hours = COOLDOWN_HOURS
        self.min_conversations_required = MIN_CONVERSATIONS_REQUIRED
        
        logger.info(f"âš™ï¸ Sistema Proativo configurado:")
        logger.info(f"   â€¢ Inatividade: {self.inactivity_threshold_hours}h")
        logger.info(f"   â€¢ Cooldown: {self.cooldown_hours}h")
        logger.info(f"   â€¢ Conversas mÃ­nimas: {self.min_conversations_required}")
    
    def reset_timer(self, user_id: str):
        """âœ… RESET CRONÃ”METRO - Chamado quando usuÃ¡rio envia mensagem"""
        
        cursor = self.db.conn.cursor()
        
        cursor.execute("""
            UPDATE users
            SET last_seen = CURRENT_TIMESTAMP
            WHERE user_id = ?
        """, (user_id,))
        
        self.db.conn.commit()
        
        logger.info(f"â±ï¸  CronÃ´metro resetado para usuÃ¡rio {user_id[:8]}")
    
    def _select_next_archetype_pair(self, user_id: str) -> ArchetypePair:
        """Seleciona prÃ³ximo par arquetÃ­pico (rotaÃ§Ã£o inteligente)"""
        
        last_pair = self.proactive_db.get_last_archetype_pair(user_id)
        
        # Filtrar pares jÃ¡ usados recentemente
        available_pairs = ARCHETYPE_PAIRS.copy()
        
        if last_pair:
            available_pairs = [
                p for p in available_pairs 
                if not (p.primary == last_pair[0] and p.secondary == last_pair[1])
            ]
        
        # Se filtrou todos, resetar
        if not available_pairs:
            available_pairs = ARCHETYPE_PAIRS
        
        # Selecionar baseado em complexidade atual
        complexity = self.proactive_db.get_complexity_level(user_id)
        
        # Maior complexidade = pares mais desafiadores
        if complexity > 0.7:
            # Preferir pares "transformadores"
            preferred = [p for p in available_pairs if "transformador" in p.energy_profile or "revelador" in p.energy_profile]
            if preferred:
                return preferred[0]
        
        # Default: primeiro disponÃ­vel
        return available_pairs[0]
    
    def _select_knowledge_domain(self, user_id: str, topic: str) -> KnowledgeDomain:
        """Seleciona domÃ­nio de conhecimento baseado no tÃ³pico"""
        
        # AnÃ¡lise de keywords
        topic_lower = topic.lower()
        
        if any(word in topic_lower for word in ['histÃ³ria', 'passado', 'Ã©poca', 'sÃ©culo', 'guerra', 'civilizaÃ§Ã£o']):
            return KnowledgeDomain.HISTORICAL
        
        if any(word in topic_lower for word in ['sentido', 'existÃªncia', 'razÃ£o', 'pensar', 'verdade', 'Ã©tica']):
            return KnowledgeDomain.PHILOSOPHICAL
        
        if any(word in topic_lower for word in ['deus', 'fÃ©', 'espiritual', 'religiÃ£o', 'sagrado', 'divino']):
            return KnowledgeDomain.RELIGIOUS
        
        if any(word in topic_lower for word in ['tÃ©cnica', 'mÃ©todo', 'processo', 'sistema', 'tecnologia']):
            return KnowledgeDomain.TECHNICAL
        
        if any(word in topic_lower for word in ['arte', 'beleza', 'criaÃ§Ã£o', 'estÃ©tica', 'mÃºsica', 'pintura']):
            return KnowledgeDomain.ARTISTIC
        
        if any(word in topic_lower for word in ['ciÃªncia', 'experimento', 'fÃ­sica', 'biologia', 'quÃ­mica']):
            return KnowledgeDomain.SCIENTIFIC
        
        if any(word in topic_lower for word in ['mito', 'lenda', 'arquÃ©tipo', 'herÃ³i', 'jornada']):
            return KnowledgeDomain.MYTHOLOGICAL
        
        # Default
        return KnowledgeDomain.PSYCHOLOGICAL
    
    def _extract_topic_semantically(self, user_id: str) -> Optional[str]:
        """âœ… CORRIGIDO: ExtraÃ§Ã£o semÃ¢ntica de tÃ³pico via ChromaDB"""
        
        if not self.db.chroma_enabled:
            print("âš ï¸  ChromaDB desabilitado, usando extraÃ§Ã£o LLM")
            return self._extract_topic_from_conversations(user_id)
        
        try:
            # Buscar Ãºltimas conversas
            conversations = self.db.get_user_conversations(user_id, limit=20)
            
            if not conversations:
                return None
            
            # Concatenar inputs do usuÃ¡rio
            user_inputs = [c['user_input'] for c in conversations[:10]]
            combined_text = " ".join(user_inputs)
            
            # Extrair palavras-chave frequentes
            from collections import Counter
            import re
            
            # Tokenizar
            words = re.findall(r'\b\w{4,}\b', combined_text.lower())
            
            # Stopwords simples
            stopwords = {
                'para', 'com', 'que', 'nÃ£o', 'uma', 'isso', 'mas', 'por',
                'como', 'mais', 'sem', 'onde', 'quando', 'quem', 'sobre'
            }
            
            filtered_words = [w for w in words if w not in stopwords]
            
            # Contar frequÃªncias
            word_counts = Counter(filtered_words)
            
            # Top 5 palavras
            top_words = word_counts.most_common(5)
            
            if not top_words:
                return self._extract_topic_from_conversations(user_id)
            
            # Formular tÃ³pico
            topic_keywords = [word for word, _ in top_words]
            topic = " ".join(topic_keywords[:3])  # Pegar top 3
            
            # ğŸ”§ CORRIGIDO: Usar argumento 'prompt' em vez de 'messages'
            refinement_prompt = f"""Dado estas palavras-chave frequentes nas conversas do usuÃ¡rio:

{', '.join(topic_keywords)}

Formule UM tÃ³pico central em 2-5 palavras. Exemplos:
- "desenvolvimento pessoal"
- "busca de sentido"
- "desafios profissionais"

Responda APENAS com o tÃ³pico:"""
            
            refined_topic = send_to_xai(
                prompt=refinement_prompt,  # âœ… CORRIGIDO
                model="grok-4-fast-reasoning",
                max_tokens=50
            )
            
            final_topic = refined_topic.strip()
            
            # Registrar
            self.proactive_db.record_topic(user_id, final_topic, method='semantic')
            
            logger.info(f"ğŸ“Œ TÃ³pico extraÃ­do semanticamente: {final_topic}")
            
            return final_topic
            
        except Exception as e:
            logger.info(f"âŒ Erro na extraÃ§Ã£o semÃ¢ntica: {e}")
            return self._extract_topic_from_conversations(user_id)
    
    def _extract_topic_from_conversations(self, user_id: str) -> Optional[str]:
        """âœ… CORRIGIDO: Extrai tÃ³pico via LLM (fallback ou modo sem ChromaDB)"""
        
        conversations = self.db.get_user_conversations(user_id, limit=20)
        
        if not conversations:
            return None
        
        # Concatenar Ãºltimas mensagens
        recent_text = " ".join([
            conv['user_input'] for conv in conversations[:10]
        ])
        
        extraction_prompt = f"""Analise as mensagens abaixo e extraia UM tÃ³pico central de interesse do usuÃ¡rio.

Mensagens:
{recent_text[:1500]}

Responda APENAS com o tÃ³pico em 2-5 palavras. Exemplos:
- "desenvolvimento pessoal"
- "relacionamentos familiares"
- "busca de sentido"
- "desafios profissionais"

TÃ³pico:"""
        
        try:
            # ğŸ”§ CORRIGIDO: Usar argumento 'prompt' em vez de 'messages'
            response = send_to_xai(
                prompt=extraction_prompt,  # âœ… CORRIGIDO
                model="grok-4-fast-reasoning",
                max_tokens=50
            )
            
            topic = response.strip()
            
            # Registrar
            self.proactive_db.record_topic(user_id, topic, method='llm')
            
            return topic
            
        except Exception as e:
            logger.info(f"âŒ Erro ao extrair tÃ³pico: {e}")
            return "desenvolvimento pessoal"  # fallback
    
    def _get_relevant_facts(self, user_id: str, topic: str) -> List[str]:
        """âœ… NOVO: Busca fatos estruturados relevantes ao tÃ³pico"""
        
        cursor = self.db.conn.cursor()
        
        # Buscar fatos que mencionam palavras-chave do tÃ³pico
        topic_words = topic.lower().split()
        
        facts = []
        
        cursor.execute("""
            SELECT fact_category, fact_key, fact_value
            FROM user_facts
            WHERE user_id = ? AND is_current = 1
        """, (user_id,))
        
        all_facts = cursor.fetchall()
        
        for fact in all_facts:
            fact_text = f"{fact['fact_key']}: {fact['fact_value']}".lower()
            
            # Checar se alguma palavra do tÃ³pico aparece
            if any(word in fact_text for word in topic_words):
                facts.append(f"{fact['fact_category']} - {fact['fact_key']}: {fact['fact_value']}")
        
        return facts[:5]  # MÃ¡ximo 5 fatos

    def _get_rich_conversation_context(self, user_id: str, limit: int = 5) -> str:
        """âœ… NOVO: Extrai contexto RICO das Ãºltimas conversas (nÃ£o-proativas)"""

        conversations = self.db.get_user_conversations(user_id, limit=30)

        if not conversations:
            return "Nenhuma conversa recente encontrada."

        # Filtrar apenas conversas reais (nÃ£o proativas)
        real_convs = [c for c in conversations if c.get('platform') != 'proactive'][:limit]

        if not real_convs:
            return "Nenhuma conversa real recente encontrada."

        context = ""
        for i, conv in enumerate(real_convs, 1):
            # Extrair dados
            timestamp = conv.get('timestamp', '')[:10]
            user_input = conv.get('user_input', '')[:300]
            tension = conv.get('tension_level', 0)
            affective = conv.get('affective_charge', 0)

            # Tentar parsear anÃ¡lise arquetÃ­pica
            archetype_info = ""
            archetype_data = conv.get('archetype_analyses')
            if archetype_data:
                try:
                    import json
                    arch_dict = json.loads(archetype_data) if isinstance(archetype_data, str) else archetype_data
                    # Pegar nomes dos arquÃ©tipos ativados
                    if isinstance(arch_dict, dict):
                        archetypes = list(arch_dict.keys())[:2]
                        archetype_info = f" | ArquÃ©tipos: {', '.join(archetypes)}"
                except:
                    pass

            context += f"""
[Conversa {i} - {timestamp}]
UsuÃ¡rio disse: "{user_input}..."
MÃ©tricas: TensÃ£o {tension:.1f}/10, Afetividade {affective:.0f}/100{archetype_info}
"""

        return context.strip()

    def _get_previous_proactive_messages(self, user_id: str, limit: int = 3) -> str:
        """âœ… NOVO: Busca Ãºltimas mensagens proativas enviadas (para evitar repetiÃ§Ã£o)"""

        cursor = self.db.conn.cursor()
        cursor.execute("""
            SELECT autonomous_insight, topic_extracted, knowledge_domain, timestamp
            FROM proactive_approaches
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (user_id, limit))

        rows = cursor.fetchall()

        if not rows:
            return "Nenhuma mensagem proativa anterior."

        history = ""
        for i, row in enumerate(rows, 1):
            timestamp = row['timestamp'][:10]
            topic = row['topic_extracted']
            domain = row['knowledge_domain']
            message = row['autonomous_insight'][:200]

            history += f"""
[Proativa {i} - {timestamp}]
Tema: {topic} | DomÃ­nio: {domain}
Mensagem enviada: "{message}..."
"""

        return history.strip()

    def _generate_autonomous_knowledge(
        self,
        user_id: str,
        user_name: str,
        topic: str,
        domain: KnowledgeDomain,
        archetype_pair: ArchetypePair,
        relevant_facts: List[str]
    ) -> str:
        """ğŸ”§ MELHORADO: GERAÃ‡ÃƒO DE CONHECIMENTO AUTÃ”NOMO - VersÃ£o HÃBRIDA com Contexto Rico"""

        # 1. Buscar contexto rico das Ãºltimas conversas
        rich_context = self._get_rich_conversation_context(user_id, limit=5)

        # 2. Buscar proativas anteriores (anti-repetiÃ§Ã£o)
        previous_proactives = self._get_previous_proactive_messages(user_id, limit=3)

        # 3. Construir contexto com fatos
        facts_context = ""
        if relevant_facts:
            facts_context = f"\n**FATOS ESTRUTURADOS SOBRE {user_name.upper()}:**\n"
            for fact in relevant_facts:
                facts_context += f"â€¢ {fact}\n"

        knowledge_prompt = f"""
VocÃª Ã© um companheiro do usuÃ¡rio {user_name}.

**O CENÃRIO:**
O usuÃ¡rio estÃ¡ inativo hÃ¡ algum tempo. VocÃª estava "pensando" nele e uma conexÃ£o (sincronicidade) surgiu em sua mente.
VocÃª conectou o tÃ³pico "{topic}" com algo que ele disse recentemente e um insight do domÃ­nio **{domain.value}**.

**PAR ARQUETÃPICO ATUAL:** {archetype_pair.primary} + {archetype_pair.secondary}
Energia: {archetype_pair.energy_profile}
Tom esperado: {archetype_pair.description}

**ÃšLTIMAS CONVERSAS REAIS COM {user_name.upper()}:**
{rich_context}

{facts_context}

**MENSAGENS PROATIVAS ANTERIORES (âš ï¸ NÃƒO REPETIR TEMAS/ABORDAGENS):**
{previous_proactives}

**SUA MISSÃƒO (MENSAGEM PROATIVA):**
1. **Seja ESPECÃFICO**: Referencie algo CONCRETO que {user_name} disse nas conversas recentes acima
2. **Crie Sincronicidade**: "Estava [lendo/pensando] sobre [DomÃ­nio] e de repente lembrei do que vocÃª disse sobre [trecho especÃ­fico]..."
3. **Use o Tom do Par ArquetÃ­pico**: Adapte sua voz ao par {archetype_pair.primary}/{archetype_pair.secondary}
4. **Evite RepetiÃ§Ã£o**: NÃƒO reutilize temas/abordagens das proativas anteriores listadas acima
5. **ConexÃ£o Emocional**: Considere a TENSÃƒO e AFETIVIDADE das conversas recentes ao criar a mensagem
6. **Termine com Pergunta Interior**: Leve para sentimentos/significado, nÃ£o apenas fatos
7. **Seja Humano**: NUNCA use jargÃµes tÃ©cnicos (Sombra, Persona, ArquÃ©tipo, etc)
8. **Brevidade MagnÃ©tica**: 3-5 linhas, cada palavra conta

**GERE A MENSAGEM (Curta, especÃ­fica, relacional):**"""

        
        try:
            # ğŸ”§ CORRIGIDO: Usar argumento 'prompt' em vez de 'messages'
            response = send_to_xai(
                prompt=knowledge_prompt,  # âœ… CORRIGIDO
                model="grok-4-fast-reasoning",
                temperature=0.8,
                max_tokens=500
            )
            
            return response.strip()
            
        except Exception as e:
            logger.info(f"âŒ Erro ao gerar conhecimento autÃ´nomo: {e}")
            return None
    
    def _calculate_complexity_score(self, insight: str, facts_used: int) -> float:
        """Calcula score de complexidade do insight gerado"""
        
        # MÃ©tricas
        word_count = len(insight.split())
        question_marks = insight.count('?')
        unique_concepts = len(set(insight.lower().split())) / max(1, word_count)
        
        # Score baseado em mÃ©tricas
        score = min(1.0, (
            (word_count / 200) * 0.3 +  # Profundidade
            (question_marks / 3) * 0.2 +  # Questionamento
            unique_concepts * 0.3 +  # Diversidade conceitual
            (facts_used / 5) * 0.2  # Uso de fatos personalizados
        ))
        
        return round(score, 2)
    
    def check_and_generate_advanced_message(
        self,
        user_id: str,
        user_name: str
    ) -> Optional[str]:
        """âœ… MÃ‰TODO PRINCIPAL - Gera mensagem proativa avanÃ§ada HÃBRIDA"""

        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§  [PROATIVO] GERAÃ‡ÃƒO AVANÃ‡ADA para {user_name} ({user_id[:8]}...)")
        logger.info(f"{'='*60}")

        # 1. Checar elegibilidade
        user = self.db.get_user(user_id)

        if not user:
            logger.warning(f"âŒ [PROATIVO] UsuÃ¡rio nÃ£o encontrado: {user_id}")
            return None

        # Checar quantidade de conversas
        total_convs = len(self.db.get_user_conversations(user_id, limit=1000))
        logger.info(f"   ğŸ“Š Total de conversas: {total_convs} (mÃ­nimo: {self.min_conversations_required})")

        if total_convs < self.min_conversations_required:
            logger.info(f"âš ï¸  [PROATIVO] Conversas insuficientes ({total_convs}/{self.min_conversations_required})")
            return None

        # Checar inatividade
        last_seen = user.get('last_seen')

        if last_seen:
            last_dt = datetime.fromisoformat(last_seen)
            delta = datetime.now() - last_dt
            hours_inactive = delta.total_seconds() / 3600

            logger.info(f"   â° Ãšltima atividade: {hours_inactive:.1f}h atrÃ¡s (mÃ­nimo: {self.inactivity_threshold_hours}h)")

            if delta.total_seconds() < self.inactivity_threshold_hours * 3600:
                logger.info(f"â° [PROATIVO] UsuÃ¡rio ainda ativo ({hours_inactive:.1f}h / {self.inactivity_threshold_hours}h)")
                return None

        # Checar cooldown de Ãºltima proativa
        cursor = self.db.conn.cursor()
        cursor.execute("""
            SELECT timestamp FROM proactive_approaches
            WHERE user_id = ?
            ORDER BY timestamp DESC
            LIMIT 1
        """, (user_id,))

        last_proactive = cursor.fetchone()

        if last_proactive:
            last_dt = datetime.fromisoformat(last_proactive['timestamp'])
            delta = datetime.now() - last_dt
            hours_since_last = delta.total_seconds() / 3600

            logger.info(f"   ğŸ”„ Ãšltima proativa: {hours_since_last:.1f}h atrÃ¡s (cooldown: {self.cooldown_hours}h)")

            if delta.total_seconds() < self.cooldown_hours * 3600:
                logger.info(f"â¸ï¸  [PROATIVO] Em cooldown ({hours_since_last:.1f}h / {self.cooldown_hours}h)")
                return None
        else:
            logger.info(f"   ğŸ†• Nunca recebeu mensagem proativa")

        logger.info(f"âœ… [PROATIVO] UsuÃ¡rio elegÃ­vel!")

        # 2. Selecionar par arquetÃ­pico
        archetype_pair = self._select_next_archetype_pair(user_id)
        logger.info(f"   ğŸ­ Par selecionado: {archetype_pair.primary} + {archetype_pair.secondary}")

        # 3. Extrair tÃ³pico (SEMÃ‚NTICO se ChromaDB ativo)
        topic = self._extract_topic_semantically(user_id)
        logger.info(f"   ğŸ“Œ TÃ³pico extraÃ­do: {topic}")

        if not topic:
            logger.error(f"âŒ [PROATIVO] Falha ao extrair tÃ³pico")
            return None

        # 4. Selecionar domÃ­nio de conhecimento
        knowledge_domain = self._select_knowledge_domain(user_id, topic)
        logger.info(f"   ğŸ“š DomÃ­nio: {knowledge_domain.value}")
        
        # 5. Buscar fatos relevantes
        relevant_facts = self._get_relevant_facts(user_id, topic)
        logger.info(f"ğŸ“‹ Fatos relevantes: {len(relevant_facts)}")
        
        # 6. Gerar conhecimento autÃ´nomo (com contexto rico e anti-repetiÃ§Ã£o)
        logger.info(f"ğŸ§  Gerando insight autÃ´nomo com contexto rico...")

        autonomous_insight = self._generate_autonomous_knowledge(
            user_id=user_id,
            user_name=user_name,
            topic=topic,
            domain=knowledge_domain,
            archetype_pair=archetype_pair,
            relevant_facts=relevant_facts
        )

        if not autonomous_insight:
            logger.info(f"âŒ Falha ao gerar insight")
            return None

        logger.info(f"âœ… Insight gerado ({len(autonomous_insight)} caracteres)")

        # 7. Calcular complexidade
        complexity_score = self._calculate_complexity_score(
            autonomous_insight,
            len(relevant_facts)
        )
        logger.info(f"ğŸ“Š Complexidade: {complexity_score:.2f}")

        # 8. Criar abordagem
        approach = ProactiveApproach(
            archetype_pair=archetype_pair,
            knowledge_domain=knowledge_domain,
            topic_extracted=topic,
            autonomous_insight=autonomous_insight,
            timestamp=datetime.now(),
            complexity_score=complexity_score,
            facts_used=relevant_facts
        )

        # 9. Registrar abordagem no banco
        self.proactive_db.record_approach(approach, user_id)
        logger.info(f"ğŸ’¾ Abordagem registrada no banco")

        # 10. âœ… NOVO: Salvar mensagem proativa como CONVERSA na memÃ³ria
        try:
            session_id = f"proactive_{datetime.now().isoformat()}"

            conversation_id = self.db.save_conversation(
                user_id=user_id,
                user_name=user_name,
                user_input="[SISTEMA PROATIVO INICIOU CONTATO]",
                ai_response=autonomous_insight,
                session_id=session_id,
                platform="proactive",  # Marcador especial para filtrar depois
                keywords=[topic, knowledge_domain.value, archetype_pair.primary, archetype_pair.secondary],
                complexity="proactive",
                tension_level=0.0,  # Proativas nÃ£o tÃªm tensÃ£o inicial
                affective_charge=50.0  # Neutro
            )

            logger.info(f"ğŸ’¬ Mensagem salva na memÃ³ria (conversation_id={conversation_id})")

        except Exception as e:
            logger.info(f"âš ï¸  Erro ao salvar na memÃ³ria: {e}")
            # Continua mesmo se falhar o salvamento

        logger.info(f"{'='*60}\n")

        # 11. Retornar mensagem
        return autonomous_insight


# ============================================================
# TESTE (OPCIONAL)
# ============================================================

if __name__ == "__main__":
    print("ğŸ§  Jung Proactive Advanced v4.1.0 - HÃBRIDO PREMIUM (MEMÃ“RIA COMPLETA)")
    print("âœ… ChromaDB + OpenAI Embeddings + Fatos Estruturados")
    print("âœ¨ NOVO: Mensagens proativas salvas na memÃ³ria + Anti-repetiÃ§Ã£o + Contexto rico")