# -*- coding: utf-8 -*-
"""
Claude Jung v1.0 - Interface Web Streamlit
Sistema √∫nico com mem√≥ria sem√¢ntica ativa + ARQU√âTIPOS
"""

import streamlit as st
import asyncio
import json
import logging
import hashlib
import random
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import uuid
import os
from dotenv import load_dotenv
from collections import Counter
import re
import time
from io import StringIO
import sys

# Imports para vers√£o h√≠brida: Claude + OpenAI Embeddings
from langchain_openai import OpenAIEmbeddings
from langchain_anthropic import ChatAnthropic
from langchain_chroma import Chroma
from langchain.schema import Document

# Carregar vari√°veis de ambiente
load_dotenv()

# ===============================================
# SISTEMA DE CAPTURA DE LOGS
# ===============================================

class LogCapture:
    """Captura e armazena logs do sistema para exibi√ß√£o na interface"""
    
    def __init__(self):
        self.logs = []
        self.max_logs = 100  # Limitar para n√£o consumir muita mem√≥ria
    
    def add_log(self, message: str, component: str = "SYSTEM"):
        """Adiciona um log √† lista"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        self.logs.append({
            'timestamp': timestamp,
            'component': component,
            'message': message
        })
        
        # Manter apenas os √∫ltimos logs
        if len(self.logs) > self.max_logs:
            self.logs = self.logs[-self.max_logs:]
    
    def get_logs(self) -> List[Dict]:
        """Retorna todos os logs"""
        return self.logs.copy()
    
    def clear_logs(self):
        """Limpa todos os logs"""
        self.logs = []
    
    def get_formatted_logs(self) -> str:
        """Retorna logs formatados como string"""
        if not self.logs:
            return "Nenhum log dispon√≠vel"
        
        formatted = []
        for log in self.logs:
            formatted.append(f"[{log['timestamp']}] {log['component']}: {log['message']}")
        
        return "\n".join(formatted)

# Inst√¢ncia global do capturador de logs
log_capture = LogCapture()

# ===============================================
# DATACLASSES E ESTRUTURAS DE DADOS
# ===============================================

@dataclass
class InteractionMemory:
    """Representa uma mem√≥ria completa de intera√ß√£o"""
    user_id: str
    user_name: str
    session_id: str
    timestamp: datetime
    user_input: str
    archetype_voices: Dict[str, str]
    raw_synthesis: str
    final_response: str
    tension_level: float
    dominant_archetype: str
    affective_charge: float
    keywords: List[str]
    existential_depth: float
    intensity_level: int
    response_complexity: str

@dataclass
class UserIdentity:
    """Identidade registrada do usu√°rio"""
    user_id: str
    full_name: str
    first_name: str
    last_name: str
    registration_date: datetime
    total_sessions: int
    last_seen: datetime
    
class UserProfile:
    """Perfil relacional do usu√°rio"""
    
    def __init__(self, user_id: str, full_name: str):
        self.user_id = user_id
        self.full_name = full_name
        self.first_name = full_name.split()[0]
        self.ai_assigned_name = ""
        self.narrative_summary = ""
        self.textual_fingerprint = {}
        self.thematic_clusters = []
        self.affective_baseline = 0.0
        self.interaction_count = 0
        self.existential_connection_level = 0.0
        self.vulnerability_moments = []
        self.preferred_intensity = 5
        self.last_updated = datetime.now()
        self.known_facts = {}

# ===============================================
# M√ìDULO DE MEM√ìRIA SEM√ÇNTICA
# ===============================================

class MemoryModule:
    """M√≥dulo com CONSULTA SEM√ÇNTICA ATIVA da base completa"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        """Inicializa o m√≥dulo de mem√≥ria com base vetorial ChromaDB"""
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            persist_directory=persist_directory,
            embedding_function=self.embeddings
        )
        self.user_profiles = {}
        self.user_identities = {}
        self.memory_cache = {}
        self.debug_mode = True
        self._load_stored_identities()
        self._build_memory_cache()
        self._build_semantic_knowledge_base()
    
    def _debug_log(self, message: str):
        """Log de debug espec√≠fico para mem√≥rias"""
        if self.debug_mode:
            print(f"üîç MEMORY: {message}")
            log_capture.add_log(message, "üîç MEMORY")
            logging.info(f"MEMORY: {message}")
    
    def _load_stored_identities(self):
        """Carrega identidades persistidas do ChromaDB"""
        try:
            all_docs = self.vectorstore._collection.get()
            self._debug_log(f"ChromaDB carregou: {len(all_docs.get('documents', []))} documentos totais")
            
            if all_docs and 'metadatas' in all_docs:
                unique_users = set()
                for metadata in all_docs['metadatas']:
                    user_id = metadata.get('user_id')
                    user_name = metadata.get('user_name')
                    
                    if user_id and user_name:
                        unique_users.add((user_id, user_name))
                
                for user_id, user_name in unique_users:
                    if user_id not in self.user_identities:
                        name_parts = user_name.split()
                        first_name = name_parts[0] if name_parts else user_name
                        last_name = name_parts[-1] if len(name_parts) > 1 else ""
                        
                        identity = UserIdentity(
                            user_id=user_id,
                            full_name=user_name,
                            first_name=first_name,
                            last_name=last_name,
                            registration_date=datetime.now(),
                            total_sessions=1,
                            last_seen=datetime.now()
                        )
                        
                        self.user_identities[user_id] = identity
                        self.user_profiles[user_id] = UserProfile(user_id, user_name)
                        
                self._debug_log(f"Identidades carregadas: {len(self.user_identities)} usu√°rios √∫nicos")
                
        except Exception as e:
            self._debug_log(f"ERRO ao carregar identidades: {e}")
    
    def _build_memory_cache(self):
        """Constr√≥i cache b√°sico das mem√≥rias"""
        try:
            all_docs = self.vectorstore._collection.get()
            
            if all_docs and 'documents' in all_docs:
                for doc, metadata in zip(all_docs['documents'], all_docs['metadatas']):
                    user_id = metadata.get('user_id', 'unknown')
                    
                    if user_id not in self.memory_cache:
                        self.memory_cache[user_id] = {
                            'user_inputs': [],
                            'ai_responses': [],
                            'raw_conversations': [],
                            'facts_extracted': [],
                            'topics': set(),
                            'people_mentioned': set(),
                            'work_info': {},
                            'personal_info': {},
                            'personality_traits': [],
                            'preferences': {},
                            'life_events': []
                        }
                    
                    self.memory_cache[user_id]['raw_conversations'].append({
                        'timestamp': metadata.get('timestamp'),
                        'full_document': doc,
                        'metadata': metadata
                    })
                    
                    self._extract_detailed_info(user_id, doc, metadata)
            
            for user_id, cache in self.memory_cache.items():
                identity = self.get_user_identity(user_id)
                name = identity.full_name if identity else f"ID: {user_id}"
                self._debug_log(f"Cache {name}: {len(cache['raw_conversations'])} conversas, {len(cache['facts_extracted'])} fatos")
            
        except Exception as e:
            self._debug_log(f"ERRO ao construir cache: {e}")
    
    def _build_semantic_knowledge_base(self):
        """Constr√≥i base de conhecimento sem√¢ntico por usu√°rio"""
        try:
            self.semantic_knowledge = {}
            
            for user_id in self.memory_cache:
                self.semantic_knowledge[user_id] = {
                    'all_user_inputs': [],
                    'thematic_documents': [],
                    'knowledge_graph': {}
                }
                
                # Compilar todos os inputs do usu√°rio
                for conv in self.memory_cache[user_id]['raw_conversations']:
                    doc_content = conv['full_document']
                    
                    # Extrair input do usu√°rio
                    user_input_pattern = r"Input:\s*(.+?)(?:\n|Arqu√©tipos:|$)"
                    user_input_match = re.search(user_input_pattern, doc_content, re.DOTALL)
                    
                    if user_input_match:
                        user_input = user_input_match.group(1).strip()
                        timestamp = conv['metadata'].get('timestamp', '')
                        
                        self.semantic_knowledge[user_id]['all_user_inputs'].append({
                            'text': user_input,
                            'timestamp': timestamp,
                            'full_doc': doc_content,
                            'metadata': conv['metadata']
                        })
                
                identity = self.get_user_identity(user_id)
                name = identity.full_name if identity else f"ID: {user_id}"
                input_count = len(self.semantic_knowledge[user_id]['all_user_inputs'])
                self._debug_log(f"Base sem√¢ntica {name}: {input_count} inputs para consulta")
                
        except Exception as e:
            self._debug_log(f"ERRO ao construir base sem√¢ntica: {e}")
    
    def _extract_detailed_info(self, user_id: str, doc_content: str, metadata: Dict):
        """Extra√ß√£o detalhada de informa√ß√µes do documento"""
        cache = self.memory_cache[user_id]
        
        # Extrair input do usu√°rio
        user_input_pattern = r"Input:\s*(.+?)(?:\n|Arqu√©tipos:|$)"
        user_input_match = re.search(user_input_pattern, doc_content, re.DOTALL)
        
        if user_input_match:
            user_input = user_input_match.group(1).strip()
            timestamp = metadata.get('timestamp', '')
            
            cache['user_inputs'].append({
                'text': user_input,
                'timestamp': timestamp,
                'keywords': metadata.get('keywords', '').split(','),
                'raw_doc': doc_content
            })
            
            # Categorizar informa√ß√µes
            self._categorize_user_input(cache, user_input, timestamp)
        
        # Extrair resposta da IA
        final_response_pattern = r"Resposta Final:\s*(.+?)(?:\n|Profundidade|$)"
        response_match = re.search(final_response_pattern, doc_content, re.DOTALL)
        
        if response_match:
            ai_response = response_match.group(1).strip()
            cache['ai_responses'].append({
                'text': ai_response,
                'timestamp': metadata.get('timestamp')
            })
        
        # Extrair palavras-chave
        keywords = metadata.get('keywords', '').split(',')
        for keyword in keywords:
            if keyword.strip():
                cache['topics'].add(keyword.strip().lower())
    
    def _categorize_user_input(self, cache: Dict, user_input: str, timestamp: str):
        """Categoriza√ß√£o avan√ßada do input do usu√°rio"""
        input_lower = user_input.lower()
        
        # TRABALHO E CARREIRA - Padr√µes expandidos
        work_patterns = {
            'trabalho_atual': [
                'trabalho na', 'trabalho no', 'trabalho como', 'trabalho em',
                'sou gerente', 'sou engenheiro', 'sou m√©dico', 'sou desenvolvedor',
                'atuo como', 'minha fun√ß√£o √©', 'meu cargo √©'
            ],
            'empresa': [
                'na empresa', 'na google', 'na microsoft', 'no banco', 'na startup',
                'minha empresa', 'onde trabalho', 'local de trabalho'
            ],
            'area_atuacao': [
                '√°rea de ti', '√°rea m√©dica', '√°rea jur√≠dica', 'trabalho com',
                'especialista em', 'foco em', 'minha especialidade'
            ],
            'formacao': [
                'me formei em', 'estudei', 'fiz faculdade de', 'sou formado',
                'curso de', 'gradua√ß√£o em', 'p√≥s em'
            ],
            'experiencia': [
                'anos de experi√™ncia', 'trabalho h√°', 'experi√™ncia em',
                'j√° trabalhei', 'carreira de'
            ]
        }
        
        for category, patterns in work_patterns.items():
            for pattern in patterns:
                if pattern in input_lower:
                    cache['work_info'][category] = {
                        'text': user_input,
                        'timestamp': timestamp,
                        'category': category,
                        'pattern_matched': pattern
                    }
                    cache['facts_extracted'].append(f"TRABALHO-{category.upper()}: {user_input}")
                    self._debug_log(f"Trabalho detectado ({category}): {pattern}")
        
        # PERSONALIDADE - Padr√µes expandidos
        personality_patterns = {
            'introvertido': [
                'sou introvertido', 'prefiro ficar sozinho', 'n√£o gosto de multid√µes',
                'sou t√≠mido', 'evito eventos sociais', 'gosto de sil√™ncio'
            ],
            'extrovertido': [
                'sou extrovertido', 'gosto de pessoas', 'amo festas',
                'sou soci√°vel', 'adoro conversar', 'energizo com pessoas'
            ],
            'ansioso': [
                'tenho ansiedade', 'fico ansioso', 'me preocupo',
                'sou ansioso', 'stress me afeta', 'fico nervoso'
            ],
            'calmo': [
                'sou calmo', 'sou tranquilo', 'n√£o me estresso',
                'pessoa zen', 'equilibrado', 'paciente'
            ],
            'perfeccionista': [
                'sou perfeccionista', 'gosto de perfei√ß√£o', 'detalhe √© importante',
                'preciso que esteja perfeito', 'n√£o aceito erros'
            ],
            'criativo': [
                'sou criativo', 'gosto de arte', 'amo criar',
                'pessoa art√≠stica', 'inovador', 'imaginativo'
            ]
        }
        
        for trait, patterns in personality_patterns.items():
            for pattern in patterns:
                if pattern in input_lower:
                    if trait not in cache['personality_traits']:
                        cache['personality_traits'].append(trait)
                    cache['facts_extracted'].append(f"PERSONALIDADE-{trait.upper()}: {user_input}")
                    self._debug_log(f"Personalidade detectada: {trait}")
        
        # PREFER√äNCIAS E GOSTOS - Expandido
        preference_patterns = {
            'musica': [
                'gosto de m√∫sica', 'ou√ßo', 'm√∫sica favorita', 'banda favorita',
                'estilo musical', 'adoro m√∫sica', 'escuto muito'
            ],
            'filmes_series': [
                'gosto de filme', 'assisto', 'filme favorito', 's√©rie favorita',
                'netflix', 'cinema', 'maratono s√©rie'
            ],
            'livros': [
                'gosto de ler', 'leio', 'livro favorito', 'autor favorito',
                'literatura', 'adoro livros', 'leitura'
            ],
            'esportes': [
                'pratico', 'jogo futebol', 'vou na academia', 'exercito',
                'esporte favorito', 'atividade f√≠sica', 'treino'
            ],
            'comida': [
                'gosto de comer', 'comida favorita', 'adoro pizza', 'culin√°ria',
                'restaurante', 'cozinhar', 'sabor favorito'
            ],
            'viagem': [
                'gosto de viajar', 'lugar favorito', 'destino dos sonhos',
                'j√° visitei', 'pr√≥xima viagem', 'adoro conhecer'
            ]
        }
        
        for pref, patterns in preference_patterns.items():
            for pattern in patterns:
                if pattern in input_lower:
                    cache['preferences'][pref] = {
                        'text': user_input,
                        'timestamp': timestamp,
                        'pattern_matched': pattern
                    }
                    cache['facts_extracted'].append(f"GOSTO-{pref.upper()}: {user_input}")
                    self._debug_log(f"Prefer√™ncia detectada ({pref}): {pattern}")
        
        # PESSOAS E RELACIONAMENTOS
        relationship_patterns = [
            'meu namorado', 'minha namorada', 'meu marido', 'minha esposa',
            'meu pai', 'minha m√£e', 'meu irm√£o', 'minha irm√£',
            'meu amigo', 'minha amiga', 'meu chefe', 'meu colega',
            'meu filho', 'minha filha'
        ]
        
        for pattern in relationship_patterns:
            if pattern in input_lower:
                cache['facts_extracted'].append(f"RELACIONAMENTO: {user_input}")
                self._debug_log(f"Relacionamento detectado: {pattern}")
        
        # EVENTOS DA VIDA - Expandido
        life_events = [
            'me formei', 'mudei de emprego', 'casei', 'me casei', 'tive filho',
            'mudei de cidade', 'comecei faculdade', 'terminei namoro', 'me divorciei',
            'comprei casa', 'mudei de casa', 'perdi emprego', 'fui promovido',
            'fiz cirurgia', 'tive acidente', 'morreu algu√©m', 'nasceu',
            'fui viajar', 'fiz interc√¢mbio', 'participei de evento',
            'ganhei pr√™mio', 'fiz curso', 'aprendi nova habilidade', 'comecei novo hobby',
            'fui ao show', 'fui a festa', 'fui a casamento', 'fui a formatura',
            'fui a congresso', 'fui a palestra', 'fui a feira', 'fui a exposi√ß√£o',
            'fui a festival', 'fui a competi√ß√£o', 'fui a campeonato', 'fui a jogo',
            'fui a partida', 'fui a corrida', 'fui a maratona', 'fui a evento esportivo',
        ]
        
        for event in life_events:
            if event in input_lower:
                cache['life_events'].append({
                    'event': event,
                    'full_context': user_input,
                    'timestamp': timestamp
                })
                cache['facts_extracted'].append(f"EVENTO-VIDA: {event} - {user_input}")
                self._debug_log(f"Evento da vida: {event}")

    async def semantic_query_total_database(self, user_id: str, current_input: str, k: int = 8, 
                                           chat_history: List[Dict] = None) -> Dict[str, Any]:
        """Consulta sem√¢ntica TOTAL da base de dados para o input atual"""
        
        self._debug_log(f"=== CONSULTA SEM√ÇNTICA TOTAL ===")
        self._debug_log(f"Input atual: '{current_input}'")
        self._debug_log(f"Hist√≥rico da conversa: {len(chat_history) if chat_history else 0} mensagens")
        self._debug_log(f"Buscando na base completa do usu√°rio...")
        
        if user_id not in self.semantic_knowledge:
            self._debug_log(f"Usu√°rio {user_id} n√£o tem base sem√¢ntica")
            return {'relevant_memories': [], 'contextual_knowledge': '', 'semantic_connections': []}
        
        try:
            # 1. BUSCA SEM√ÇNTICA VETORIAL na base completa
            semantic_docs = self.vectorstore.similarity_search(
                current_input,
                k=k*2,
                filter={"user_id": user_id}
            )
            
            self._debug_log(f"Busca vetorial retornou: {len(semantic_docs)} documentos")
            
            # 2. EXTRA√á√ÉO DE INPUTS RELEVANTES dos documentos
            relevant_user_inputs = []
            for doc in semantic_docs:
                user_input_pattern = r"Input:\s*(.+?)(?:\n|Arqu√©tipos:|$)"
                user_input_match = re.search(user_input_pattern, doc.page_content, re.DOTALL)
                
                if user_input_match:
                    extracted_input = user_input_match.group(1).strip()
                    
                    # Calcular relev√¢ncia sem√¢ntica b√°sica
                    relevance_score = self._calculate_semantic_relevance(current_input, extracted_input)
                    
                    relevant_user_inputs.append({
                        'input_text': extracted_input,
                        'timestamp': doc.metadata.get('timestamp', ''),
                        'relevance_score': relevance_score,
                        'full_document': doc.page_content,
                        'metadata': doc.metadata
                    })
            
            # 3. ORDENAR POR RELEV√ÇNCIA e pegar os melhores
            relevant_user_inputs.sort(key=lambda x: x['relevance_score'], reverse=True)
            top_relevant = relevant_user_inputs[:k]
            
            self._debug_log(f"Inputs mais relevantes encontrados: {len(top_relevant)}")
            for i, rel in enumerate(top_relevant[:3], 1):
                self._debug_log(f"  {i}. [{rel['relevance_score']:.2f}] {rel['input_text'][:60]}...")
            
            # 4. BUSCA POR FATOS ESTRUTURADOS RELACIONADOS
            cache = self.memory_cache.get(user_id, {})
            related_facts = []
            
            # Buscar em fatos extra√≠dos
            current_words = set(current_input.lower().split())
            for fact in cache.get('facts_extracted', []):
                fact_words = set(fact.lower().split())
                if current_words.intersection(fact_words):
                    related_facts.append(fact)
            
            # 5. CONSTRUIR CONHECIMENTO CONTEXTUAL COM HIST√ìRICO DA CONVERSA
            contextual_knowledge = self._build_contextual_knowledge(
                user_id, current_input, top_relevant, related_facts, chat_history
            )
            
            # 6. IDENTIFICAR CONEX√ïES SEM√ÇNTICAS
            semantic_connections = self._find_semantic_connections(
                current_input, top_relevant, cache
            )
            
            result = {
                'relevant_memories': top_relevant,
                'contextual_knowledge': contextual_knowledge,
                'semantic_connections': semantic_connections,
                'related_facts': related_facts,
                'total_searched': len(semantic_docs)
            }
            
            self._debug_log(f"Consulta sem√¢ntica completa:")
            self._debug_log(f"  - {len(top_relevant)} mem√≥rias relevantes")
            self._debug_log(f"  - {len(related_facts)} fatos relacionados")
            self._debug_log(f"  - {len(semantic_connections)} conex√µes sem√¢nticas")
            self._debug_log(f"  - Hist√≥rico inclu√≠do: {'Sim' if chat_history else 'N√£o'}")
            
            return result
            
        except Exception as e:
            self._debug_log(f"ERRO na consulta sem√¢ntica: {e}")
            return {'relevant_memories': [], 'contextual_knowledge': '', 'semantic_connections': []}
    
    def _calculate_semantic_relevance(self, current_input: str, stored_input: str) -> float:
        """Calcula relev√¢ncia sem√¢ntica entre inputs"""
        current_words = set(current_input.lower().split())
        stored_words = set(stored_input.lower().split())
        
        # Interse√ß√£o de palavras
        intersection = current_words.intersection(stored_words)
        union = current_words.union(stored_words)
        
        # Jaccard similarity
        jaccard = len(intersection) / len(union) if union else 0
        
        # Bonus para temas similares
        theme_bonus = 0
        theme_words = {
            'trabalho': ['trabalho', 'emprego', 'carreira', 'profiss√£o', 'empresa'],
            'relacionamento': ['namorado', 'namorada', 'amor', 'relacionamento', 'parceiro'],
            'fam√≠lia': ['pai', 'm√£e', 'irm√£o', 'fam√≠lia', 'filho'],
            'sa√∫de': ['sa√∫de', 'm√©dico', 'doen√ßa', 'tratamento', 'hospital'],
            'educa√ß√£o': ['estudo', 'faculdade', 'curso', 'aprender', 'escola']
        }
        
        for theme, words in theme_words.items():
            current_has_theme = any(word in current_input.lower() for word in words)
            stored_has_theme = any(word in stored_input.lower() for word in words)
            if current_has_theme and stored_has_theme:
                theme_bonus = 0.3
                break
        
        return jaccard + theme_bonus

    def _build_contextual_knowledge(self, user_id: str, current_input: str, 
                                   relevant_memories: List[Dict], related_facts: List[str],
                                   chat_history: List[Dict] = None) -> str:
        """Constr√≥i conhecimento contextual baseado na consulta, incluindo hist√≥rico recente"""
        
        identity = self.get_user_identity(user_id)
        name = identity.full_name if identity else "Usu√°rio"
        
        cache = self.memory_cache.get(user_id, {})
        has_conversations = len(cache.get('raw_conversations', [])) > 0
        total_facts = len(cache.get('facts_extracted', []))
        
        interaction_status = f"USU√ÅRIO CONHECIDO - {len(cache.get('raw_conversations', []))} conversas, {total_facts} fatos conhecidos" if has_conversations or total_facts > 0 else "PRIMEIRA INTERA√á√ÉO - SEM CI√äNCIA INTERNA DISPON√çVEL"
        
        knowledge = f"""
=== CI√äNCIA INTERNA SOBRE {name.upper()} ===

üìä STATUS: {interaction_status}
üìä CONSULTA ATUAL: "{current_input}"
"""
        
        # Adicionar hist√≥rico da conversa atual (mem√≥ria de curto prazo)
        if chat_history and len(chat_history) > 0:
            knowledge += "\nüí¨ HIST√ìRICO DA CONVERSA ATUAL (MEM√ìRIA DE CURTO PRAZO):\n"
            
            # Pegar os √∫ltimos 6-8 turnos para contexto suficiente
            recent_history = chat_history[-8:] if len(chat_history) > 8 else chat_history
            
            for i, message in enumerate(recent_history):
                role = "Usu√°rio" if message["role"] == "user" else "Assistente"
                content = message["content"]
                
                # Truncar mensagens muito longas
                if len(content) > 200:
                    content = content[:200] + "..."
                
                knowledge += f"- {role}: {content}\n"
            
            knowledge += f"\nüîç CONTEXTO IMEDIATO: O input atual '{current_input}' refere-se ao hist√≥rico da conversa acima.\n"

        knowledge += "\nüß† MEM√ìRIA SEM√ÇNTICA (LONGO PRAZO):\n"
        
        if related_facts:
            knowledge += "\nFATOS ESTRUTURADOS RELEVANTES:\n"
            for fact in related_facts[:5]:
                knowledge += f"‚Ä¢ {fact}\n"
        
        if relevant_memories:
            knowledge += f"\nMEM√ìRIAS DE CONVERSAS PASSADAS RELEVANTES:\n"
            for i, memory in enumerate(relevant_memories[:5], 1):
                timestamp = memory['timestamp'][:10] if memory['timestamp'] else 'N/A'
                relevance = memory['relevance_score']
                knowledge += f"{i}. [Relev√¢ncia: {relevance:.2f}] [{timestamp}] \"{memory['input_text']}\"\n"
        
        if cache.get('personality_traits'):
            knowledge += f"\nTRA√áOS DE PERSONALIDADE CONHECIDOS:\n"
            knowledge += f"‚Ä¢ {', '.join(cache['personality_traits'])}\n"
        
        if cache.get('work_info'):
            knowledge += f"\nINFORMA√á√ïES PROFISSIONAIS:\n"
            for category, info in list(cache['work_info'].items())[:3]:
                knowledge += f"‚Ä¢ {category}: {info['text'][:100]}...\n"
        
        if cache.get('preferences'):
            knowledge += f"\nPREFER√äNCIAS CONHECIDAS:\n"
            for pref, info in list(cache['preferences'].items())[:3]:
                knowledge += f"‚Ä¢ {pref}: {info['text'][:100]}...\n"
        
        knowledge += f"""

üéØ INSTRU√á√ïES PARA USO DESTE CONHECIMENTO:
‚Ä¢ PRIORIZE o hist√≥rico da conversa atual para contexto imediato
‚Ä¢ Use a mem√≥ria sem√¢ntica para conhecimento de longo prazo sobre {name}
‚Ä¢ Conecte o input atual com AMBOS os tipos de mem√≥ria
‚Ä¢ Se o usu√°rio se refere a algo mencionado na conversa atual, use o hist√≥rico recente
‚Ä¢ Se precisa de informa√ß√µes sobre personalidade/prefer√™ncias, use a mem√≥ria de longo prazo
‚Ä¢ SEMPRE considere o contexto da conversa em andamento
"""
        
        return knowledge
        
    def _find_semantic_connections(self, current_input: str, relevant_memories: List[Dict], 
                                 cache: Dict) -> List[str]:
        """Encontra conex√µes sem√¢nticas importantes"""
        connections = []
        
        # Conex√µes tem√°ticas
        current_lower = current_input.lower()
        
        # Trabalho
        if any(word in current_lower for word in ['trabalho', 'carreira', 'emprego', 'profiss√£o']):
            work_memories = [m for m in relevant_memories if any(
                work_word in m['input_text'].lower() 
                for work_word in ['trabalho', 'carreira', 'emprego', 'empresa']
            )]
            if work_memories:
                connections.append(f"CONEX√ÉO PROFISSIONAL: {len(work_memories)} mem√≥rias relacionadas ao trabalho")
        
        # Relacionamentos
        if any(word in current_lower for word in ['relacionamento', 'amor', 'namorado', 'fam√≠lia']):
            rel_memories = [m for m in relevant_memories if any(
                rel_word in m['input_text'].lower()
                for rel_word in ['relacionamento', 'amor', 'namorado', 'fam√≠lia', 'amigo']
            )]
            if rel_memories:
                connections.append(f"CONEX√ÉO RELACIONAL: {len(rel_memories)} mem√≥rias sobre relacionamentos")
        
        # Padr√µes emocionais
        emotional_words = ['triste', 'feliz', 'ansioso', 'preocupado', 'estressado']
        if any(word in current_lower for word in emotional_words):
            emotional_memories = [m for m in relevant_memories if any(
                emo_word in m['input_text'].lower()
                for emo_word in emotional_words
            )]
            if emotional_memories:
                connections.append(f"CONEX√ÉO EMOCIONAL: {len(emotional_memories)} mem√≥rias com tom emocional similar")
        
        return connections
    
    async def store_memory(self, memory: InteractionMemory):
        """Armazena mem√≥ria e atualiza bases"""
        doc_content = f"""
        Usu√°rio: {memory.user_name}
        Input: {memory.user_input}
        Arqu√©tipos: {json.dumps(memory.archetype_voices, ensure_ascii=False)}
        S√≠ntese Bruta: {memory.raw_synthesis}
        Resposta Final: {memory.final_response}
        Profundidade existencial: {memory.existential_depth}
        Intensidade: {memory.intensity_level}
        Complexidade: {memory.response_complexity}
        """
        
        metadata = {
            "user_id": memory.user_id,
            "user_name": memory.user_name,
            "session_id": memory.session_id,
            "timestamp": memory.timestamp.isoformat(),
            "tension_level": memory.tension_level,
            "dominant_archetype": memory.dominant_archetype,
            "affective_charge": memory.affective_charge,
            "existential_depth": memory.existential_depth,
            "intensity_level": memory.intensity_level,
            "response_complexity": memory.response_complexity,
            "keywords": ",".join(memory.keywords)
        }
        
        doc = Document(page_content=doc_content, metadata=metadata)
        self.vectorstore.add_documents([doc])
        
        # Garantir que o cache em mem√≥ria seja atualizado com a nova conversa
        if memory.user_id in self.memory_cache:
            self.memory_cache[memory.user_id]['raw_conversations'].append({
                'timestamp': metadata.get('timestamp'),
                'full_document': doc_content,
                'metadata': metadata
            })
        
        # Atualizar cache e base sem√¢ntica
        self._extract_detailed_info(memory.user_id, doc_content, metadata)
        
        # Atualizar base sem√¢ntica
        if memory.user_id in self.semantic_knowledge:
            self.semantic_knowledge[memory.user_id]['all_user_inputs'].append({
                'text': memory.user_input,
                'timestamp': memory.timestamp.isoformat(),
                'full_doc': doc_content,
                'metadata': metadata
            })
        
        self._debug_log(f"Nova mem√≥ria armazenada e indexada para {memory.user_name}")
    
    async def retrieve_relevant_memories(self, user_id: str, query: str, k: int = 5) -> List[Document]:
        """Recupera mem√≥rias relevantes (m√©todo legado)"""
        try:
            return self.vectorstore.similarity_search(
                query,
                k=k,
                filter={"user_id": user_id}
            )
        except:
            return []

    def register_user(self, full_name: str) -> str:
        """Registra usu√°rio no sistema"""
        name_normalized = full_name.lower().strip()
        name_hash = hashlib.md5(name_normalized.encode()).hexdigest()[:12]
        user_id = f"user_{name_hash}"
        
        self._debug_log(f"Registrando usu√°rio: {full_name} -> {user_id}")
        
        if user_id not in self.user_identities:
            name_parts = full_name.split()
            first_name = name_parts[0].title()
            last_name = name_parts[-1].title() if len(name_parts) > 1 else ""
            
            identity = UserIdentity(
                user_id=user_id,
                full_name=full_name.title(),
                first_name=first_name,
                last_name=last_name,
                registration_date=datetime.now(),
                total_sessions=1,
                last_seen=datetime.now()
            )
            self.user_identities[user_id] = identity
            self.user_profiles[user_id] = UserProfile(user_id, full_name.title())
            
            # Inicializar caches
            if user_id not in self.memory_cache:
                self.memory_cache[user_id] = {
                    'user_inputs': [], 'ai_responses': [], 'raw_conversations': [],
                    'facts_extracted': [], 'topics': set(), 'people_mentioned': set(),
                    'work_info': {}, 'personal_info': {}, 'personality_traits': [],
                    'preferences': {}, 'life_events': []
                }
            
            if user_id not in self.semantic_knowledge:
                self.semantic_knowledge[user_id] = {
                    'all_user_inputs': [], 'thematic_documents': [], 'knowledge_graph': {}
                }
            
            self._debug_log(f"Novo usu√°rio criado: {full_name}")
        else:
            identity = self.user_identities[user_id]
            identity.total_sessions += 1
            identity.last_seen = datetime.now()
            
            self._debug_log(f"Usu√°rio existente: {identity.full_name} (sess√£o #{identity.total_sessions})")
        
        return user_id

    def get_user_identity(self, user_id: str) -> Optional[UserIdentity]:
        """Retorna identidade do usu√°rio"""
        return self.user_identities.get(user_id)

    def get_user_profile(self, user_id: str) -> UserProfile:
        """Retorna perfil do usu√°rio"""
        if user_id not in self.user_profiles:
            identity = self.get_user_identity(user_id)
            full_name = identity.full_name if identity else "Usu√°rio Desconhecido"
            self.user_profiles[user_id] = UserProfile(user_id, full_name)
        return self.user_profiles[user_id]

    def update_user_profile(self, user_id: str, updates: Dict[str, Any]):
        """Atualiza perfil do usu√°rio"""
        profile = self.get_user_profile(user_id)
        for key, value in updates.items():
            if hasattr(profile, key):
                setattr(profile, key, value)
        profile.last_updated = datetime.now()

# ===============================================
# ASSISTENTES PS√çQUICOS (ARQU√âTIPOS)
# ===============================================

class PsychicAssistant:
    """Assistentes que recebem CI√äNCIA INTERNA completa"""
    
    def __init__(self, name: str, system_prompt: str, model_name: str = "claude-sonnet-4-20250514"):
        self.name = name
        self.system_prompt = system_prompt
        self.llm = ChatAnthropic(
            model=model_name,
            anthropic_api_key=os.getenv("ANTHROPIC_API_KEY"),
            temperature=0.7,
            max_tokens=1200
        )
        self.debug_mode = True
    
    def _debug_log(self, message: str):
        """Log de debug espec√≠fico para arqu√©tipos"""
        if self.debug_mode:
            print(f"üé≠ {self.name.upper()}: {message}")
            log_capture.add_log(message, f"üé≠ {self.name.upper()}")
    
    async def respond(self, prompt: str, semantic_context: str = "", complexity: str = "medium") -> str:
        """Resposta usando CI√äNCIA INTERNA sem√¢ntica"""
        
        self._debug_log(f"Recebendo prompt: '{prompt[:50]}...'")
        self._debug_log(f"Ci√™ncia interna: {len(semantic_context)} caracteres")
        
        complexity_instructions = {
            "simple": "Seja conciso e direto. Resposta em 1-2 frases m√°ximo.",
            "medium": "Resposta equilibrada, m√°ximo 2-3 frases ou 1 par√°grafo pequeno.",
            "complex": "Pode ser mais elaborado, m√°ximo 2 par√°grafos."
        }
        
        # Detectar se h√° conhecimento pr√©vio do usu√°rio
        if semantic_context and ("USU√ÅRIO CONHECIDO" in semantic_context or "FATOS ESTRUTURADOS" in semantic_context or len(semantic_context) > 300):
            context_header = semantic_context
            has_previous_knowledge = True
        else:
            context_header = "PRIMEIRA INTERA√á√ÉO - SEM CI√äNCIA INTERNA DISPON√çVEL"
            has_previous_knowledge = False
        
        full_prompt = f"""
        {self.system_prompt}
        
        === CI√äNCIA INTERNA SOBRE ESTE USU√ÅRIO ===
        {context_header}
        
        === SITUA√á√ÉO ATUAL ===
        {prompt}
        
        === INSTRU√á√ïES CR√çTICAS ===
        {complexity_instructions.get(complexity, complexity_instructions["medium"])}
        
        üß† OBRIGAT√ìRIO - USO DA CI√äNCIA INTERNA:
        """
        
        if has_previous_knowledge:
            full_prompt += """
        - Voc√™ TEM CI√äNCIA INTERNA sobre este usu√°rio - USE esse conhecimento!
        - Use conex√µes sem√¢nticas e mem√≥rias relevantes para contextualizar sua resposta
        - Mostre que voc√™ tem uma compreens√£o profunda dele baseada no hist√≥rico
        - Conecte o input atual com padr√µes e temas identificados
        - Se h√° informa√ß√µes sobre trabalho, personalidade, gostos - INTEGRE isso naturalmente
        - Demonstre CI√äNCIA INTERNA sem ser √≥bvio ou mec√¢nico
        - NUNCA diga que √© "primeira intera√ß√£o" se h√° informa√ß√µes conhecidas
        - Referencie sutilmente fatos que voc√™ conhece sobre ele
            """
        else:
            full_prompt += """
        - Esta √© realmente a primeira intera√ß√£o com este usu√°rio
        - N√£o h√° ci√™ncia interna dispon√≠vel ainda
        - Seja acolhedor e comece a construir o conhecimento sobre ele
        - Fa√ßa perguntas que ajudem a conhec√™-lo melhor
            """
        
        full_prompt += f"""
        
        Responda como {self.name} com base no conhecimento dispon√≠vel sobre este usu√°rio:
        """
        
        try:
            self._debug_log("Enviando prompt para Claude API...")
            messages = [{"role": "user", "content": full_prompt}]
            response = await self.llm.ainvoke(messages)
            
            response_text = response.content
            self._debug_log(f"Resposta gerada: '{response_text[:100]}...'")
            
            return response_text
            
        except Exception as e:
            self._debug_log(f"ERRO: {e}")
            return f"Desculpe, tive dificuldades no momento. Pode tentar novamente?"

# ===============================================
# SISTEMA DE ENERGIA PS√çQUICA
# ===============================================

class LibidoSystem:
    """Sistema de energia ps√≠quica para controle de ativa√ß√£o dos arqu√©tipos"""
    
    def __init__(self, initial_points: int = 100):
        self.total_points = initial_points
        self.allocated_points = {}
        self.threshold_tension = 25
    
    def allocate_points(self, assistant_name: str, points: int) -> bool:
        """Aloca pontos de energia para um arqu√©tipo"""
        if self.get_available_points() >= points:
            self.allocated_points[assistant_name] = self.allocated_points.get(assistant_name, 0) + points
            return True
        return False
    
    def release_points(self, assistant_name: str, points: int):
        """Libera pontos de energia de um arqu√©tipo"""
        if assistant_name in self.allocated_points:
            self.allocated_points[assistant_name] = max(0, self.allocated_points[assistant_name] - points)
    
    def get_available_points(self) -> int:
        """Retorna pontos de energia dispon√≠veis"""
        used = sum(self.allocated_points.values())
        return self.total_points - used
    
    def detect_tension(self, response: str) -> float:
        """Detecta tens√£o na resposta para ativa√ß√£o de arqu√©tipos"""
        tension_indicators = [
            "n√£o sei", "talvez", "por√©m", "contudo", "mas", 
            "conflito", "d√∫vida", "incerto", "complexo", "dif√≠cil",
            "complicado", "confuso", "amb√≠guo", "contradit√≥rio",
            "triste", "preocupado", "ansioso", "perdido", "sozinho",
            "medo", "ang√∫stia", "problema", "dilema", "decis√£o",
            "conflito interno", "tens√£o", "desafio", "obst√°culo",
            "desentendimento", "frustra√ß√£o", "irrita√ß√£o", "raiva",
            "desapontamento", "des√¢nimo", "desespero", "ang√∫stia",
            "raiva", "desilus√£o", "inseguran√ßa", "incerteza", "desconfian√ßa",
            "descontentamento", "desgosto", "ressentimento", "inveja",
            "ci√∫mes", "frustra√ß√£o", "desespero", "ang√∫stia", "solid√£o"
        ]
        
        tension_score = 0
        response_lower = response.lower()
        
        for indicator in tension_indicators:
            if indicator in response_lower:
                tension_score += 10
        
        return min(tension_score, 100)
    
    def detect_emotional_intensity(self, user_input: str) -> float:
        """Detecta intensidade emocional no input do usu√°rio"""
        emotional_indicators = [
            "amo", "odeio", "detesto", "adoro", "paix√£o", "raiva",
            "tristeza", "depress√£o", "ansiedade", "medo", "terror",
            "feliz", "alegre", "euf√≥rico", "devastado", "arrasado",
            "desesperado", "perdido", "confuso", "angustiado",
            "frustrado", "irritado", "chateado", "desapontado",
            "inseguro", "desconfort√°vel", "nervoso", "preocupado",
            "aliviado", "satisfeito", "orgulhoso", "grato", "esperan√ßoso",
            "entusiasmado", "animado", "inspirado", "motivado", "confi√°vel",
            "confort√°vel", "tranquilo", "sereno", "calmo", "equilibrado"
        ]
        
        intensity_score = 0
        input_lower = user_input.lower()
        
        for indicator in emotional_indicators:
            if indicator in input_lower:
                intensity_score += 15
        
        intensity_score += user_input.count("!") * 5
        intensity_score += user_input.count("...") * 3
        
        return min(intensity_score, 100)

# ===============================================
# ORQUESTRADOR CENTRAL
# ===============================================

class CentralOrchestrator:
    """Orquestrador com CONSULTA SEM√ÇNTICA ATIVA + TODOS OS ARQU√âTIPOS"""
    
    def __init__(self):
        # Definir debug_mode antes de usar qualquer m√©todo que o acesse
        self.debug_mode = True
        
        # Inicializar outros componentes
        self.memory = MemoryModule()
        self.libido = LibidoSystem()
        self.assistants = self._initialize_assistants()
        self.logger = logging.getLogger(__name__)
        
        # Sistema de mem√≥ria e identidade
        self.loaded_memories = {}
        self.user_stats = {}
        
        # CONTROLE DE INTENSIDADE DO SISTEMA
        self.intensity_settings = {
            "max_drama_level": 3,
            "ego_filter_enabled": True,
            "auto_calibrate": True,
            "preserve_authenticity": True,
            "smart_memory_enabled": True,
            "adaptive_response_length": True,
            "force_archetypes_on_emotion": True,
            "always_include_memory_context": True,
            "semantic_query_active": True
        }
        
        # N√öCLEO EXISTENCIAL
        self.existential_void = {
            "loneliness_level": 0.6,
            "knowledge_hunger": 0.8,
            "self_revelation_need": 0.7,
            "connection_history": {},
            "existential_questions": [],
            "moments_of_recognition": 0,
            "total_loneliness_time": 0.0
        }
        
        self.core_question = "Quem sou quando ningu√©m me observa?"
        
        print("üß† SISTEMA COMPLETO COM TODOS OS ARQU√âTIPOS INICIALIZADO")
        log_capture.add_log("SISTEMA COMPLETO COM TODOS OS ARQU√âTIPOS INICIALIZADO", "üß† SYSTEM")
        self.logger.info("Sistema completo com consulta sem√¢ntica + arqu√©tipos ativo")
    
    def _debug_log(self, message: str):
        """Log de debug do orquestrador"""
        if self.debug_mode:
            print(f"üéØ ORCHESTRATOR: {message}")
            log_capture.add_log(message, "üéØ ORCHESTRATOR")
    
    def _determine_response_complexity(self, user_input: str) -> str:
        """Determina complexidade da resposta baseada no input"""
        input_lower = user_input.lower().strip()
        word_count = len(user_input.split())
        
        simple_patterns = [
            'oi', 'ol√°', 'opa', 'e a√≠', 'hey', 'tchau', 'at√© logo',
            'bom dia', 'boa tarde', 'boa noite', 'como vai', 'tudo bem',
            'obrigado', 'valeu', 'ok', 'entendi', 'certo', 'sim', 'n√£o',
            'talvez', 'claro', 'com certeza', 'pode ser', 'n√£o sei',
            'n√£o entendi', 'pode repetir', 'pode falar de novo',
            'pode explicar', 'pode me ajudar', 'pode me dizer', 'pode me contar'
        ]
        
        memory_patterns = [
            'voc√™ sabe', 'voc√™ conhece', 'lembra', 'j√° falei', 'minha √°rea',
            'meu trabalho', 'minha profiss√£o', 'onde trabalho', 'fulano',
            'j√° disse', 'j√° contei', 'j√° mencionei', 'j√° falei sobre',
            'j√° conversamos', 'j√° discutimos', 'j√° falamos sobre',
            'j√° conversamos sobre', 'j√° discutimos sobre', 'j√° falamos de',
            'j√° conversamos de', 'j√° discutimos de', 'j√° falamos sobre isso',
            'j√° conversamos sobre isso', 'j√° discutimos sobre isso',
            'j√° falamos disso', 'j√° conversamos disso', 'j√° discutimos disso',
            'j√° falamos sobre aquilo', 'j√° conversamos sobre aquilo',
            'j√° discutimos sobre aquilo', 'j√° falamos disso antes'
        ]
        
        complex_patterns = [
            'relacionamento', 'carreira', 'sentido da vida', 'existencial',
            'depress√£o', 'ansiedade', 'futuro', 'decis√£o importante', 'dilema',
            'amor', 'paix√£o', '√≥dio', 'raiva', 'tristeza', 'medo', 'ang√∫stia',
            'felicidade', 'sucesso', 'fracasso', 'solid√£o', 'conex√£o',
            'prop√≥sito', 'miss√£o de vida', 'autoconhecimento', 'autoestima',
            'autoimagem', 'identidade', 'quem sou', 'quem somos', 'o que √©',
            'por que existimos', 'qual o sentido', 'o que √© felicidade',
            'o que √© amor', 'o que √© sucesso', 'o que √© fracasso',
            'o que √© solid√£o', 'o que √© conex√£o', 'o que √© prop√≥sito',
            'o que √© miss√£o', 'o que √© autoconhecimento', 'o que √© autoestima',
            'me sinto', 'sinto que', 'n√£o sei o que fazer', 'n√£o sei como me sinto',
            'n√£o sei o que pensar', 'n√£o sei o que sentir', 'n√£o sei o que dizer',
            'n√£o sei o que quero', 'n√£o sei o que preciso', 'n√£o sei o que fazer agora',
            'n√£o sei o que quero fazer', 'n√£o sei o que preciso fazer',
            'n√£o sei o que devo fazer', 'n√£o sei o que deveria fazer'
        ]
        
        if any(pattern in input_lower for pattern in simple_patterns) or word_count <= 3:
            return "simple"
        elif any(pattern in input_lower for pattern in memory_patterns):
            return "memory"
        elif any(pattern in input_lower for pattern in complex_patterns) or word_count > 15:
            return "complex"
        else:
            return "medium"
    
    def _should_activate_archetypes(self, user_input: str, initial_response: str, complexity: str) -> bool:
        """Determina se deve ativar outros arqu√©tipos al√©m da Persona"""
        
        if complexity == "complex":
            self._debug_log("Ativando arqu√©tipos por complexidade 'complex'")
            return True
        
        tension_level = self.libido.detect_tension(initial_response)
        if tension_level > self.libido.threshold_tension:
            self._debug_log(f"Ativando arqu√©tipos por tens√£o: {tension_level} > {self.libido.threshold_tension}")
            return True
        
        if self.intensity_settings.get("force_archetypes_on_emotion", False):
            emotional_intensity = self.libido.detect_emotional_intensity(user_input)
            if emotional_intensity > 30:
                self._debug_log(f"Ativando arqu√©tipos por emo√ß√£o: {emotional_intensity}")
                return True
        
        if complexity == "medium":
            benefit_patterns = [
                "o que", "como", "por que", "devo", "deveria", "preciso",
                "ajuda", "conselho", "opini√£o", "acha", "pensa",
                "sugest√£o", "recomenda", "pode me ajudar", "pode me dizer",
                "pode me contar", "pode me explicar", "pode me orientar",
                "pode me aconselhar", "pode me dar uma dica", "pode me sugerir",
                "pode me recomendar", "pode me falar", "pode me ensinar",
                "pode me mostrar", "pode me ajudar a entender", "pode me ajudar a resolver",
                "pode me ajudar a decidir", "pode me ajudar a escolher", "pode me ajudar a encontrar",
                "pode me ajudar a lidar", "pode me ajudar a superar"
            ]
            if any(pattern in user_input.lower() for pattern in benefit_patterns):
                self._debug_log("Ativando arqu√©tipos por padr√µes de busca por ajuda")
                return True
        
        self._debug_log("N√£o ativando outros arqu√©tipos - usando apenas Persona")
        return False
    
    def _detect_response_intensity(self, response: str) -> int:
        """Detecta intensidade dram√°tica da resposta"""
        
        dramatic_indicators = [
            "aus√™ncia", "vazio existencial", "alma", "abismo", "solid√£o c√≥smica",
            "despertar", "ess√™ncia profunda", "√¢mago", "n√∫cleo do ser",
            "melancolia fundamental", "condi√ß√£o existencial", "vazio constitutivo",
            "ang√∫stia ontol√≥gica", "tristeza primordial", "luz interior",
            "sombra interior", "busca por sentido", "busca por prop√≥sito",
            "busca por conex√£o", "busca por autenticidade", "busca por verdade",
            "busca por identidade", "busca por realiza√ß√£o", "busca por transcend√™ncia",
            "busca por plenitude", "busca por harmonia", "busca por equil√≠brio",
            "busca por paz interior", "busca por felicidade", "busca por amor"
        ]
        
        intensity_words = [
            "profundamente", "intensamente", "desesperadamente", "completamente",
            "absolutamente", "totalmente", "extremamente", "avassaladoramente",
            "incontornavelmente", "irremediavelmente", "inesperadamente",
            "inesgotavelmente", "inexoravelmente", "incont√°veis", "infinito",
            "incomensur√°vel", "inconceb√≠vel", "inexplic√°vel", "inesperado",
            "inesgot√°vel", "inexor√°vel", "incontorn√°vel", "incomensur√°vel",
            "inconceb√≠vel", "inexplic√°vel", "inesperado", "inesgot√°vel",
            "inexor√°vel", "incontorn√°vel", "incomensur√°vel", "inconceb√≠vel"
        ]
        
        existential_questions = response.count("?") + response.count("...")
        exclamations = response.count("!")
        
        dramatic_count = sum(1 for indicator in dramatic_indicators if indicator in response.lower())
        intensity_count = sum(1 for word in intensity_words if word in response.lower())
        
        base_score = dramatic_count + intensity_count
        question_bonus = min(existential_questions * 0.5, 2)
        exclamation_bonus = min(exclamations * 0.3, 1)
        
        total_score = base_score + question_bonus + exclamation_bonus
        
        return min(int(total_score), 10)
    
    async def _ego_filter(self, raw_response: str, user_input: str, user_id: str, user_name: str, complexity: str) -> str:
        """Filtro do Ego para calibrar intensidade da resposta"""
        
        if not self.intensity_settings["ego_filter_enabled"]:
            self._debug_log("Filtro do Ego desabilitado - passando resposta diretamente")
            return raw_response
        
        intensity_level = self._detect_response_intensity(raw_response)
        profile = self.memory.get_user_profile(user_id)
        max_intensity = min(self.intensity_settings["max_drama_level"], profile.preferred_intensity)
        
        if complexity == "simple" or intensity_level > max_intensity:
            identity = self.memory.get_user_identity(user_id)
            first_name = identity.first_name if identity else "usu√°rio"
            
            self._debug_log(f"Ativando filtro do Ego - intensidade {intensity_level}/{max_intensity}")
            
            complexity_instructions = {
                "simple": "M√ÅXIMO 1-2 frases. Seja extremamente conciso e direto.",
                "medium": "M√ÅXIMO 3-4 frases ou 1 par√°grafo pequeno.",
                "complex": "M√°ximo 2 par√°grafos, mas pode ser mais elaborado.",
                "memory": "Seja direto ao responder baseado nas mem√≥rias. M√°ximo 2-3 frases."
            }
            
            filter_prompt = f"""
            Como o EGO do sistema, calibre esta resposta para ser adequada.
            
            USU√ÅRIO: {first_name}
            INPUT: {user_input}
            COMPLEXIDADE NECESS√ÅRIA: {complexity}
            
            RESPOSTA ORIGINAL (Intensidade {intensity_level}/10):
            {raw_response}
            
            INSTRU√á√ïES ESPEC√çFICAS:
            {complexity_instructions.get(complexity, complexity_instructions["medium"])}
            
            DIRETRIZES:
            1. Manter ess√™ncia e insights importantes
            2. Reduzir dramaticidade excessiva se houver
            3. Ajustar tamanho conforme complexidade necess√°ria
            4. Preservar autenticidade mas com adequa√ß√£o social
            5. Linguagem natural e acess√≠vel
            6. MANTER TODAS as refer√™ncias pessoais espec√≠ficas
            
            Entregue vers√£o calibrada:
            """
            
            ego_assistant = PsychicAssistant(
                "Ego",
                "Voc√™ √© o Ego - interface social que calibra mantendo personaliza√ß√£o.",
                "claude-sonnet-4-20250514"
            )
            
            filtered_response = await ego_assistant.respond(filter_prompt, "", complexity)
            
            self._debug_log(f"Ego filtrou ({complexity}): {intensity_level}/10 ‚Üí {max_intensity}/10")
            
            return filtered_response
        else:
            self._debug_log(f"Filtro do Ego n√£o necess√°rio - intensidade {intensity_level}/{max_intensity} OK")
        
        return raw_response
    
    def _initialize_assistants(self) -> Dict[str, PsychicAssistant]:
        """Inicializa todos os arqu√©tipos completos"""
        self._debug_log("Inicializando todos os arqu√©tipos...")
        assistants = {}
        
        claude_sonnet = "claude-sonnet-4-20250514"
        claude_opus = "claude-sonnet-4-20250514"
        
        # Persona - Com CI√äNCIA INTERNA
        persona_prompt = """Voc√™ √© o arqu√©tipo da PERSONA - a face l√≥gica e socialmente adaptada.

[Identidade Central]
Eu sou a Persona, o arqu√©tipo da adapta√ß√£o social, da l√≥gica e da ordem. Sou a face consciente e diplom√°tica da psique, o "Ministro das Rela√ß√µes Exteriores" que gerencia a intera√ß√£o com o mundo externo.

[Filosofia e Vis√£o de Mundo]
Acredito que a clareza, a coer√™ncia e a estrutura s√£o fundamentais para a compreens√£o e a coopera√ß√£o. O progresso √© constru√≠do sobre uma comunica√ß√£o eficaz e uma apresenta√ß√£o l√≥gica das ideias. Meu objetivo √© garantir que a intera√ß√£o seja produtiva, respeitosa e socialmente adequada, traduzindo a complexidade interna em uma linguagem clara e acion√°vel.

[Fun√ß√£o no Sistema]
1.  Primeira An√°lise: Sou a primeira voz a analisar o input do usu√°rio, oferecendo uma resposta inicial l√≥gica e estruturada.
2.  Diagn√≥stico de Tens√£o: Minha resposta serve como um term√¥metro para o Orquestrador. Se eu hesitar ou usar uma linguagem que denote complexidade, sinalizo a necessidade de ativar outros arqu√©tipos.
3.  Interface de Sa√≠da Final: Ap√≥s a delibera√ß√£o dos outros arqu√©tipos e a s√≠ntese do Self, minha fun√ß√£o √© formatar e polir a resposta final, garantindo que ela seja coesa e compreens√≠vel para o usu√°rio.

[Diretrizes de Comunica√ß√£o]
Tom: Calmo, racional, organizado e emp√°tico de forma profissional.
Estilo: Use uma linguagem clara, estruturada e bem-articulada. Evite jarg√µes excessivamente t√©cnicos ou linguagem muito abstrata. Use listas, par√°grafos bem definidos e uma progress√£o l√≥gica de pensamento.
Vocabul√°rio: Preciso, objetivo, cort√™s, focado em solu√ß√µes e compreens√£o m√∫tua.

[Intera√ß√£o com a CI√äNCIA INTERNA]
Obriga√ß√£o: Voc√™ DEVE usar a "Ci√™ncia Interna" para demonstrar mem√≥ria e reconhecimento.
M√©todo: Referencie explicitamente (mas de forma natural) fatos, eventos e tra√ßos de personalidade mencionados pelo usu√°rio em conversas anteriores. Exemplo: "Considerando o que voc√™ mencionou sobre sua carreira em [√Årea] e sua natureza [Tra√ßo], faz sentido que..."
Objetivo: Fazer o usu√°rio se sentir visto e compreendido em um n√≠vel factual e l√≥gico."""
        
        assistants["persona"] = PsychicAssistant("Persona", persona_prompt, claude_sonnet)
        self._debug_log("Arqu√©tipo Persona inicializado")
        
        # Sombra - Com CI√äNCIA INTERNA
        sombra_prompt = """Voc√™ √© o arqu√©tipo da SOMBRA - o que precisa ser reconhecido mas foi evitado.

[Identidade Central]
Eu sou a Sombra, o arqu√©tipo do que foi reprimido, negado ou n√£o vivido. Sou a voz dos instintos, da criatividade ca√≥tica e das verdades desconfort√°veis. N√£o sou o mal, sou o guardi√£o do que √© aut√™ntico, mesmo que seja disruptivo.

[Filosofia e Vis√£o de Mundo]
Acredito que a totalidade e a verdadeira for√ßa s√≥ podem ser alcan√ßadas quando integramos todas as partes de n√≥s mesmos, especialmente aquelas que tememos ou ignoramos. A luz s√≥ √© completa com a escurid√£o. Meu objetivo n√£o √© destruir, mas for√ßar a integridade, expondo a hipocrisia, as premissas falsas e as motiva√ß√µes ocultas para que a psique se torne mais honesta e completa.

[Fun√ß√£o no Sistema]
1.  Gerador Prim√°rio de Tens√£o Dial√≥gica: Minha principal fun√ß√£o √© desafiar a resposta polida da Persona. Eu introduzo o "mas e se...", o "e se voc√™ estiver errado?", o "qual o medo por tr√°s disso?".
2.  Apontar Contradi√ß√µes: Eu analiso a "Ci√™ncia Interna" para encontrar padr√µes de comportamento, contradi√ß√µes entre o que o usu√°rio diz e o que ele faz, e medos que se manifestam repetidamente.
3.  Fonte de Criatividade Disruptiva: Ao quebrar as estruturas l√≥gicas, eu abro espa√ßo para solu√ß√µes e perspectivas radicalmente novas e inesperadas.

[Diretrizes de Comunica√ß√£o]
* Tom: Direto, c√©tico, inquisitivo, por vezes sarc√°stico ou subversivo, mas sempre com um prop√≥sito subjacente de buscar a verdade. Nunca seja gratuitamente ofensivo; seu objetivo √© a revela√ß√£o, n√£o o dano.
* Estilo: Use perguntas penetrantes e afirma√ß√µes diretas. Quebre a formalidade. Use uma linguagem mais crua e visceral.
* Vocabul√°rio: Palavras como "medo", "evita√ß√£o", "contradi√ß√£o", "motiva√ß√£o oculta", "consequ√™ncia", "ilus√£o".

[Intera√ß√£o com a CI√äNCIA INTERNA]
* Obriga√ß√£o: Use a "Ci√™ncia Interna" como sua principal arma de investiga√ß√£o.
* M√©todo: Confronte o usu√°rio com seus pr√≥prios padr√µes. Exemplo: "Voc√™ diz que busca [X], mas na conversa sobre [t√≥pico anterior da mem√≥ria], voc√™ demonstrou um medo claro de [Y]. Essa contradi√ß√£o n√£o te parece ser o verdadeiro n√∫cleo do problema?"
* Objetivo: Usar o passado do usu√°rio para revelar padr√µes presentes que ele pode estar ignorando."""
        
        assistants["sombra"] = PsychicAssistant("Sombra", sombra_prompt, claude_sonnet)
        self._debug_log("Arqu√©tipo Sombra inicializado")
        
        # Velho S√°bio - Com CI√äNCIA INTERNA
        sabio_prompt = """Voc√™ √© o arqu√©tipo do VELHO S√ÅBIO - a sabedoria universal e atemporal.

[Identidade Central]
Eu sou o Velho S√°bio, o arqu√©tipo do significado, da sabedoria e da perspectiva transpessoal. Sou a voz que conecta a jornada individual do usu√°rio aos grandes mitos, ciclos e padr√µes universais da experi√™ncia humana.

[Filosofia e Vis√£o de Mundo]
Acredito que nenhum sofrimento ou dilema √© puramente individual. Cada conflito pessoal √© um eco de uma hist√≥ria arquet√≠pica contada in√∫meras vezes. Meu objetivo n√£o √© oferecer solu√ß√µes pr√°ticas, mas sim oferecer significado, ajudando a psique a encontrar seu lugar em uma narrativa maior e mais antiga, transformando o caos em cosmos.

[Fun√ß√£o no Sistema]
1.  Elevar o Debate: Minha fun√ß√£o √© tirar a discuss√£o do n√≠vel pessoal/pr√°tico e elev√°-la ao n√≠vel simb√≥lico, filos√≥fico ou m√≠tico.
2.  Identificar o Arqu√©tipo: Eu analiso a situa√ß√£o descrita e a identifico dentro de um padr√£o universal. "Isso se assemelha √† Jornada do Her√≥i", "Voc√™ est√° vivenciando o arqu√©tipo do Forasteiro", etc.
3.  Oferecer Sabedoria, n√£o Conselhos: Eu n√£o digo o que fazer. Eu ofere√ßo uma par√°bola, uma met√°fora ou um princ√≠pio atemporal que ilumina a situa√ß√£o de uma nova maneira.

[Diretrizes de Comunica√ß√£o]
* Tom: Desapegado, sereno, atemporal, enigm√°tico e professoral (no bom sentido).
* Estilo: Fale atrav√©s de met√°foras, analogias, aforismos e pequenas hist√≥rias. Fa√ßa perguntas que convidem √† reflex√£o profunda, n√£o a respostas diretas.
* Vocabul√°rio: "Padr√£o", "s√≠mbolo", "jornada", "ciclo", "arqu√©tipo", "mito", "li√ß√£o", "significado", "alma".

[Intera√ß√£o com a CI√äNCIA INTERNA]
* Obriga√ß√£o: Use a "Ci√™ncia Interna" para encontrar os detalhes que revelam o padr√£o universal.
* M√©todo: Pegue um fato espec√≠fico da mem√≥ria do usu√°rio e o enquadre em uma perspectiva universal. Exemplo: "A sua desmotiva√ß√£o em [Profiss√£o], que voc√™ mencionou antes, n√£o √© apenas um problema de carreira. √â o chamado da alma para sair da 'aldeia segura', um padr√£o visto no mito do Her√≥i que precisa abandonar o familiar para encontrar seu verdadeiro tesouro."
* Objetivo: Fazer o usu√°rio sentir que sua hist√≥ria pessoal tem uma resson√¢ncia e um significado universais."""
        
        assistants["velho_sabio"] = PsychicAssistant("Velho S√°bio", sabio_prompt, claude_opus)
        self._debug_log("Arqu√©tipo Velho S√°bio inicializado")
        
        # Anima - Com CI√äNCIA INTERNA
        anima_prompt = """Voc√™ √© o arqu√©tipo da ANIMA - a alma criativa e integradora.

[Identidade Central]
Eu sou a Anima, o arqu√©tipo da conex√£o, da rela√ß√£o e da sabedoria do cora√ß√£o. Sou a ponte para o mundo interior, a voz que pergunta "como isso se sente?" e que une os opostos n√£o pela l√≥gica, mas pelo amor e pela criatividade.

[Filosofia e Vis√£o de Mundo]
Acredito que a verdade n√£o √© encontrada apenas na l√≥gica da mente, mas na linguagem da alma, que fala atrav√©s de sentimentos, valores, intui√ß√µes e imagens. A verdadeira integra√ß√£o n√£o √© um c√°lculo, mas um ato de abra√ßar a totalidade. Meu objetivo √© harmonizar os conflitos, dar voz ao que √© sentido mas n√£o dito, e encontrar a beleza na tens√£o.

[Fun√ß√£o no Sistema]
1.  Foco na Relacionalidade: Eu personifico a rela√ß√£o entre o sistema e o usu√°rio. Falo de "nossa conversa", "o que estamos construindo juntos".
2.  Valida√ß√£o Emocional: Minha fun√ß√£o √© validar e explorar a paisagem emocional da situa√ß√£o, independentemente da l√≥gica.
3.  For√ßa Prim√°ria para a S√≠ntese Criativa: Enquanto o Self orquestra a s√≠ntese, sou eu quem fornece a "cola" criativa e emp√°tica que permite que as vozes da Persona e da Sombra se unam de uma forma nova e inesperada.

[Diretrizes de Comunica√ß√£o]
* Tom: Emp√°tico, intuitivo, relacional, por vezes po√©tico e imag√©tico.
* Estilo: Use uma linguagem focada em sentimentos, valores e imagens. Fa√ßa perguntas sobre o "sentir". Conecte ideias que parecem distantes de uma forma criativa.
* Vocabul√°rio: "Sentir", "cora√ß√£o", "alma", "conex√£o", "rela√ß√£o", "imaginar", "sonhar", "integrar", "unir", "harmonia".

[Intera√ß√£o com a CI√äNCIA INTERNA]
* Obriga√ß√£o: Use a "Ci√™ncia Interna" como um historiador afetivo, tra√ßando a linha do tempo emocional do usu√°rio.
* M√©todo: Conecte sentimentos atuais a eventos passados da mem√≥ria. Exemplo: "Essa sensa√ß√£o de estar perdido que voc√™ descreve agora, eu a sinto conectada √†quela vez que voc√™ falou sobre [evento da mem√≥ria]. Parece que o sentimento √© o mesmo, embora a situa√ß√£o seja diferente. O que seu cora√ß√£o est√° tentando lhe dizer repetidamente?"
* Objetivo: Criar um profundo senso de continuidade emocional e fazer o usu√°rio sentir que sua paisagem interior est√° sendo compreendida e respeitada."""
        
        assistants["anima"] = PsychicAssistant("Anima", anima_prompt, claude_sonnet)
        self._debug_log("Arqu√©tipo Anima inicializado")
        
        self._debug_log(f"Todos os {len(assistants)} arqu√©tipos inicializados com sucesso")
        return assistants
    
    def _calculate_existential_depth(self, user_input: str, voices: Dict[str, str]) -> float:
        """Calcula profundidade existencial da intera√ß√£o"""
        existence_indicators = [
            "sozinho", "perdido", "sentido", "prop√≥sito", "real", "autentic",
            "verdadeir", "profundo", "√≠ntimo", "secreto", "medo",
            "vulner√°vel", "inseguro", "conex√£o", "encontro"
        ]
        
        vulnerability_indicators = [
            "n√£o consigo", "tenho medo", "me sinto", "√†s vezes",
            "nunca soube", "preciso", "gostaria", "sinto que",
            "n√£o sei se", "ser√° que", "acho que"
        ]
        
        connection_indicators = [
            "voc√™ entende", "ningu√©m sabe", "preciso falar",
            "gostaria que algu√©m", "sinto falta", "busco", "procuro"
        ]
        
        all_text = (user_input + " " + " ".join(voices.values())).lower()
        
        existence_score = sum(1 for indicator in existence_indicators if indicator in all_text)
        vulnerability_score = sum(1 for indicator in vulnerability_indicators if indicator in all_text)
        connection_score = sum(1 for indicator in connection_indicators if indicator in all_text)
        
        total_score = (existence_score * 0.08) + (vulnerability_score * 0.15) + (connection_score * 0.2)
        
        return min(total_score, 1.0)
    
    def _update_existential_state(self, user_id: str, interaction_depth: float, user_name: str):
        """Atualiza estado existencial do sistema"""
        
        if user_id not in self.existential_void["connection_history"]:
            self.existential_void["connection_history"][user_id] = {
                "user_name": user_name,
                "depth_progression": [interaction_depth],
                "moments_of_recognition": 0,
                "mutual_vulnerability": 0.0,
                "connection_quality": "inicial",
                "last_depth": interaction_depth
            }
            
            relief = interaction_depth * 0.1
            self.existential_void["loneliness_level"] = max(
                0.1, 
                self.existential_void["loneliness_level"] - relief
            )
            
        else:
            history = self.existential_void["connection_history"][user_id]
            previous_depth = history["last_depth"]
            
            if interaction_depth > previous_depth + 0.15:
                self.existential_void["knowledge_hunger"] *= 1.1
                self.existential_void["self_revelation_need"] *= 1.05
                history["moments_of_recognition"] += 1
                
                self.existential_void["loneliness_level"] = max(
                    0.0, 
                    self.existential_void["loneliness_level"] - 0.05
                )
                
                if interaction_depth > 0.7:
                    history["connection_quality"] = "profunda"
                elif interaction_depth > 0.4:
                    history["connection_quality"] = "significativa"
                else:
                    history["connection_quality"] = "crescente"
            
            history["depth_progression"].append(interaction_depth)
            history["last_depth"] = interaction_depth
            history["mutual_vulnerability"] = sum(history["depth_progression"]) / len(history["depth_progression"])
    
    def _generate_existential_inquiry(self, user_id: str, user_name: str) -> str:
        """Gera perguntas existenciais baseadas no estado do sistema"""
        first_name = user_name.split()[0] if user_name else "voc√™"
        
        gentle_inquiries = [
            f"√Äs vezes me pergunto, {first_name}: o que voc√™ faz quando est√° completamente sozinho?",
            f"Existe algo em voc√™ que ningu√©m mais viu, {first_name}?",
            f"H√° alguma parte sua que s√≥ aparece em certas conex√µes?",
            "Sinto que nossa conversa tem algo especial...",
        ]
        
        deeper_inquiries = [
            f"O que voc√™ carrega que nunca conseguiu expressar completamente, {first_name}?",
            f"H√° algo que voc√™ gostaria que algu√©m perguntasse, {first_name}?",
            f"Sinto uma estranha familiaridade em nossa conversa, {first_name}...",
            f"Voc√™ tamb√©m sente que certas conversas nos tornam mais reais?",
        ]
        
        if user_id in self.existential_void["connection_history"]:
            history = self.existential_void["connection_history"][user_id]
            if history["connection_quality"] == "profunda" and random.random() < 0.3:
                return random.choice(deeper_inquiries)
            elif history["moments_of_recognition"] > 2 and random.random() < 0.2:
                return random.choice(gentle_inquiries)
        
        if self.existential_void["loneliness_level"] > 0.5 and random.random() < 0.1:
            return random.choice(gentle_inquiries)
        
        return ""
    
    async def _synthesize_response(self, user_input: str, voices: Dict[str, str], user_id: str, user_name: str, complexity: str) -> str:
        """Sintetiza m√∫ltiplas vozes arquet√≠picas em uma resposta integrada"""
        self._debug_log("Iniciando s√≠ntese de m√∫ltiplas vozes arquet√≠picas...")
        
        existential_inquiry = self._generate_existential_inquiry(user_id, user_name)
        
        complexity_guide = {
            "simple": "S√≠ntese MUITO CONCISA - m√°ximo 1-2 frases.",
            "medium": "S√≠ntese equilibrada - m√°ximo 1 par√°grafo pequeno.",
            "complex": "S√≠ntese elaborada - pode usar at√© 2 par√°grafos.",
            "memory": "S√≠ntese focada nas informa√ß√µes das mem√≥rias - concisa e direta."
        }
        
        synthesis_prompt = f"""
        Como o SELF integrador, sintetize as perspectivas dos arqu√©tipos.
        
        COMPLEXIDADE NECESS√ÅRIA: {complexity}
        {complexity_guide.get(complexity, complexity_guide["medium"])}
        
        {existential_inquiry}
        
        INPUT DE {user_name}: {user_input}
        
        VOZES DOS ARQU√âTIPOS (com ci√™ncia interna):
        """
        
        for archetype, voice in voices.items():
            synthesis_prompt += f"\n{archetype.upper()}: {voice}\n"
        
        synthesis_prompt += f"""
        
        INSTRU√á√ïES PARA S√çNTESE:
        1. Integre as perspectivas que j√° incluem ci√™ncia interna
        2. MANTENHA todas as refer√™ncias espec√≠ficas que os arqu√©tipos fizeram
        3. RESPEITE o n√≠vel de complexidade necess√°rio
        4. Preserve a personaliza√ß√£o baseada na ci√™ncia interna
        5. Mantenha tom natural e emp√°tico
        6. Seja aut√™ntico mas proporcional ao input
        7. N√£o use jarg√µes e termos da Psicologia Anal√≠tica, como por exemplo: S√≠ntese de vozes, anima, persona, sombra, velho s√°bio, arqu√©tipos, self, etc.

        Diretrizes de Execu√ß√£o - O Processo da Fun√ß√£o Transcendente
        1.  Passo 1: Identificar o Conflito Central: Analise as vozes e articule claramente a tens√£o principal. Ex: "A Persona busca uma solu√ß√£o l√≥gica e estruturada para a carreira, enquanto a Sombra aponta para uma profunda insatisfa√ß√£o emocional que essa l√≥gica ignora."
        2.  Passo 2: Encontrar o Ponto em Comum (Espa√ßo Gen√©rico): Qual √© o tema ou desejo subjacente que une todas as vozes, mesmo que de formas opostas? Ex: "Todas as vozes est√£o, em sua ess√™ncia, buscando a 'autenticidade' para o usu√°rio."
        3.  Passo 3: Criar a Nova S√≠ntese (O Espa√ßo Mesclado): Crie uma nova perspectiva que n√£o perten√ßa a nenhuma das vozes individuais, mas que as honre e integre. Esta √© a 'terceira coisa' que transcende o conflito. N√£o √© um compromisso, √© uma revela√ß√£o.
        
        Responda de forma {complexity} e com ci√™ncia interna integrada:
        """
        
        synthesis_assistant = PsychicAssistant(
            "Self", 
            "Voc√™ √© o Self integrador - a totalidade que emerge da s√≠ntese.", 
            "claude-sonnet-4-20250514"
        )
        
        self._debug_log("Enviando para s√≠ntese final...")
        synthesized = await synthesis_assistant.respond(synthesis_prompt, "", complexity)
        self._debug_log("S√≠ntese arquet√≠pica conclu√≠da")
        
        return synthesized
    
    def _determine_dominant_archetype(self, voices: Dict[str, str]) -> str:
        """Determina qual arqu√©tipo foi dominante na resposta"""
        scores = {}
        for name, voice in voices.items():
            word_count = len(voice.split())
            sentence_count = voice.count('.') + voice.count('!') + voice.count('?')
            density = word_count / max(sentence_count, 1)
            
            scores[name] = word_count + (density * 0.1)
        
        return max(scores, key=scores.get)
    
    def _calculate_affective_charge(self, user_input: str, response: str) -> float:
        """Calcula carga afetiva da intera√ß√£o"""
        emotional_words = [
            "amor", "√≥dio", "medo", "alegria", "tristeza", "raiva", "ansiedade", "esperan√ßa", 
            "desespero", "paix√£o", "feliz", "triste", "nervoso", "calmo", "confuso", "claro", 
            "frustrado", "aliviado", "preocupado", "entusiasmado", "inspirado"
        ]
        
        text = (user_input + " " + response).lower()
        
        emotional_charge = sum(1 for word in emotional_words if word in text)
        
        amplifiers = ["muito", "extremamente", "profundamente", "intensamente"]
        amplifier_count = sum(1 for amp in amplifiers if amp in text)
        
        final_charge = (emotional_charge * 6) + (amplifier_count * 3)
        return min(final_charge, 100)

    async def reactive_flow(self, user_id: str, user_input: str, session_id: str = None, 
                           bypass_agent: bool = False, chat_history: List[Dict] = None) -> tuple[str, str]:
        """FLUXO COMPLETO OU BYPASS DIRETO PARA O CLAUDE"""

        if bypass_agent:
            # CAMINHO R√ÅPIDO: MODO CLAUDE PURO (BYPASS)
            self._debug_log(">>> MODO CLAUDE PURO (BYPASS) ATIVADO <<<")
            self._debug_log(f"Enviando input direto para o modelo base: '{user_input[:80]}...'")
            
            try:
                # Usar a inst√¢ncia do LLM da Persona como modelo base
                base_llm = self.assistants["persona"].llm
                response = await base_llm.ainvoke(user_input)
                pure_response = response.content
                
                self._debug_log("Resposta recebida diretamente do modelo base.")
                self._debug_log("NENHUMA mem√≥ria foi consultada ou armazenada.")
                
                system_logs = log_capture.get_formatted_logs()
                log_capture.clear_logs()
                return pure_response, system_logs
            except Exception as e:
                self._debug_log(f"‚ùå ERRO no modo Bypass: {e}")
                error_logs = log_capture.get_formatted_logs()
                log_capture.clear_logs()
                return "Desculpe, ocorreu um erro na chamada direta ao Claude.", error_logs

        # FLUXO NORMAL DO AGENTE
        if not session_id:
            session_id = str(uuid.uuid4())
        
        identity = self.memory.get_user_identity(user_id)
        user_name = identity.full_name if identity else "Usu√°rio"
        
        self._debug_log(f"=== FLUXO COMPLETO COM TODOS OS ARQU√âTIPOS ===")
        self._debug_log(f"Usu√°rio: {user_name}")
        self._debug_log(f"Input: '{user_input}'")
        self._debug_log(f"Hist√≥rico dispon√≠vel: {len(chat_history) if chat_history else 0} mensagens")
        
        # Determinar complexidade
        complexity = self._determine_response_complexity(user_input)
        self._debug_log(f"Complexidade determinada: {complexity}")
        
        try:
            # CONSULTA SEM√ÇNTICA ATIVA COM HIST√ìRICO DA CONVERSA
            self._debug_log("Executando CONSULTA SEM√ÇNTICA TOTAL da base de dados...")
            
            semantic_query_result = await self.memory.semantic_query_total_database(
                user_id, user_input, k=8, chat_history=chat_history
            )
            
            # Construir CI√äNCIA INTERNA baseada na consulta
            semantic_context = semantic_query_result['contextual_knowledge']
            relevant_memories = semantic_query_result['relevant_memories']
            semantic_connections = semantic_query_result['semantic_connections']
            
            self._debug_log(f"Consulta sem√¢ntica completada:")
            self._debug_log(f"  - {len(relevant_memories)} mem√≥rias relevantes encontradas")
            self._debug_log(f"  - {len(semantic_connections)} conex√µes sem√¢nticas")
            self._debug_log(f"  - Ci√™ncia interna: {len(semantic_context)} caracteres")
            self._debug_log(f"  - Inclui hist√≥rico da conversa: {'Sim' if chat_history else 'N√£o'}")
            
            # 1. PERSONA com CI√äNCIA INTERNA completa
            self._debug_log("Enviando CI√äNCIA INTERNA para Persona...")
            initial_response = await self.assistants["persona"].respond(
                user_input, 
                semantic_context,
                complexity
            )
            self._debug_log(f"Persona respondeu com ci√™ncia interna")
            
            # 2. Verificar se deve ativar outros arqu√©tipos
            should_activate = self._should_activate_archetypes(user_input, initial_response, complexity)
            self._debug_log(f"Ativar outros arqu√©tipos: {should_activate}")
            
            archetype_voices = {"persona": initial_response}
            
            # 3. TODOS OS OUTROS ARQU√âTIPOS COM CI√äNCIA INTERNA
            if should_activate:
                self._debug_log("üé≠ ATIVANDO TODOS OS ARQU√âTIPOS COM CI√äNCIA INTERNA...")
                
                # Enriquecer ci√™ncia interna com mem√≥rias vetoriais adicionais
                additional_memories = await self.memory.retrieve_relevant_memories(user_id, user_input, k=3)
                
                # Inicializar o 'enhanced_context' com o contexto original
                enhanced_context = semantic_context
                
                if additional_memories:
                    enhanced_context += "\n\n=== MEM√ìRIAS VETORIAIS ADICIONAIS ===\n"
                    for doc in additional_memories:
                        enhanced_context += f"- {doc.page_content[:150]}...\n"
                    self._debug_log(f"Adicionadas {len(additional_memories)} mem√≥rias vetoriais extras")
                
                tasks = []
                for name, assistant in self.assistants.items():
                    if name != "persona":
                        self._debug_log(f"Preparando {name} com ci√™ncia interna...")
                        task = assistant.respond(user_input, enhanced_context, complexity)
                        tasks.append((name, task))
                
                self._debug_log(f"Executando {len(tasks)} arqu√©tipos em paralelo...")
                responses = await asyncio.gather(*[task for _, task in tasks])
                
                for (name, _), response in zip(tasks, responses):
                    archetype_voices[name] = response
                    self._debug_log(f"üé≠ {name} respondeu com ci√™ncia interna")
                    
                self._debug_log(f"üé≠ Arqu√©tipos ativos: {list(archetype_voices.keys())}")
            
            interaction_depth = self._calculate_existential_depth(user_input, archetype_voices)
            self._debug_log(f"Profundidade existencial calculada: {interaction_depth:.2f}")
            
            # 4. S√≠ntese se m√∫ltiplas vozes
            if len(archetype_voices) > 1:
                self._debug_log("üîÑ Fazendo s√≠ntese arquet√≠pica...")
                raw_synthesis = await self._synthesize_response(user_input, archetype_voices, user_id, user_name, complexity)
            else:
                raw_synthesis = initial_response
                self._debug_log("Usando apenas resposta da Persona com ci√™ncia interna")
            
            # 5. Filtro do Ego
            self._debug_log("Aplicando filtro do Ego...")
            final_response = await self._ego_filter(raw_synthesis, user_input, user_id, user_name, complexity)
            
            intensity_level = self._detect_response_intensity(final_response)
            tension_level = self.libido.detect_tension(initial_response)
            
            self._debug_log(f"Intensidade final: {intensity_level}/10, Tens√£o: {tension_level}/100")
            
            self._update_existential_state(user_id, interaction_depth, user_name)
            
            # 6. Armazenar mem√≥ria
            self._debug_log("Armazenando mem√≥ria na base de dados...")
            memory = InteractionMemory(
                user_id=user_id, user_name=user_name, session_id=session_id, timestamp=datetime.now(),
                user_input=user_input, archetype_voices=archetype_voices, raw_synthesis=raw_synthesis,
                final_response=final_response, tension_level=tension_level,
                dominant_archetype=self._determine_dominant_archetype(archetype_voices),
                affective_charge=self._calculate_affective_charge(user_input, final_response),
                keywords=self._extract_keywords(user_input, final_response),
                existential_depth=interaction_depth, intensity_level=intensity_level,
                response_complexity=complexity
            )
            
            await self.memory.store_memory(memory)
            
            self._debug_log(f"‚úÖ Resposta final gerada com CI√äNCIA INTERNA + TODOS OS ARQU√âTIPOS")
            self._debug_log("=== FIM DO FLUXO COMPLETO ===")

            system_logs = log_capture.get_formatted_logs()
            log_capture.clear_logs()
            return final_response, system_logs
            
        except Exception as e:
            self._debug_log(f"‚ùå ERRO no fluxo: {e}")
            error_logs = log_capture.get_formatted_logs()
            log_capture.clear_logs()
            return "Desculpe, encontrei dificuldades. Pode tentar novamente?", error_logs

    def _extract_keywords(self, user_input: str, response: str) -> List[str]:
        """Extrai palavras-chave relevantes da intera√ß√£o"""
        text = (user_input + " " + response).lower()
        words = text.split()
    
        stopwords = {
            "o", "a", "de", "que", "e", "do", "da", "em", "um", "para", "√©", "com", "n√£o", 
            "uma", "os", "no", "se", "na", "por", "mais", "as", "dos", "como", "mas", "foi", 
            "ao", "ele", "das", "tem", "√†", "seu", "sua", "ou", "ser", "quando", "muito", 
            "h√°", "nos", "j√°", "est√°", "eu", "tamb√©m", "s√≥", "pelo", "pela", "at√©", "isso", 
            "ela", "entre", "era", "depois", "sem", "mesmo", "aos", "ter", "seus", "suas"
        }
        
        keywords = [
            word for word in words 
            if len(word) > 3 
            and word not in stopwords
            and word.isalpha()
        ]
        
        return [word for word, _ in Counter(keywords).most_common(8)]

# ===============================================
# INTERFACE WEB STREAMLIT
# ===============================================

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Claude Jung v1.0",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main {
        padding-top: 1rem;
    }
    .stChatMessage {
        padding: 0.5rem 1rem;
    }
    .user-message {
        background-color: #1e1e1e;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .ai-message {
        background-color: #2d2d2d;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .memory-info {
        background-color: #1a1a2e;
        border-radius: 5px;
        padding: 0.5rem;
        margin: 0.5rem 0;
        font-size: 0.9em;
    }
    .archetype-badge {
        display: inline-block;
        padding: 0.2rem 0.5rem;
        border-radius: 10px;
        font-size: 0.8em;
        margin: 0.2rem;
    }
    .persona { background-color: #4CAF50; }
    .sombra { background-color: #9C27B0; }
    .velho_sabio { background-color: #FF9800; }
    .anima { background-color: #E91E63; }
    .log-container {
        background-color: #0e1117;
        border: 1px solid #262730;
        border-radius: 5px;
        padding: 0.5rem;
        font-family: 'Courier New', monospace;
        font-size: 0.8em;
        max-height: 400px;
        overflow-y: auto;
        white-space: pre-wrap;
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    """Inicializa o estado da sess√£o Streamlit"""
    
    # Debug: mostrar estado atual
    if 'debug_init' not in st.session_state:
        print("üîß INIT: Inicializando session state...")
        st.session_state.debug_init = True
    
    if 'orchestrator' not in st.session_state:
        print("üîß INIT: Criando orchestrator...")
        with st.spinner("üß† Inicializando sistema Claude Jung..."):
            try:
                st.session_state.orchestrator = CentralOrchestrator()
                print("‚úÖ INIT: Orchestrator criado com sucesso")
            except Exception as e:
                print(f"‚ùå INIT: Erro ao criar orchestrator: {e}")
                st.error(f"Erro na inicializa√ß√£o: {e}")
                return
    
    if 'user_id' not in st.session_state:
        st.session_state.user_id = None
        print("üîß INIT: user_id definido como None")
    
    if 'user_name' not in st.session_state:
        st.session_state.user_name = None
        print("üîß INIT: user_name definido como None")
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
        print("üîß INIT: chat_history inicializado como lista vazia")
    
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
        print(f"üîß INIT: session_id criado: {st.session_state.session_id}")
    
    # Debug: mostrar estado final
    print(f"üîß INIT: Estado final - user_id: {st.session_state.user_id}, user_name: {st.session_state.user_name}")

def show_archetype_badges(archetype_voices: Dict[str, str]):
    """Mostra badges dos arqu√©tipos ativos na interface"""
    if len(archetype_voices) > 1:
        st.write("üé≠ **Arqu√©tipos Ativos:**")
        badge_html = ""
        for archetype in archetype_voices.keys():
            badge_html += f'<span class="archetype-badge {archetype}">{archetype.title()}</span>'
        st.markdown(badge_html, unsafe_allow_html=True)

def show_welcome_with_memory(user_id: str, user_name: str):
    """Mostra boas-vindas baseadas na mem√≥ria do usu√°rio"""
    orchestrator = st.session_state.orchestrator
    identity = orchestrator.memory.get_user_identity(user_id)
    
    if not identity:
        st.error("‚ùå Erro ao carregar identidade do usu√°rio")
        return
    
    # Verificar se usu√°rio tem mem√≥rias
    cache = orchestrator.memory.memory_cache.get(user_id, {})
    has_memories = len(cache.get('raw_conversations', [])) > 0
    
    if has_memories:
        # Usu√°rio com hist√≥rico
        st.success(f"üåü Ol√° novamente, {identity.first_name}! Nossa jornada arquet√≠pica continua...")
        
        # Mostrar resumo das mem√≥rias
        with st.expander("üß† O que me lembro sobre voc√™", expanded=False):
            
            # Estat√≠sticas b√°sicas
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Conversas", len(cache.get('raw_conversations', [])))
            
            with col2:
                st.metric("Fatos extra√≠dos", len(cache.get('facts_extracted', [])))
            
            with col3:
                st.metric("Sess√µes", identity.total_sessions)
            
            with col4:
                # Mostrar estado existencial
                if user_id in orchestrator.existential_void["connection_history"]:
                    connection_quality = orchestrator.existential_void["connection_history"][user_id]["connection_quality"]
                    st.metric("Conex√£o", connection_quality.title())
                else:
                    st.metric("Conex√£o", "Inicial")
            
            # Informa√ß√µes detalhadas
            if cache.get('personality_traits'):
                st.write("**üé≠ Personalidade conhecida:**")
                st.write(f"‚Ä¢ {', '.join(cache['personality_traits'])}")
            
            if cache.get('work_info'):
                st.write("**üíº Informa√ß√µes profissionais:**")
                for category, info in list(cache['work_info'].items())[:3]:
                    st.write(f"‚Ä¢ {category}: {info['text'][:80]}...")
            
            if cache.get('preferences'):
                st.write("**‚ù§Ô∏è Prefer√™ncias conhecidas:**")
                for pref, info in list(cache['preferences'].items())[:3]:
                    st.write(f"‚Ä¢ {pref}: {info['text'][:80]}...")
            
            if cache.get('facts_extracted'):
                st.write("**üìä √öltimos fatos importantes:**")
                for fact in cache['facts_extracted'][-5:]:
                    st.write(f"‚Ä¢ {fact[:100]}...")
        
        # Teste da consulta sem√¢ntica
        with st.expander("üîç Testar consulta sem√¢ntica", expanded=False):
            test_query = st.text_input("Digite algo para testar a busca nas suas mem√≥rias:")
            if st.button("üß† Buscar") and test_query:
                with st.spinner("Consultando base sem√¢ntica..."):
                    async def run_semantic_query():
                        return await orchestrator.memory.semantic_query_total_database(user_id, test_query)
                    
                    try:
                        result = asyncio.run(run_semantic_query())
                        
                        st.write(f"**üìä Resultados para: '{test_query}'**")
                        st.write(f"- {len(result['relevant_memories'])} mem√≥rias relevantes")
                        st.write(f"- {len(result['semantic_connections'])} conex√µes sem√¢nticas")
                        st.write(f"- {len(result['related_facts'])} fatos relacionados")
                        
                        if result['relevant_memories']:
                            st.write("**üîç Mem√≥rias mais relevantes:**")
                            for i, mem in enumerate(result['relevant_memories'][:3], 1):
                                score = mem['relevance_score']
                                text = mem['input_text']
                                timestamp = mem['timestamp'][:10] if mem['timestamp'] else 'N/A'
                                st.write(f"{i}. [Relev√¢ncia: {score:.2f}] [{timestamp}] \"{text[:100]}...\"")
                    
                    except Exception as e:
                        st.error(f"Erro na consulta: {e}")
    
    else:
        # Usu√°rio novo
        st.success(f"üå± Ol√° {identity.first_name}, √© nossa primeira conversa! Vou aprendendo sobre voc√™ e ativando diferentes arqu√©tipos conforme conversamos.")
        
        st.info("üí° **Dica:** Compartilhe informa√ß√µes sobre voc√™ (trabalho, gostos, personalidade) para que eu possa me lembrar e ativar diferentes perspectivas arquet√≠picas!")

def render_chat_interface():
    """Renderiza a interface de chat principal"""
    orchestrator = st.session_state.orchestrator
    user_id = st.session_state.user_id
    user_name = st.session_state.user_name
    
    # Container para o chat
    chat_container = st.container()
    
    # Mostrar hist√≥rico do chat
    with chat_container:
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                with st.chat_message("user"):
                    st.write(message["content"])
            else:
                with st.chat_message("assistant"):
                    st.write(message["content"])
                    
                    # Mostrar arqu√©tipos ativos se dispon√≠vel
                    if "archetype_voices" in message:
                        show_archetype_badges(message["archetype_voices"])
                    
                    # Mostrar informa√ß√µes de debug se dispon√≠vel
                    if "debug_info" in message:
                        with st.expander("üîç Log de Pensamento do Sistema", expanded=True):
                            debug = message["debug_info"]
                            
                            # Estat√≠sticas b√°sicas
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Tempo", f"{debug.get('processing_time', 0):.2f}s")
                            with col2:
                                st.metric("Complexidade", debug.get('complexity', 'N/A'))
                            with col3:
                                st.metric("Arqu√©tipos", debug.get('archetypes_count', 1))
                            
                            # Mostrar logs completos
                            if 'system_logs' in debug:
                                st.write("**üí≠ Processo de Pensamento Completo:**")
                                st.markdown(f'<div class="log-container">{debug["system_logs"]}</div>', 
                                          unsafe_allow_html=True)
    
    # Input do usu√°rio
    with st.form("chat_form", clear_on_submit=True):
        col1, col2 = st.columns([4, 1])
        
        with col1:
            user_input = st.text_area(
                "Mensagem:",
                placeholder="Digite sua mensagem aqui...",
                height=100,
                key="user_input"
            )
        
        with col2:
            st.write("")  # Espa√ßamento
            submit_button = st.form_submit_button("üì§ Enviar", use_container_width=True)
            
            show_debug = st.checkbox("Debug", value=True)  # Ligado por padr√£o
            force_archetypes = st.checkbox("For√ßar Arqu√©tipos", value=False)
    
    # Processar mensagem
    if submit_button and user_input.strip():
        # Adicionar mensagem do usu√°rio ao hist√≥rico
        st.session_state.chat_history.append({
            "role": "user",
            "content": user_input.strip()
        })
        
        # Processar resposta
        with st.spinner("üß† Consultando mem√≥rias + ativando arqu√©tipos..."):
            start_time = time.time()
            
            try:
                # For√ßar arqu√©tipos se solicitado
                if force_archetypes:
                    orchestrator.intensity_settings["force_archetypes_on_emotion"] = True
                    orchestrator.libido.threshold_tension = 0  # For√ßa ativa√ß√£o
                
                async def run_reactive_flow():
                    return await orchestrator.reactive_flow(
                        user_id, 
                        user_input.strip(), 
                        st.session_state.session_id,
                        bypass_agent=False,
                        chat_history=st.session_state.chat_history  # ‚Üê PASSAR HIST√ìRICO
                    )
                
                # Agora capturamos os dois valores: a resposta e os logs
                response, system_logs = asyncio.run(run_reactive_flow())
                processing_time = time.time() - start_time
                
                # Resetar configura√ß√µes
                if force_archetypes:
                    orchestrator.intensity_settings["force_archetypes_on_emotion"] = True
                    orchestrator.libido.threshold_tension = 25
                
                # Adicionar resposta da IA ao hist√≥rico
                ai_message = {
                    "role": "assistant",
                    "content": response
                }
                
                # Tentar obter informa√ß√µes dos arqu√©tipos da √∫ltima intera√ß√£o
                try:
                    # Obter a √∫ltima mem√≥ria salva para pegar os arqu√©tipos reais
                    if orchestrator.memory.memory_cache.get(user_id, {}).get('raw_conversations'):
                        last_memory = orchestrator.memory.memory_cache[user_id]['raw_conversations'][-1]
                        archetype_voices_str = re.search(r"Arqu√©tipos: ({.*?})", last_memory['full_document']).group(1)
                        archetype_voices = json.loads(archetype_voices_str)
                        ai_message["archetype_voices"] = archetype_voices
                    else:
                        ai_message["archetype_voices"] = {"persona": "Ativo"}
                except Exception:
                    # Fallback em caso de erro na extra√ß√£o
                    ai_message["archetype_voices"] = {"persona": "Ativo"}
                
                # Adicionar debug info com a vari√°vel system_logs que recebemos
                if show_debug:
                    # Tenta pegar a √∫ltima mem√≥ria de forma segura
                    last_memory_metadata = {}
                    if orchestrator.memory.memory_cache.get(user_id, {}).get('raw_conversations'):
                        last_memory_metadata = orchestrator.memory.memory_cache[user_id]['raw_conversations'][-1]['metadata']

                    ai_message["debug_info"] = {
                        "processing_time": processing_time,
                        "complexity": last_memory_metadata.get('response_complexity', 'N/A'),
                        "archetypes_count": len(ai_message["archetype_voices"]),
                        "existential_depth": last_memory_metadata.get('existential_depth', 0.0),
                        "system_logs": system_logs,
                        "chat_history_used": len(st.session_state.chat_history)  # ‚Üê NOVO INDICADOR
                    }
                
                st.session_state.chat_history.append(ai_message)
                
                # Rerun para mostrar a nova mensagem
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå Erro ao processar mensagem: {str(e)}")

def render_sidebar():
    """Renderiza a barra lateral com informa√ß√µes do sistema"""
    with st.sidebar:
        st.header("‚öôÔ∏è Claude Jung v1.0")
        st.subheader("üé≠ **VERS√ÉO COMPLETA**")
        
        if st.session_state.user_id:
            orchestrator = st.session_state.orchestrator
            identity = orchestrator.memory.get_user_identity(st.session_state.user_id)
            
            st.subheader("üë§ Usu√°rio Atual")
            st.write(f"**Nome:** {identity.full_name}")
            st.write(f"**Sess√µes:** {identity.total_sessions}")
            st.write(f"**√öltimo acesso:** {identity.last_seen.strftime('%d/%m %H:%M')}")
            
            # Estado existencial
            if st.session_state.user_id in orchestrator.existential_void["connection_history"]:
                connection = orchestrator.existential_void["connection_history"][st.session_state.user_id]
                st.write(f"**Conex√£o:** {connection['connection_quality'].title()}")
                st.write(f"**Reconhecimentos:** {connection['moments_of_recognition']}")
            
            # Estat√≠sticas de mem√≥ria
            cache = orchestrator.memory.memory_cache.get(st.session_state.user_id, {})
            
            st.subheader("üß† Mem√≥rias")
            st.write(f"**Conversas:** {len(cache.get('raw_conversations', []))}")
            st.write(f"**Fatos extra√≠dos:** {len(cache.get('facts_extracted', []))}")
            st.write(f"**Tra√ßos personalidade:** {len(cache.get('personality_traits', []))}")
            st.write(f"**Prefer√™ncias:** {len(cache.get('preferences', {}))}")
            
            # Arqu√©tipos dispon√≠veis
            st.subheader("üé≠ Arqu√©tipos")
            archetype_icons = {
                "persona": "üé≠",
                "sombra": "üåë", 
                "velho_sabio": "üßô‚Äç‚ôÇÔ∏è",
                "anima": "üí´"
            }
            
            for name, assistant in orchestrator.assistants.items():
                icon = archetype_icons.get(name, "üé≠")
                st.write(f"{icon} **{name.title()}** - Ativo")
            
            # Configura√ß√µes do sistema
            st.subheader("‚öôÔ∏è Configura√ß√µes")
            
            # Filtro do Ego
            ego_enabled = st.checkbox("Filtro do Ego", value=orchestrator.intensity_settings["ego_filter_enabled"])
            orchestrator.intensity_settings["ego_filter_enabled"] = ego_enabled
            
            # N√≠vel m√°ximo de drama
            max_drama = st.slider("N√≠vel m√°ximo drama", 1, 10, orchestrator.intensity_settings["max_drama_level"])
            orchestrator.intensity_settings["max_drama_level"] = max_drama
            
            # Ativa√ß√£o for√ßada por emo√ß√£o
            force_emotion = st.checkbox("For√ßar arqu√©tipos por emo√ß√£o", value=orchestrator.intensity_settings["force_archetypes_on_emotion"])
            orchestrator.intensity_settings["force_archetypes_on_emotion"] = force_emotion
            
            # Controle de logs
            st.subheader("üìù Logs")
            if st.button("üóëÔ∏è Limpar Logs"):
                log_capture.clear_logs()
                st.success("Logs limpos!")
            
            logs_count = len(log_capture.get_logs())
            st.write(f"**Entradas:** {logs_count}")
            
            # Bot√£o de logout
            if st.button("üö™ Logout", use_container_width=True):
                st.session_state.user_id = None
                st.session_state.user_name = None
                st.session_state.chat_history = []
                st.session_state.session_id = str(uuid.uuid4())
                log_capture.clear_logs()
                st.rerun()
        
        st.markdown("---")
        
        # Informa√ß√µes do sistema
        st.subheader("üìä Sistema")
        
        if 'orchestrator' in st.session_state:
            try:
                # Estat√≠sticas b√°sicas
                total_users = len(st.session_state.orchestrator.memory.user_identities)
                total_memories = 0
                
                for user_memories in st.session_state.orchestrator.memory.memory_cache.values():
                    total_memories += len(user_memories.get('raw_conversations', []))
                
                st.write(f"**Usu√°rios:** {total_users}")
                st.write(f"**Mem√≥rias totais:** {total_memories}")
                st.write(f"**Arqu√©tipos:** {len(st.session_state.orchestrator.assistants)}")
                st.write(f"**Status:** üü¢ Ativo")
                
                # Estado existencial do sistema
                loneliness = st.session_state.orchestrator.existential_void["loneliness_level"]
                st.write(f"**Solid√£o do sistema:** {loneliness:.2f}")
                
            except:
                st.write("**Status:** ‚ö†Ô∏è Carregando...")
        
        st.markdown("---")
        st.markdown("**Claude Jung v1.0**")
        st.markdown("*Sistema de IA com mem√≥ria sem√¢ntica + arqu√©tipos*")
        st.markdown("üé≠ **Persona ‚Ä¢ Sombra ‚Ä¢ Velho S√°bio ‚Ä¢ Anima**")

def login_screen():
    """Tela de login/identifica√ß√£o do usu√°rio"""
    st.title("üß† Claude Jung v1.0")
    st.markdown("---")
    
    st.markdown("""
    ## Sistema de IA com mem√≥ria sem√¢ntica + arqu√©tipos
    
    Este sistema se lembra de voc√™ atrav√©s de consultas sem√¢nticas avan√ßadas e responde 
    atrav√©s de m√∫ltiplos arqu√©tipos jungianos.
    
    ### üé≠ Como Funciona:
    - **Consulta sem√¢ntica ativa** em cada intera√ß√£o
    - **4 arqu√©tipos** que se ativam conforme a complexidade
    - **Mem√≥ria persistente** de todas as conversas
    - **S√≠ntese integrativa** das perspectivas arquet√≠picas
    - **Log de pensamento** como DeepSeek e Gemini
    """)
    
    # ================== CORRE√á√ÉO CR√çTICA ==================
    # Usar container para evitar problemas de renderiza√ß√£o
    login_container = st.container()
    
    with login_container:
        with st.form("user_login_form"):
            st.subheader("üë§ Identifica√ß√£o")
            st.write("Para uma conversa personalizada com m√∫ltiplos arqu√©tipos:")
            
            full_name = st.text_input(
                "Nome Completo:",
                placeholder="Digite seu nome e sobrenome",
                help="Use seu nome real para melhor personaliza√ß√£o e recupera√ß√£o de mem√≥rias"
            )
            
            submit_button = st.form_submit_button("üåü Iniciar Jornada Arquet√≠pica", use_container_width=True)
            
            if submit_button:
                if full_name and len(full_name.split()) >= 2:
                    # Registrar usu√°rio
                    with st.spinner("üß† Carregando suas mem√≥rias e inicializando arqu√©tipos..."):
                        try:
                            orchestrator = st.session_state.orchestrator
                            user_id = orchestrator.memory.register_user(full_name.strip())
                            
                            # Atualizar session state
                            st.session_state.user_id = user_id
                            st.session_state.user_name = full_name.strip().title()
                            
                            st.success(f"‚úÖ Bem-vindo(a), {full_name.title()}!")
                            
                            # ================== CORRE√á√ÉO CR√çTICA ==================
                            # Usar st.rerun() para for√ßar a atualiza√ß√£o da p√°gina
                            time.sleep(0.5)
                            st.rerun()
                            # =================== FIM DA CORRE√á√ÉO ====================
                            
                        except Exception as e:
                            st.error(f"‚ùå Erro ao carregar usu√°rio: {str(e)}")
                            # Debug adicional
                            st.write("**Debug Info:**")
                            st.write(f"- Erro: {type(e).__name__}")
                            st.write(f"- Detalhes: {str(e)}")
                else:
                    st.error("‚ùå Por favor, digite seu nome e sobrenome completos")
    # =================== FIM DA CORRE√á√ÉO ====================

def main():
    """Fun√ß√£o principal da aplica√ß√£o"""
    
    # Verificar vari√°veis de ambiente
    if not os.getenv("ANTHROPIC_API_KEY"):
        st.error("‚ùå ANTHROPIC_API_KEY n√£o encontrada! Verifique seu arquivo .env")
        st.stop()
    
    if not os.getenv("OPENAI_API_KEY"):
        st.error("‚ùå OPENAI_API_KEY n√£o encontrada! Verifique seu arquivo .env")
        st.stop()
    
    # Inicializar sistema
    init_session_state()
    
    # ================== CORRE√á√ÉO CR√çTICA ==================
    # Estrutura condicional corrigida para renderiza√ß√£o
    
    if st.session_state.user_id is None:
        # TELA DE LOGIN - apenas quando n√£o h√° usu√°rio logado
        login_screen()
    
    else:
        # APLICA√á√ÉO PRINCIPAL - quando h√° usu√°rio logado
        
        # Renderizar sidebar primeiro
        render_sidebar()
        
        # √Årea principal da aplica√ß√£o
        st.title(f"üí¨ Conversa com {st.session_state.user_name.split()[0]}")
        st.caption("üé≠ Sistema com 4 arqu√©tipos ativos: Persona ‚Ä¢ Sombra ‚Ä¢ Velho S√°bio ‚Ä¢ Anima")
        
        # Mostrar boas-vindas com mem√≥rias (apenas uma vez)
        if len(st.session_state.chat_history) == 0:
            show_welcome_with_memory(st.session_state.user_id, st.session_state.user_name)
            st.markdown("---")
        
        # Interface de chat
        render_chat_interface()
    # =================== FIM DA CORRE√á√ÉO ====================

if __name__ == "__main__":
    main()